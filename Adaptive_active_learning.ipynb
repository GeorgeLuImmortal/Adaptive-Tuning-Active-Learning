{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(2019)\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "import random as r\n",
    "r.seed(2019)\n",
    "\n",
    "import sys\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(2019)\n",
    "torch.cuda.manual_seed_all(2019)\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(2019)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import d, here\n",
    "\n",
    "import pandas as pd\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import random, tqdm, sys, math, gzip\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "import gc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit,StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import fine_tuned\n",
    "import inference\n",
    "import time\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Built-in Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show size of variables\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "## random over sampling instances belong to minority class in case of imbalanced dataset\n",
    "def resample(X,Y,random_state=2019):\n",
    "    X_reshape = np.reshape(X, (X.shape[0], X.shape[1]*X.shape[2]))\n",
    "    rus = RandomOverSampler(random_state=random_state)\n",
    "    X_res, y_res = rus.fit_resample(X_reshape, Y)\n",
    "    X_back = np.reshape(X_res, (X_res.shape[0],X.shape[1],X.shape[2]))\n",
    "    \n",
    "    return X_back, y_res\n",
    "\n",
    "## seed the initial data\n",
    "def initial_seed_dataset(n_initial, Y,random_state):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['label'] = Y\n",
    "\n",
    "    Samplesize = n_initial  #number of samples that you want       \n",
    "    initial_samples = df.groupby('label', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:])\n",
    "\n",
    "    permutation = [index[1] for index in initial_samples.index.tolist()]\n",
    "    \n",
    "    print ('initial random chosen samples', permutation)\n",
    "    \n",
    "    return permutation\n",
    "\n",
    "## compute the entropy\n",
    "def compute_entropy(output):\n",
    "    entropy = -(output[:,0]*np.log2(output[:,0]) + output[:,1]*np.log2(output[:,1]))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "## sample the candidates for labelling\n",
    "def sample_candidates(selection_method,permutation,y_prob,num_candidate,y_pred,dist):\n",
    "    \n",
    "    print('*'*20,'selection method ',selection_method,'*'*20)\n",
    "    \n",
    "        \n",
    "        \n",
    "    if selection_method == 'uncertainty':\n",
    "       \n",
    "        candidate_index = []\n",
    "        \n",
    "        for index in dist.argsort():\n",
    "            if len(candidate_index) == num_candidate:\n",
    "                break\n",
    "            if index not in permutation:\n",
    "                candidate_index.append(index)\n",
    "\n",
    "        permutation = permutation+candidate_index\n",
    "        \n",
    "    if selection_method == 'certainty':\n",
    "        entropy = compute_entropy(np.array(y_prob))\n",
    "        candidate_index = []\n",
    "        \n",
    "        \n",
    "        for index in entropy.argsort()[:]:\n",
    "            if len(candidate_index) == num_candidate:\n",
    "                break\n",
    "            if index not in permutation:\n",
    "                candidate_index.append(index)\n",
    "\n",
    "        permutation = permutation+candidate_index\n",
    "        \n",
    "    if selection_method == 'mostConfident':\n",
    "        entropy = compute_entropy(np.array(y_prob))\n",
    "        candidate_index = []\n",
    "        \n",
    "        \n",
    "        for index in np.argsort(np.array(y_prob)[:,1])[::-1]:\n",
    "            if len(candidate_index) == num_candidate:\n",
    "                break\n",
    "            if index not in permutation:\n",
    "                candidate_index.append(index)\n",
    "\n",
    "        permutation = permutation+candidate_index\n",
    "        \n",
    "    print('*'*20,'num of training set ',len(permutation),'*'*20)   \n",
    "        \n",
    "    return permutation\n",
    "\n",
    "## normalization instance\n",
    "class Normalize(object):\n",
    "    \n",
    "    def normalize(self, X_train, X_val):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_val   = self.scaler.transform(X_val)\n",
    "       \n",
    "        return (X_train, X_val) \n",
    "    \n",
    "    def inverse(self, X_train, X_val):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_val   = self.scaler.inverse_transform(X_val)\n",
    "    \n",
    "        return (X_train, X_val) \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "## read data from directory\n",
    "def read_data(path):\n",
    "\n",
    "    corpora = []\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "        df_temp = pd.read_csv(path+filename)\n",
    "\n",
    "        corpora.append(df_temp.text.tolist())\n",
    "\n",
    "    class_one_len = len(corpora[0])\n",
    "    class_two_len = len(corpora[1])\n",
    "\n",
    "    return corpora, class_one_len, class_two_len\n",
    "\n",
    "## construct training text dataset for fine tuning language model, save in directory data/\n",
    "def construct_train_set(dataset,permutation):\n",
    "    print('constructing new text training set.....')\n",
    "    corpora, class_one_len, class_two_len = read_data('./corpus_data/'+dataset+'/')\n",
    "\n",
    "    texts = np.array(corpora[0]+corpora[1])\n",
    "    labels = np.array([0]*class_one_len+[1]*class_two_len)\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(texts[permutation], labels[permutation], test_size=0.0, random_state=2019)\n",
    "    X_train, y_train = texts[permutation], labels[permutation]\n",
    "    \n",
    "    train_df = pd.DataFrame({'id':range(len(X_train)),'label':y_train,'alpha':['a']*len(X_train),'text':X_train})\n",
    "#     dev_df = pd.DataFrame({'id':range(len(X_test)),'label':y_test,'alpha':['a']*len(X_test),'text':X_test})\n",
    "    \n",
    "    train_df.to_csv('data/train.tsv', sep='\\t', index=False, header=False)\n",
    "#     dev_df.to_csv('data/dev.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Import Inferred embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## choose the bert-like models, options are roberta-base, disilbert-base-uncased, gpt2, xlnet-base-cased, albert-base-v2\n",
    "text_rep = 'roberta-base'\n",
    "\n",
    "\n",
    "## input dataset \n",
    "dataset = 'ProtonPumpInhibitors'\n",
    "dir_neg = dataset + '_neg.csv'\n",
    "dir_pos = dataset + '_pos.csv'\n",
    "\n",
    "representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "\n",
    "ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "labels = np.array([0]*len(representations_neg)+[1]*len(representations_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Active Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of class for final output\n",
    "NUM_CLS = 2\n",
    "\n",
    "def active_process(arg):\n",
    "    \"\"\"\n",
    "    Active learning procedure for Adaptive Tuning active learning model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## gridsearch for hyper-parameters tuning for SVM\n",
    "    if arg.loop%arg.gridsearch_interval==0:\n",
    "        gridsearch = True\n",
    "    else:\n",
    "        gridsearch = False\n",
    "    \n",
    "    \n",
    "    if arg.initial: \n",
    "        ## the first round, initialize seed data\n",
    "        permutation = initial_seed_dataset(arg.n_seedsamples,arg.LABEL_emb,arg.initial_random_seed)\n",
    "       \n",
    "        X_train = arg.TEXT_emb[permutation]\n",
    "        Y_train = arg.LABEL_emb[permutation]\n",
    "\n",
    "        X_val = arg.TEXT_emb\n",
    "        Y_val = arg.LABEL_emb\n",
    "        \n",
    "        bin_count = np.bincount(Y_train)\n",
    "        unique = np.unique(Y_train)\n",
    "        print (\n",
    "        'initial training set size:',\n",
    "        Y_train.shape[0],\n",
    "        'unique(labels):',\n",
    "        unique,\n",
    "        'label counts:',\n",
    "        bin_count\n",
    "        )\n",
    "\n",
    "        print('Number of training examples ', len(Y_train))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        permutation = arg.permutation\n",
    "       \n",
    "        \n",
    "        X_train = arg.TEXT_emb[permutation]\n",
    "        Y_train = arg.LABEL_emb[permutation]\n",
    "\n",
    "        X_val = arg.TEXT_emb\n",
    "        Y_val = arg.LABEL_emb\n",
    "        \n",
    "        bin_count = np.bincount(Y_train)\n",
    "        unique = np.unique(Y_train)\n",
    "        print (\n",
    "        'training set size:',\n",
    "        Y_train.shape[0],\n",
    "        'unique(labels):',\n",
    "        unique,\n",
    "        'label counts:',\n",
    "        bin_count\n",
    "        )\n",
    "\n",
    "        print('Number of training examples ', len(Y_train))\n",
    "\n",
    "\n",
    "    evaluation= { 'Confusion matrix':[]}\n",
    "    \n",
    "    normalizer = Normalize()\n",
    "    X_train, X_val = normalizer.normalize(X_train, X_val) \n",
    "        \n",
    "    \n",
    "    if gridsearch == True:\n",
    "        ## gridsearch for finding best hyper-parameters\n",
    "        print('start gridsearch ...')\n",
    "        parameters = [\n",
    "                    {'kernel': ['linear'],\n",
    "                     'C': [ 0.01, 0.1, 1,10]}]\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5,random_state=arg.initial_random_seed)\n",
    "        svc = SVC(probability=True,random_state=2019,class_weight='balanced',max_iter=10000)\n",
    "        classifier = GridSearchCV(svc, parameters, cv=cv,scoring='accuracy',n_jobs=8,verbose = 0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        print('best parameters is ', classifier.best_params_)\n",
    "        best_params_ = classifier.best_params_\n",
    "       \n",
    "        \n",
    "    else:\n",
    "        ## hyper-parameters from last loop\n",
    "        best_params_ = arg.best_params_\n",
    "        kernel = best_params_['kernel']\n",
    "        C = best_params_['C']\n",
    "        \n",
    "        classifier = SVC(probability=True,random_state=2019,class_weight='balanced',C=C,kernel=kernel,max_iter=10000)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        print('best parameters is ', classifier)\n",
    "        \n",
    "        \n",
    "    ## evaluation\n",
    "        \n",
    "    y_pred_prob = classifier.predict_proba(X_val)\n",
    "#     y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    y_true = Y_val\n",
    "    \n",
    "    numerators = classifier.decision_function(X_val)\n",
    "    try:\n",
    "        w_norm = np.linalg.norm(classifier.best_estimator_.coef_)\n",
    "    except Exception:\n",
    "        w_norm = np.linalg.norm(classifier.coef_)\n",
    "\n",
    "    dist = abs(numerators) / w_norm\n",
    "   \n",
    "\n",
    "    y_true_remain = np.delete(np.array(y_true),permutation)\n",
    "    y_pred_remain = np.delete(np.array(y_pred),permutation)\n",
    "        \n",
    "    print(classification_report(y_true_remain,y_pred_remain))\n",
    "   \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_remain, y_pred_remain, labels=[0,1]).ravel()\n",
    "    print('TP_H',bin_count[1],' TN_H',bin_count[0], ' TP_M',tp, ' TN_M',tn, ' FP_M', fp, ' FN_M',fn)\n",
    "    acc = accuracy_score(y_true_remain, y_pred_remain)\n",
    "    f_score = f1_score(y_true_remain,y_pred_remain,average='macro')\n",
    "                \n",
    "    evaluation['Confusion matrix'].append({'TP_H':bin_count[1],'TN_H':bin_count[0], 'TP_M':tp, 'TN_M':tn, 'FP_M': fp, 'FN_M':fn})\n",
    "\n",
    "    \n",
    "    return evaluation, y_pred_prob, y_pred,permutation, best_params_,dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  0 th loops---------------\n",
      "initial random chosen samples [476, 707, 770, 587, 468, 1026, 1891, 1549, 1101, 1390]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88       995\n",
      "           1       0.84      0.95      0.89       995\n",
      "\n",
      "    accuracy                           0.88      1990\n",
      "   macro avg       0.89      0.88      0.88      1990\n",
      "weighted avg       0.89      0.88      0.88      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 943  TN_M 818  FP_M 177  FN_M 52\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [12  8]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       988\n",
      "           1       0.99      0.93      0.96       992\n",
      "\n",
      "    accuracy                           0.96      1980\n",
      "   macro avg       0.96      0.96      0.96      1980\n",
      "weighted avg       0.96      0.96      0.96      1980\n",
      "\n",
      "TP_H 8  TN_H 12  TP_M 922  TN_M 975  FP_M 13  FN_M 70\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [15 15]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94       985\n",
      "           1       0.91      0.98      0.94       985\n",
      "\n",
      "    accuracy                           0.94      1970\n",
      "   macro avg       0.94      0.94      0.94      1970\n",
      "weighted avg       0.94      0.94      0.94      1970\n",
      "\n",
      "TP_H 15  TN_H 15  TP_M 964  TN_M 892  FP_M 93  FN_M 21\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [24 16]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       976\n",
      "           1       0.94      0.99      0.96       984\n",
      "\n",
      "    accuracy                           0.96      1960\n",
      "   macro avg       0.96      0.96      0.96      1960\n",
      "weighted avg       0.96      0.96      0.96      1960\n",
      "\n",
      "TP_H 16  TN_H 24  TP_M 970  TN_M 912  FP_M 64  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [30 20]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       970\n",
      "           1       0.94      0.98      0.96       980\n",
      "\n",
      "    accuracy                           0.96      1950\n",
      "   macro avg       0.96      0.96      0.96      1950\n",
      "weighted avg       0.96      0.96      0.96      1950\n",
      "\n",
      "TP_H 20  TN_H 30  TP_M 962  TN_M 914  FP_M 56  FN_M 18\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [36 24]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       964\n",
      "           1       0.97      0.98      0.98       976\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 24  TN_H 36  TP_M 958  TN_M 934  FP_M 30  FN_M 18\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [42 28]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       958\n",
      "           1       0.98      0.98      0.98       972\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "TP_H 28  TN_H 42  TP_M 953  TN_M 939  FP_M 19  FN_M 19\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [46 34]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       954\n",
      "           1       0.97      0.99      0.98       966\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 34  TN_H 46  TP_M 959  TN_M 922  FP_M 32  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [53 37]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       947\n",
      "           1       0.99      0.99      0.99       963\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 37  TN_H 53  TP_M 951  TN_M 937  FP_M 10  FN_M 12\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [57 43]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       943\n",
      "           1       0.99      0.99      0.99       957\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 43  TN_H 57  TP_M 949  TN_M 929  FP_M 14  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [65 45]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       935\n",
      "           1       0.99      0.99      0.99       955\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 45  TN_H 65  TP_M 949  TN_M 924  FP_M 11  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [69 51]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       931\n",
      "           1       0.99      0.99      0.99       949\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 51  TN_H 69  TP_M 944  TN_M 922  FP_M 9  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [77 53]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       923\n",
      "           1       0.99      0.99      0.99       947\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 53  TN_H 77  TP_M 942  TN_M 918  FP_M 5  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [80 60]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       920\n",
      "           1       1.00      0.99      1.00       940\n",
      "\n",
      "    accuracy                           1.00      1860\n",
      "   macro avg       1.00      1.00      1.00      1860\n",
      "weighted avg       1.00      1.00      1.00      1860\n",
      "\n",
      "TP_H 60  TN_H 80  TP_M 935  TN_M 916  FP_M 4  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [86 64]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       914\n",
      "           1       1.00      1.00      1.00       936\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 64  TN_H 86  TP_M 933  TN_M 911  FP_M 3  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [92 68]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       908\n",
      "           1       1.00      1.00      1.00       932\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 68  TN_H 92  TP_M 929  TN_M 905  FP_M 3  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [96 74]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       904\n",
      "           1       1.00      1.00      1.00       926\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 74  TN_H 96  TP_M 923  TN_M 901  FP_M 3  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [99 81]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       901\n",
      "           1       1.00      1.00      1.00       919\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 81  TN_H 99  TP_M 916  TN_M 899  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [103  87]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       897\n",
      "           1       1.00      1.00      1.00       913\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 87  TN_H 103  TP_M 910  TN_M 895  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [107  93]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       893\n",
      "           1       1.00      1.00      1.00       907\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 93  TN_H 107  TP_M 904  TN_M 891  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:36:11.690764 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 16:36:11.692757 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:36:12.444759 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 16:36:12.445730 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 16:36:12.904016 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 16:36:12.905013 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:36:13.297335 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 16:36:16.666580 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 16:36:16.668575 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 16:36:18.975284 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 56.70it/s]\n",
      "I0120 16:36:23.484139 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:36:23.641718 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 16:36:23.642715 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 16:36:23.643712 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 16:36:23.644710 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 16:36:23.644710 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 16:36:23.645600 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309b9e6aa2dc4962a55714a20cb92e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.703386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:23<05:22, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3c336ccec84525b2d6cc3de21d7294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674982"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:36:54.054612 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 16:36:55.402951 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 16:36:55.403949 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.083920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:47<05:03, 23.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8c95e4bc9d46aca15b9829f6ce1f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:37:25.206765 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 16:37:26.541428 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 16:37:26.542425 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.122284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:10<04:41, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf93fd0e52444ff3848fe23f750b8887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001535"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:37:55.791858 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 16:37:57.022987 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 16:37:57.024982 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001428"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:34<04:17, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe32f4c18e84a6fba151601178d7aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:56<03:49, 22.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7418c6fa1d28412b884ca99bf023f00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:38:25.898785 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 16:38:27.155432 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 16:38:27.156429 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:19<03:28, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e9034ff9774ce285b15aaf29c44247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:38:56.671554 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 16:38:57.994041 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 16:38:57.995039 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:43<03:06, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac846b908744f15a91f0b9d3fa826f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:39:27.390511 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 16:39:28.709488 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 16:39:28.710485 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:06<02:43, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e33b2166c2457babe5feeb2d6f68f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:28<02:18, 23.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d17dd1e1ab846e1be5ab9b6b5715808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000337"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:39:58.168157 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 16:39:59.435186 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 16:39:59.437175 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:52<01:55, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b0bf05948e4a4e9468f32da9e76b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:40:28.730723 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 16:40:30.034878 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 16:40:30.035875 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:16<01:33, 23.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c9001649a2481899b651151a2bd3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000274"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:40:59.497760 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 16:41:00.836203 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 16:41:00.837201 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:39<01:10, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9ca4d4cd144a62b4ad0b1dedd8b17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [05:02<00:46, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf7d91003704ea18ffa623596c3859d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:41:30.568188 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 16:41:31.892541 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 16:41:31.893537 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:26<00:23, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a44a3917ac8410f941443a38ceb21ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:01.565318 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 16:42:02.895474 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 16:42:02.895474 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:49<00:00, 23.29s/it]\n",
      "I0120 16:42:12.997270 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.09568803911126635\n",
      "I0120 16:42:13.002258 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 16:42:13.004251 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 16:42:13.004251 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:42:13.005249 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:16.370282 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 50.94it/s]\n",
      "I0120 16:42:21.279529 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:42:21.457053 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 16:42:21.458050 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:42:21.459048 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eec6b1c29834a9eb0a02476cf3f4d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:26.640758 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 16:42:26.641756 15348 fine_tuned.py:368]   acc = 0.9761904761904762\n",
      "I0120 16:42:26.641756 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:42:26.641756 15348 fine_tuned.py:368]   fp = 4\n",
      "I0120 16:42:26.642753 15348 fine_tuned.py:368]   mcc = 0.9526506069685131\n",
      "I0120 16:42:26.642753 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 16:42:26.643750 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:42:26.643750 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 16:42:26.644748 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:42:26.645745 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:29.987503 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.20it/s]\n",
      "I0120 16:42:34.790782 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:42:34.970301 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 16:42:34.972296 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:42:34.972296 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a147b35e214b31bd1279b040264450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:40.164776 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 16:42:40.165774 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 16:42:40.165774 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:42:40.166770 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:42:40.166770 15348 fine_tuned.py:368]   mcc = 0.99048503575804\n",
      "I0120 16:42:40.166770 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:42:40.167769 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:42:40.168766 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 16:42:40.169764 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:42:40.170762 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:43.533253 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 51.48it/s]\n",
      "I0120 16:42:48.334195 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:42:48.497756 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 16:42:48.498753 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:42:48.498753 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b39f1903cb49598e335213c7133a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:53.639896 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 16:42:53.640893 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:42:53.640893 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:42:53.641891 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:42:53.641891 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:42:53.642889 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:42:53.642889 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:42:53.643885 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 16:42:53.643885 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:42:53.644883 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:42:57.035953 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.40it/s]\n",
      "I0120 16:43:01.774793 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:43:01.936897 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 16:43:01.937866 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:43:01.937866 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1953da0a5d294af6a1e54eb910d25efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:07.120684 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 16:43:07.122679 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:43:07.122679 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:43:07.123677 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:43:07.123677 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:43:07.124673 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:43:07.124673 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:43:07.125671 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 16:43:07.126668 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:43:07.127665 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:10.518790 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 50.00it/s]\n",
      "I0120 16:43:15.498278 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:43:15.654831 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 16:43:15.654831 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:43:15.655828 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3398994e473943ed90e1f5394bfc2c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:20.834916 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 16:43:20.835914 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:43:20.835914 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:43:20.836912 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:43:20.836912 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:43:20.837908 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:43:20.837908 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:43:20.839904 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 16:43:20.840901 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:43:20.841897 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:24.305696 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 48.82it/s]\n",
      "I0120 16:43:29.372552 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:43:29.521181 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 16:43:29.521181 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:43:29.522175 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c85607c0114483e8da7986b9be09997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:34.829345 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 16:43:34.830341 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:43:34.830341 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:43:34.831338 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:43:34.831338 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:43:34.832336 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:43:34.832336 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:43:34.834330 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 16:43:34.834330 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:43:34.835328 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:38.350957 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.99it/s]\n",
      "I0120 16:43:42.672943 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:43:42.814564 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 16:43:42.814564 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:43:42.815562 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1228c40adb7f40d484bddf8dde244597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:47.965547 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 16:43:47.965547 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:43:47.966544 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:43:47.966544 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:43:47.967541 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:43:47.967541 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:43:47.967541 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:43:47.968539 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 16:43:47.969536 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:43:47.970533 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:43:51.389526 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.18it/s]\n",
      "I0120 16:43:56.030575 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:43:56.188155 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 16:43:56.188155 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:43:56.189150 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131d2442674a4725a810564916bb9bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:01.329566 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 16:44:01.330563 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:44:01.330563 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:44:01.331561 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:44:01.331561 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:44:01.331561 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:44:01.332560 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:44:01.333556 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 16:44:01.333556 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:44:01.334553 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:04.828943 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.58it/s]\n",
      "I0120 16:44:09.304685 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:44:09.438933 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 16:44:09.438933 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:44:09.439960 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc289757edc45c692cc6bf588f227ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:14.550368 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 16:44:14.550368 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:44:14.551365 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:44:14.551365 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:44:14.552362 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:44:14.552362 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:44:14.552362 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:44:14.554358 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 16:44:14.554358 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:44:14.555355 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:17.881003 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.63it/s]\n",
      "I0120 16:44:22.183375 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:44:22.332538 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 16:44:22.333568 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:44:22.333568 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d866807e9890453b9b9ba0ecae7d75a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:27.446271 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 16:44:27.447269 15348 fine_tuned.py:368]   acc = 0.5380952380952381\n",
      "I0120 16:44:27.447269 15348 fine_tuned.py:368]   fn = 97\n",
      "I0120 16:44:27.448266 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:44:27.448266 15348 fine_tuned.py:368]   mcc = 0.07394738666465357\n",
      "I0120 16:44:27.449262 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:44:27.449262 15348 fine_tuned.py:368]   tp = 1\n",
      "I0120 16:44:27.450259 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 16:44:27.451257 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:44:27.451257 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:30.997519 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 47.48it/s]\n",
      "I0120 16:44:36.095072 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:44:36.245668 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 16:44:36.246666 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:44:36.247663 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2e68851377471ca2b0eb6c086c9c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:41.347716 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 16:44:41.348713 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 16:44:41.348713 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 16:44:41.349710 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:44:41.349710 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 16:44:41.349710 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 16:44:41.350708 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 16:44:41.351705 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 16:44:41.352703 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:44:41.352703 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:44.808720 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 51.52it/s]\n",
      "I0120 16:44:49.534909 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:44:49.687500 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 16:44:49.687500 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:44:49.688525 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66603631abc4fc591a5f8c0ef1673a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:54.889574 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 16:44:54.889574 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:44:54.889574 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:44:54.890571 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:44:54.890571 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:44:54.891568 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:44:54.891568 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:44:54.892565 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 16:44:54.893563 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:44:54.893563 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:44:58.391391 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 50.61it/s]\n",
      "I0120 16:45:02.872303 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:45:02.996969 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 16:45:02.997966 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:45:02.997966 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6ed8d2e1774e0da4113ae160dedc92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:08.195519 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 16:45:08.195519 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:45:08.196516 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:45:08.196516 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:45:08.197512 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:45:08.197512 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:45:08.198509 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:45:08.199507 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 16:45:08.200505 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:45:08.201503 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:11.555600 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 48.55it/s]\n",
      "I0120 16:45:16.217836 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:45:16.371431 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 16:45:16.372428 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:45:16.373424 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8c9128653485e9790bc361bd0229f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:21.508015 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 16:45:21.509014 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:45:21.509014 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:45:21.510038 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:45:21.510038 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:45:21.511034 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:45:21.511034 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:45:21.512005 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 16:45:21.513003 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:45:21.514000 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:24.938847 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 54.25it/s]\n",
      "I0120 16:45:29.247916 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:45:29.410457 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 16:45:29.411454 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:45:29.412450 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2274c71906534c309a2d114fa2e83710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:34.522611 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 16:45:34.523609 15348 fine_tuned.py:368]   acc = 0.9333333333333333\n",
      "I0120 16:45:34.524606 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:45:34.524606 15348 fine_tuned.py:368]   fp = 13\n",
      "I0120 16:45:34.525604 15348 fine_tuned.py:368]   mcc = 0.8727708153369337\n",
      "I0120 16:45:34.525604 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 16:45:34.526602 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:45:34.527598 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 16:45:34.527598 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:45:34.528595 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:38.132658 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 54.61it/s]\n",
      "I0120 16:45:42.417187 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:45:42.534873 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 16:45:42.535870 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:45:42.536868 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c341a2022c4a5fa76adb4aa520aaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:47.676172 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 16:45:47.677170 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:45:47.678167 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:45:47.678167 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:45:47.679164 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:45:47.679164 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:45:47.679164 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:45:47.680161 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 16:45:47.681159 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:45:47.682155 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:45:51.135482 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.95it/s]\n",
      "I0120 16:45:55.878707 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:45:56.025321 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 16:45:56.027315 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:45:56.027315 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d59b2e1eaf84754b2b8b13ebeefc72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:01.166996 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 16:46:01.167990 15348 fine_tuned.py:368]   acc = 0.9809523809523809\n",
      "I0120 16:46:01.167990 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:46:01.168988 15348 fine_tuned.py:368]   fp = 3\n",
      "I0120 16:46:01.168988 15348 fine_tuned.py:368]   mcc = 0.9619590738385182\n",
      "I0120 16:46:01.169985 15348 fine_tuned.py:368]   tn = 109\n",
      "I0120 16:46:01.169985 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:46:01.170983 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 16:46:01.172978 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:46:01.172978 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:04.810297 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 50.86it/s]\n",
      "I0120 16:46:09.624974 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:46:09.758187 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 16:46:09.759184 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:46:09.759184 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1638bb38744976aab220a156131116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:14.869461 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 16:46:14.870458 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:46:14.870458 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:46:14.871454 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:46:14.872452 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:46:14.872452 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:46:14.873449 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:46:14.874447 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 16:46:14.875444 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:46:14.876441 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:18.418529 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 54.59it/s]\n",
      "I0120 16:46:22.534857 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:46:22.679468 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 16:46:22.680493 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:46:22.680493 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10913df9c6a64eb6bde7a24987b77a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:27.782195 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 16:46:27.783193 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:46:27.783193 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:46:27.784204 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:46:27.784204 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:46:27.784204 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:46:27.785186 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:46:27.786185 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 16:46:27.786185 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:46:27.787181 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:31.169827 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.32it/s]\n",
      "I0120 16:46:35.175447 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:46:35.350982 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 16:46:35.351978 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:46:35.351978 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff668d3293b4a17bc9b53bf3d63c0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:40.554292 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 16:46:40.556287 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:46:40.556287 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:46:40.556287 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:46:40.557284 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:46:40.558281 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:46:40.558281 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:46:40.559279 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 16:46:40.560276 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:46:40.561273 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:43.948696 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 55.62it/s]\n",
      "I0120 16:46:48.051763 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:46:48.204356 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 16:46:48.205352 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:46:48.206351 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a978d1f9a9c6491da34ed14a9d3cb5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:53.388856 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 16:46:53.389854 15348 fine_tuned.py:368]   acc = 0.9809523809523809\n",
      "I0120 16:46:53.389854 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:46:53.390851 15348 fine_tuned.py:368]   fp = 3\n",
      "I0120 16:46:53.390851 15348 fine_tuned.py:368]   mcc = 0.9619590738385182\n",
      "I0120 16:46:53.391849 15348 fine_tuned.py:368]   tn = 109\n",
      "I0120 16:46:53.391849 15348 fine_tuned.py:368]   tp = 97\n",
      "I0120 16:46:53.392846 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 16:46:53.393844 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:46:53.394841 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:46:56.715900 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.00it/s]\n",
      "I0120 16:47:01.230108 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:47:01.373698 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 16:47:01.374695 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 16:47:01.375692 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa2fe1fe66e457dbe383e6481fd6f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:47:06.421074 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 16:47:06.422070 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 16:47:06.422070 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 16:47:06.422070 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 16:47:06.423068 15348 fine_tuned.py:368]   mcc = 0.9808673469387755\n",
      "I0120 16:47:06.423068 15348 fine_tuned.py:368]   tn = 111\n",
      "I0120 16:47:06.424065 15348 fine_tuned.py:368]   tp = 97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:47:07.194251 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 16:47:07.196216 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 16:47:07.302931 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 16:47:07.304925 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:47:07.305922 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b344cf8cc944e4bc72681970c8ea17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [112  98]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       888\n",
      "           1       1.00      1.00      1.00       902\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 98  TN_H 112  TP_M 900  TN_M 886  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [119 101]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       881\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 101  TN_H 119  TP_M 897  TN_M 879  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [128 102]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       872\n",
      "           1       1.00      1.00      1.00       898\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 102  TN_H 128  TP_M 896  TN_M 870  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [137 103]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       863\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 103  TN_H 137  TP_M 896  TN_M 861  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [147 103]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       853\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 103  TN_H 147  TP_M 896  TN_M 851  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [157 103]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       843\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 103  TN_H 157  TP_M 896  TN_M 841  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [167 103]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       833\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 103  TN_H 167  TP_M 896  TN_M 831  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [177 103]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       823\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 103  TN_H 177  TP_M 896  TN_M 821  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [187 103]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       813\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 103  TN_H 187  TP_M 896  TN_M 811  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [197 103]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       803\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 103  TN_H 197  TP_M 896  TN_M 801  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [207 103]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       793\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 103  TN_H 207  TP_M 896  TN_M 791  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [217 103]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       783\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 103  TN_H 217  TP_M 896  TN_M 781  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [227 103]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       773\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 103  TN_H 227  TP_M 896  TN_M 771  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [237 103]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       763\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 103  TN_H 237  TP_M 896  TN_M 761  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [247 103]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       753\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 103  TN_H 247  TP_M 896  TN_M 751  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [256 104]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       744\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 104  TN_H 256  TP_M 896  TN_M 742  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [266 104]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       734\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 104  TN_H 266  TP_M 896  TN_M 732  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [276 104]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 104  TN_H 276  TP_M 896  TN_M 722  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [286 104]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       714\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 104  TN_H 286  TP_M 896  TN_M 712  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [296 104]\n",
      "Number of training examples  400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       704\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 104  TN_H 296  TP_M 896  TN_M 702  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:48:35.550084 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 16:48:35.551109 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:48:36.327316 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 16:48:36.328341 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 16:48:36.388154 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 16:48:36.390176 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:48:36.391146 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 16:48:39.808345 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 93.64it/s]\n",
      "I0120 16:48:44.937433 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:48:45.224145 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 16:48:45.225143 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 16:48:45.226140 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 16:48:45.226140 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 16:48:45.227137 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 16:48:45.227137 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f4e641e8e24ff9a2ebcec162b1b7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1.268423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:42<09:55, 42.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19989354d7d4429b01d54094907a7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:49:41.845563 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 16:49:43.103535 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 16:49:43.104532 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:26<09:18, 43.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf2d3fd8b6a4fa3b4d10dea206ff5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:50:39.366659 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 16:50:40.610547 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 16:50:40.611543 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:10<08:39, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80e8d0a92bb489ea93e25a274c4d405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:51:37.192922 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 16:51:38.421722 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 16:51:38.422721 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:54<07:58, 43.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a695e53ecfc4b34a4297c1db883625c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:37<07:11, 43.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c27379e0cfe45a4a8005a58e117177d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:52:34.271288 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 16:52:35.519228 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 16:52:35.520225 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:21<06:32, 43.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63dd5fceb9884ab7a45267d7ab04bea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:53:32.676387 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 16:53:33.984422 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 16:53:33.986416 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [05:05<05:49, 43.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fa65b419274143adb597663dc38745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:54:29.653520 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 16:54:30.916646 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 16:54:30.917644 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:48<05:05, 43.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b0b97b936f45cc97590f20293454e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:31<04:20, 43.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4f7d0f6e6d46d6a0d7da8cd47e3408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:55:27.689517 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 16:55:28.931521 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 16:55:28.932545 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:15<03:37, 43.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb2729a3fb044ac914f02ad8b7ef66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:56:24.515357 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 16:56:25.772969 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 16:56:25.773966 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:59<02:54, 43.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7c27e335594e67a467348473a0ba7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:57:22.507205 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 16:57:23.679759 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 16:57:23.680729 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:43<02:11, 43.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc17d69878047d6a1e885a0454d9656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:26<01:27, 43.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a5b4b526744f4ebd45bdc24c6c6124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:58:20.296566 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 16:58:21.495413 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 16:58:21.496409 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [10:12<00:44, 44.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b85321f3f74b3c93d8867ad849a912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:59:20.031066 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 16:59:21.302607 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 16:59:21.303576 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:55<00:00, 43.72s/it]\n",
      "I0120 16:59:40.966053 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.006622895207798597\n",
      "I0120 16:59:40.971039 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-280', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 16:59:40.973034 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 16:59:40.975029 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:59:40.975029 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:59:44.293383 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 102.57it/s]\n",
      "I0120 16:59:49.108863 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 16:59:49.469869 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 16:59:49.470866 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 16:59:49.470866 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5939a1c45a0745dbb81157f0e691d99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 16:59:59.479471 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 16:59:59.480468 15348 fine_tuned.py:368]   acc = 0.9951219512195122\n",
      "I0120 16:59:59.481467 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 16:59:59.481467 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 16:59:59.482463 15348 fine_tuned.py:368]   mcc = 0.9871173179519238\n",
      "I0120 16:59:59.482463 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 16:59:59.483462 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 16:59:59.484457 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 16:59:59.485455 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 16:59:59.485455 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:02.730175 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 103.58it/s]\n",
      "I0120 17:00:07.435447 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:00:07.741010 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 17:00:07.742007 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:00:07.743005 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f5ae641f544d58918d0b619d0e939f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:17.770755 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 17:00:17.770755 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:00:17.771753 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:00:17.771753 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:00:17.772750 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:00:17.772750 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:00:17.772750 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:00:17.773747 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 17:00:17.774744 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:00:17.775742 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:21.091253 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 88.67it/s]\n",
      "I0120 17:00:26.301526 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:00:26.610700 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 17:00:26.611697 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:00:26.612694 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415f231a111746ea82038d90a3bce5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:36.702163 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 17:00:36.703160 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:00:36.703160 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:00:36.704158 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:00:36.704158 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:00:36.705155 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:00:36.705155 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:00:36.706152 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 17:00:36.707149 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:00:36.707149 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:39.917744 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 102.37it/s]\n",
      "I0120 17:00:44.713796 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:00:44.961641 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 17:00:44.962637 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:00:44.962637 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d81a5692274435a1e2067574fae640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:55.007627 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 17:00:55.007627 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:00:55.008596 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:00:55.008596 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:00:55.009595 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:00:55.009595 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:00:55.010592 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:00:55.012586 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 17:00:55.013583 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:00:55.013583 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:00:58.319324 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 102.62it/s]\n",
      "I0120 17:01:02.661663 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:01:02.933907 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 17:01:02.934905 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:01:02.934905 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84a1d12098643aebbc428fbbd01d50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:12.944179 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 17:01:12.944179 15348 fine_tuned.py:368]   acc = 0.9951219512195122\n",
      "I0120 17:01:12.945176 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:01:12.945176 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 17:01:12.946174 15348 fine_tuned.py:368]   mcc = 0.9872788094188178\n",
      "I0120 17:01:12.947171 15348 fine_tuned.py:368]   tn = 304\n",
      "I0120 17:01:12.947171 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:01:12.948168 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 17:01:12.949165 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:01:12.950162 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:16.180208 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 100.97it/s]\n",
      "I0120 17:01:21.086526 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:01:21.345833 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 17:01:21.345833 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:01:21.346830 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c784603ef41f42c69dcc58807b0fe12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:31.373078 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 17:01:31.374075 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:01:31.374075 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:01:31.375072 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:01:31.375072 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:01:31.376069 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:01:31.376069 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:01:31.377067 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 17:01:31.378064 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:01:31.378064 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:34.725700 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 102.74it/s]\n",
      "I0120 17:01:39.423876 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:01:39.690164 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 17:01:39.690164 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:01:39.691161 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12e8123e4e4e78acef48f980bb77dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:49.683635 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 17:01:49.684633 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:01:49.684633 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:01:49.685631 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:01:49.685631 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:01:49.685631 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:01:49.686627 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:01:49.687625 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 17:01:49.688623 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:01:49.688623 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:01:53.068641 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.53it/s]\n",
      "I0120 17:01:57.880619 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:01:58.129951 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 17:01:58.130948 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:01:58.130948 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5635a9036f8f4afb9c53b1e90b1c77c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:08.206166 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 17:02:08.207163 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:02:08.207163 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:02:08.207163 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:02:08.208161 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:02:08.208161 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:02:08.209159 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:02:08.210155 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 17:02:08.211153 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:02:08.212180 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:11.554062 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 100.44it/s]\n",
      "I0120 17:02:16.413896 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:02:16.693457 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 17:02:16.693457 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:02:16.694455 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9456932f3c4f67ba67663ffa96183e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:26.765784 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 17:02:26.765784 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:02:26.766781 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:02:26.766781 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:02:26.767778 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:02:26.767778 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:02:26.768775 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:02:26.769772 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 17:02:26.770770 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:02:26.770770 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:29.949562 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.48it/s]\n",
      "I0120 17:02:34.661984 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:02:34.901344 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 17:02:34.901344 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:02:34.902341 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a4430adc744640805b5d4e3e39e28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:44.986922 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 17:02:44.987920 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:02:44.987920 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:02:44.988917 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:02:44.988917 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:02:44.989914 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:02:44.989914 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:02:44.990911 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 17:02:44.991910 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:02:44.991910 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:02:48.260774 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.16it/s]\n",
      "I0120 17:02:53.061177 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:02:53.326505 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 17:02:53.327503 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:02:53.328500 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cfeaecaf65e4ab8a2829175c0f0ec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:03:03.206413 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 17:03:03.207409 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:03:03.208409 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:03:03.208409 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:03:03.209403 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:03:03.210401 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:03:03.210401 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:03:03.211398 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 17:03:03.212396 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:03:03.213393 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:03:06.897585 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.60it/s]\n",
      "I0120 17:03:11.430284 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:03:11.692497 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 17:03:11.693495 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:03:11.694491 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a62bd386584ea598b9ee25ba1ce49a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:03:21.475317 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 17:03:21.476312 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:03:21.476312 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:03:21.477312 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:03:21.477312 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:03:21.478308 15348 fine_tuned.py:368]   tn = 306\n",
      "I0120 17:03:21.479305 15348 fine_tuned.py:368]   tp = 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:03:22.333615 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:03:22.334613 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:03:22.397448 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:03:22.398446 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:03:22.400440 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf857c8bcc66414b8e0b017e25c11afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [306 104]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       694\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 104  TN_H 306  TP_M 896  TN_M 692  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [316 104]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       684\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 104  TN_H 316  TP_M 896  TN_M 682  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [326 104]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       674\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 104  TN_H 326  TP_M 896  TN_M 672  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [336 104]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       664\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 104  TN_H 336  TP_M 896  TN_M 662  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [346 104]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       654\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 104  TN_H 346  TP_M 896  TN_M 652  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [356 104]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 104  TN_H 356  TP_M 896  TN_M 642  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [366 104]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       634\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 104  TN_H 366  TP_M 896  TN_M 632  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [376 104]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       624\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 104  TN_H 376  TP_M 896  TN_M 622  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [386 104]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       614\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 104  TN_H 386  TP_M 896  TN_M 612  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [396 104]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       604\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 104  TN_H 396  TP_M 896  TN_M 602  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [406 104]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       594\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 104  TN_H 406  TP_M 896  TN_M 592  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [416 104]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       584\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 104  TN_H 416  TP_M 896  TN_M 582  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [426 104]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       574\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 104  TN_H 426  TP_M 896  TN_M 572  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [436 104]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       564\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 104  TN_H 436  TP_M 896  TN_M 562  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [446 104]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       554\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 104  TN_H 446  TP_M 896  TN_M 552  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [456 104]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       544\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 104  TN_H 456  TP_M 896  TN_M 542  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [466 104]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       534\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 104  TN_H 466  TP_M 896  TN_M 532  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [476 104]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       524\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 104  TN_H 476  TP_M 896  TN_M 522  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [486 104]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       514\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 104  TN_H 486  TP_M 896  TN_M 512  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [496 104]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       504\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 104  TN_H 496  TP_M 896  TN_M 502  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:04:49.774531 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 17:04:49.775527 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:04:50.713513 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:04:50.714511 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:04:50.777343 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:04:50.780335 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:04:50.781332 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 17:04:54.070784 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 125.57it/s]\n",
      "I0120 17:04:59.268757 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:04:59.641366 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 17:04:59.642364 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 17:04:59.642364 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 17:04:59.643362 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 17:04:59.643362 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 17:04:59.644359 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ef3ca0bebd4a0d9029bcc747d19736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:02<14:34, 62.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d93e3f05e4f4ce9902a2e770ff5a6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:06:22.861590 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 17:06:24.163403 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 17:06:24.164400 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:06<13:38, 62.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4f3f7cc7bb4a35a172bc45d8aac97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:07:46.735907 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 17:07:47.973716 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 17:07:47.974714 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:10<12:38, 63.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84d67bce39648b185cbd247134f6106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:09:11.515070 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 17:09:12.755810 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 17:09:12.756807 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:14<11:37, 63.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac04367bdf446ad881f2f98db03f2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:17<10:33, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8cafc9676249ca99cbcd2c21110735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:10:36.271325 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 17:10:37.555796 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 17:10:37.556777 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:21<09:32, 63.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c208ad9cf874de181a60094444df6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:12:01.510904 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 17:12:02.793108 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 17:12:02.793108 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:25<08:30, 63.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f14ad502914c96957ae0fa1538ea55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:13:25.715823 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 17:13:26.918703 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 17:13:26.919724 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:29<07:26, 63.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d9233b0f3041df9cfa9a3e312445ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:32<06:21, 63.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3a818f0df743fcad692871d3473d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:14:50.205734 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 17:14:51.564930 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 17:14:51.565928 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:36<05:18, 63.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0837cea56684ac486bb399471546421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:16:14.334805 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 17:16:15.594241 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 17:16:15.594241 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:39<04:14, 63.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9710c48ccbe4467da77c7ef5698537e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:17:38.835269 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 17:17:40.037075 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 17:17:40.038072 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:43<03:11, 63.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6a6c0d52cd4ba4bf9ec5cebd2f95c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:47<02:07, 63.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7528537adbc94faf8e9b9956e56549b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:19:03.988446 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 17:19:05.200249 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 17:19:05.200249 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:51<01:03, 63.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189bf564ea9b4540a0acd5d9a6fc3a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:20:28.458885 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 17:20:29.748090 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 17:20:29.749087 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [15:55<00:00, 63.68s/it]\n",
      "I0120 17:20:54.905645 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.007814419756527819\n",
      "I0120 17:20:54.910630 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 17:20:54.910630 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:20:54.911628 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:20:54.912626 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:20:58.265672 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:07<00:00, 86.14it/s]\n",
      "I0120 17:21:06.205087 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:21:06.621987 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 17:21:06.622984 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:21:06.622984 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac963e17779a4458a04c29bf2333e888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:21:21.223617 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 17:21:21.224614 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:21:21.224614 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:21:21.225612 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:21:21.225612 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:21:21.226609 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:21:21.226609 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:21:21.227606 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 17:21:21.228629 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:21:21.228629 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:21:24.699568 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 89.06it/s]\n",
      "I0120 17:21:32.194154 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:21:32.581136 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 17:21:32.582134 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:21:32.582134 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3975d7b3ba4fb8954595f8cc7dba7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:21:47.219780 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 17:21:47.220777 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:21:47.220777 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:21:47.220777 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:21:47.221774 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:21:47.221774 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:21:47.222771 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:21:47.223769 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 17:21:47.224766 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:21:47.224766 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:21:50.653426 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:07<00:00, 86.38it/s]\n",
      "I0120 17:21:58.085096 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:21:58.500953 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 17:21:58.501951 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:21:58.501951 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3df081a2014c9cb5dc82c84cfead2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:22:13.115855 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 17:22:13.115855 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:22:13.116852 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:22:13.116852 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:22:13.117850 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:22:13.117850 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:22:13.118848 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:22:13.119844 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 17:22:13.119844 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:22:13.120842 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:22:16.760714 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 92.98it/s]\n",
      "I0120 17:22:23.989025 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:22:24.425828 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 17:22:24.426826 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:22:24.427823 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc153720f9554443b8f5e60e80b5fdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:22:39.027945 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 17:22:39.028942 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:22:39.028942 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:22:39.028942 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:22:39.029939 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:22:39.029939 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:22:39.030937 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:22:39.030937 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 17:22:39.031934 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:22:39.032931 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:22:42.618266 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 92.91it/s]\n",
      "I0120 17:22:49.730151 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:22:50.160001 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 17:22:50.161000 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:22:50.161997 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc33c7875d864102982e089f0323a366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:23:04.887815 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 17:23:04.888813 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:23:04.888813 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:23:04.889809 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:23:04.889809 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:23:04.890807 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:23:04.890807 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:23:04.891804 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 17:23:04.892802 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:23:04.892802 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:23:08.497554 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 91.50it/s]\n",
      "I0120 17:23:15.496064 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:23:15.902650 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 17:23:15.903647 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:23:15.904644 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6171d2d4acef4cb48b4761c238606c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:23:30.558111 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 17:23:30.559109 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:23:30.560105 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:23:30.560105 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:23:30.560105 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:23:30.561103 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:23:30.561103 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:23:30.562100 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 17:23:30.563097 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:23:30.564095 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:23:34.289399 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 93.59it/s]\n",
      "I0120 17:23:41.574465 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:23:41.930513 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 17:23:41.931511 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:23:41.932508 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2713f6587c0f4deaac80a9896952749c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:23:56.577805 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 17:23:56.578802 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:23:56.578802 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:23:56.579800 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:23:56.579800 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:23:56.580797 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:23:56.580797 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:23:56.581794 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 17:23:56.582792 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:23:56.583791 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:24:00.576775 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 105.86it/s]\n",
      "I0120 17:24:06.758743 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:24:07.147550 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 17:24:07.148520 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:24:07.148520 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5a4361ed574cf4bcef5b2de14e77c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:24:21.771996 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 17:24:21.772994 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:24:21.773991 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:24:21.773991 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:24:21.773991 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:24:21.774989 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:24:21.774989 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:24:21.775985 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 17:24:21.776983 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:24:21.776983 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:24:25.835103 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 108.18it/s]\n",
      "I0120 17:24:31.878945 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:24:32.285855 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 17:24:32.286852 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:24:32.286852 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b714cbb21bda47d19b0a5da0b595d903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:24:46.955528 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 17:24:46.956526 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:24:46.957523 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:24:46.957523 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:24:46.958520 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:24:46.958520 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:24:46.959516 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:24:46.960515 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 17:24:46.961512 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:24:46.962510 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:24:51.292754 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 111.78it/s]\n",
      "I0120 17:24:57.610949 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:24:58.022593 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 17:24:58.023563 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:24:58.023563 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb1f975db94428aaaa4313c66d71abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:25:12.539979 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 17:25:12.540950 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:25:12.541946 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:25:12.541946 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:25:12.541946 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:25:12.542943 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:25:12.542943 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:25:12.543941 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 17:25:12.544939 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:25:12.544939 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:25:17.091147 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 127.13it/s]\n",
      "I0120 17:25:22.342323 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:25:22.781292 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 17:25:22.782289 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:25:22.782289 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cd1db6dd7a405bbcee8967767d3677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:25:37.425468 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 17:25:37.426465 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:25:37.427463 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:25:37.428460 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:25:37.429457 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:25:37.429457 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:25:37.429457 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:25:37.430455 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 17:25:37.431452 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:25:37.432449 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:25:40.715241 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 126.53it/s]\n",
      "I0120 17:25:45.834353 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:25:46.213029 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 17:25:46.214028 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 17:25:46.214028 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191a27964f6f449a9c1504903c6592a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:26:00.729986 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 17:26:00.730984 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:26:00.732979 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:26:00.732979 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:26:00.733975 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:26:00.733975 15348 fine_tuned.py:368]   tn = 506\n",
      "I0120 17:26:00.734974 15348 fine_tuned.py:368]   tp = 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:26:01.482092 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:26:01.483086 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:26:01.544893 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:26:01.545891 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:26:01.546888 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e7063f3365477eade97a2029412c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [506 104]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       494\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 104  TN_H 506  TP_M 896  TN_M 492  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [516 104]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       484\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 104  TN_H 516  TP_M 896  TN_M 482  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [526 104]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       474\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 104  TN_H 526  TP_M 896  TN_M 472  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [536 104]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       464\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 104  TN_H 536  TP_M 896  TN_M 462  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [546 104]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       454\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 104  TN_H 546  TP_M 896  TN_M 452  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [556 104]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       444\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 104  TN_H 556  TP_M 896  TN_M 442  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [566 104]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       434\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 104  TN_H 566  TP_M 896  TN_M 432  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [576 104]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       424\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 104  TN_H 576  TP_M 896  TN_M 422  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [586 104]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       414\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 104  TN_H 586  TP_M 896  TN_M 412  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [596 104]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       404\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 104  TN_H 596  TP_M 896  TN_M 402  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [606 104]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       394\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 104  TN_H 606  TP_M 896  TN_M 392  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [616 104]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       384\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 104  TN_H 616  TP_M 896  TN_M 382  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [626 104]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       374\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 104  TN_H 626  TP_M 896  TN_M 372  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [636 104]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       364\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 104  TN_H 636  TP_M 896  TN_M 362  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [646 104]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       354\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 104  TN_H 646  TP_M 896  TN_M 352  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [656 104]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       344\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 104  TN_H 656  TP_M 896  TN_M 342  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [666 104]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       334\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 104  TN_H 666  TP_M 896  TN_M 332  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [676 104]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       324\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 104  TN_H 676  TP_M 896  TN_M 322  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [686 104]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       314\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 104  TN_H 686  TP_M 896  TN_M 312  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [696 104]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       304\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 104  TN_H 696  TP_M 896  TN_M 302  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [706 104]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       294\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 104  TN_H 706  TP_M 896  TN_M 292  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [716 104]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       284\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 104  TN_H 716  TP_M 896  TN_M 282  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [726 104]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       274\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 104  TN_H 726  TP_M 896  TN_M 272  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [736 104]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       264\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 104  TN_H 736  TP_M 896  TN_M 262  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [746 104]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       254\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 104  TN_H 746  TP_M 896  TN_M 252  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [756 104]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       244\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 104  TN_H 756  TP_M 896  TN_M 242  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [766 104]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       234\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 104  TN_H 766  TP_M 896  TN_M 232  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [776 104]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       224\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 104  TN_H 776  TP_M 896  TN_M 222  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [786 104]\n",
      "Number of training examples  890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       214\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 104  TN_H 786  TP_M 896  TN_M 212  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [796 104]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       204\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 104  TN_H 796  TP_M 896  TN_M 202  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [806 104]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       194\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      0.99      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 104  TN_H 806  TP_M 896  TN_M 192  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [816 104]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       184\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      0.99      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 104  TN_H 816  TP_M 896  TN_M 182  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [826 104]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       174\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      0.99      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 104  TN_H 826  TP_M 896  TN_M 172  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [836 104]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       164\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      0.99      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 104  TN_H 836  TP_M 896  TN_M 162  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [846 104]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       154\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      0.99      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 104  TN_H 846  TP_M 896  TN_M 152  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [856 104]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       144\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      0.99      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 104  TN_H 856  TP_M 896  TN_M 142  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [866 104]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       134\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      0.99      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 104  TN_H 866  TP_M 896  TN_M 132  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [876 104]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       124\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      0.99      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 104  TN_H 876  TP_M 896  TN_M 122  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [886 104]\n",
      "Number of training examples  990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       114\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 104  TN_H 886  TP_M 896  TN_M 112  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [896 104]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       104\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 104  TN_H 896  TP_M 896  TN_M 102  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [776, 904, 734, 674, 845, 1954, 1051, 1031, 1357, 1712]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       995\n",
      "           1       0.87      0.86      0.86       995\n",
      "\n",
      "    accuracy                           0.86      1990\n",
      "   macro avg       0.86      0.86      0.86      1990\n",
      "weighted avg       0.86      0.86      0.86      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 857  TN_M 864  FP_M 131  FN_M 138\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [12  8]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       988\n",
      "           1       0.95      0.90      0.92       992\n",
      "\n",
      "    accuracy                           0.93      1980\n",
      "   macro avg       0.93      0.93      0.93      1980\n",
      "weighted avg       0.93      0.93      0.93      1980\n",
      "\n",
      "TP_H 8  TN_H 12  TP_M 892  TN_M 942  FP_M 46  FN_M 100\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [15 15]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       985\n",
      "           1       0.99      0.84      0.90       985\n",
      "\n",
      "    accuracy                           0.91      1970\n",
      "   macro avg       0.92      0.91      0.91      1970\n",
      "weighted avg       0.92      0.91      0.91      1970\n",
      "\n",
      "TP_H 15  TN_H 15  TP_M 824  TN_M 973  FP_M 12  FN_M 161\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [16 24]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       984\n",
      "           1       0.98      0.94      0.96       976\n",
      "\n",
      "    accuracy                           0.96      1960\n",
      "   macro avg       0.96      0.96      0.96      1960\n",
      "weighted avg       0.96      0.96      0.96      1960\n",
      "\n",
      "TP_H 24  TN_H 16  TP_M 916  TN_M 970  FP_M 14  FN_M 60\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [18 32]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       982\n",
      "           1       0.99      0.98      0.98       968\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 32  TN_H 18  TP_M 947  TN_M 972  FP_M 10  FN_M 21\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [19 41]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       981\n",
      "           1       0.98      0.96      0.97       959\n",
      "\n",
      "    accuracy                           0.97      1940\n",
      "   macro avg       0.97      0.97      0.97      1940\n",
      "weighted avg       0.97      0.97      0.97      1940\n",
      "\n",
      "TP_H 41  TN_H 19  TP_M 921  TN_M 961  FP_M 20  FN_M 38\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [24 46]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       976\n",
      "           1       0.95      0.99      0.97       954\n",
      "\n",
      "    accuracy                           0.97      1930\n",
      "   macro avg       0.97      0.97      0.97      1930\n",
      "weighted avg       0.97      0.97      0.97      1930\n",
      "\n",
      "TP_H 46  TN_H 24  TP_M 940  TN_M 925  FP_M 51  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [33 47]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       967\n",
      "           1       0.99      0.97      0.98       953\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 47  TN_H 33  TP_M 927  TN_M 955  FP_M 12  FN_M 26\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [35 55]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       965\n",
      "           1       0.96      0.99      0.97       945\n",
      "\n",
      "    accuracy                           0.97      1910\n",
      "   macro avg       0.97      0.97      0.97      1910\n",
      "weighted avg       0.97      0.97      0.97      1910\n",
      "\n",
      "TP_H 55  TN_H 35  TP_M 933  TN_M 926  FP_M 39  FN_M 12\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [43 57]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       957\n",
      "           1       0.94      1.00      0.97       943\n",
      "\n",
      "    accuracy                           0.97      1900\n",
      "   macro avg       0.97      0.97      0.97      1900\n",
      "weighted avg       0.97      0.97      0.97      1900\n",
      "\n",
      "TP_H 57  TN_H 43  TP_M 940  TN_M 900  FP_M 57  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [53 57]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       947\n",
      "           1       0.99      0.98      0.99       943\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 57  TN_H 53  TP_M 927  TN_M 936  FP_M 11  FN_M 16\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [58 62]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       942\n",
      "           1       0.99      0.99      0.99       938\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 62  TN_H 58  TP_M 924  TN_M 932  FP_M 10  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [63 67]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       937\n",
      "           1       0.99      0.99      0.99       933\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 67  TN_H 63  TP_M 923  TN_M 929  FP_M 8  FN_M 10\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [69 71]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       931\n",
      "           1       0.99      0.99      0.99       929\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 71  TN_H 69  TP_M 922  TN_M 926  FP_M 5  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [75 75]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       925\n",
      "           1       0.99      0.99      0.99       925\n",
      "\n",
      "    accuracy                           0.99      1850\n",
      "   macro avg       0.99      0.99      0.99      1850\n",
      "weighted avg       0.99      0.99      0.99      1850\n",
      "\n",
      "TP_H 75  TN_H 75  TP_M 920  TN_M 920  FP_M 5  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [82 78]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       918\n",
      "           1       0.99      0.99      0.99       922\n",
      "\n",
      "    accuracy                           0.99      1840\n",
      "   macro avg       0.99      0.99      0.99      1840\n",
      "weighted avg       0.99      0.99      0.99      1840\n",
      "\n",
      "TP_H 78  TN_H 82  TP_M 917  TN_M 913  FP_M 5  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [86 84]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       914\n",
      "           1       1.00      0.99      1.00       916\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 84  TN_H 86  TP_M 911  TN_M 910  FP_M 4  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [92 88]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       908\n",
      "           1       1.00      1.00      1.00       912\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 88  TN_H 92  TP_M 908  TN_M 905  FP_M 3  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [100  90]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       900\n",
      "           1       1.00      1.00      1.00       910\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 90  TN_H 100  TP_M 906  TN_M 898  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [103  97]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       897\n",
      "           1       1.00      1.00      1.00       903\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 97  TN_H 103  TP_M 899  TN_M 895  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:27:40.274713 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 17:27:40.276708 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:27:41.101007 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:27:41.102005 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:27:41.533645 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 17:27:41.535639 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:27:41.910636 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 17:27:44.860643 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 17:27:44.862636 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 17:27:45.055448 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.67it/s]\n",
      "I0120 17:27:48.866414 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:27:49.012051 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 17:27:49.013064 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 17:27:49.013064 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 17:27:49.013064 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 17:27:49.014026 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 17:27:49.014026 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac9c1632b84a99aaa55f1d7f2de25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.886979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:21<05:07, 21.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c320d22b53a34e3fb6e2749023c65b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.678942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:28:18.009927 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 17:28:19.348352 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 17:28:19.349349 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:45<04:50, 22.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cb58557d8a45749923c2c0ccf63312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:28:48.441329 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 17:28:49.679528 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 17:28:49.680525 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041400"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:08<04:31, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c03ca3aa314141a406a659e200ffe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:29:18.532114 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 17:29:19.695616 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 17:29:19.696613 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:31<04:09, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b11bdbca0d44b696175defb6079c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:53<03:43, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf93705ca9b4844bc3a038831500f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:29:48.200940 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 17:29:49.445580 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 17:29:49.446578 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:15<03:22, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d3f673470d40a1b745e8aeff770ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:30:17.898023 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 17:30:19.195933 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 17:30:19.195933 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:38<03:01, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79348eb048945c189ed950f2267dc78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:30:47.971553 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 17:30:49.282485 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 17:30:49.282485 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:01<02:39, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c71a096a104caea265a7a74f0f74ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:23<02:13, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90a3ce3cda5464c8f774357c95bca73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:31:17.340047 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 17:31:18.746703 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 17:31:18.747703 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:45<01:52, 22.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa51f787b154e03a0eb7a0548439e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:31:46.970499 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 17:31:48.164273 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 17:31:48.165271 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:08<01:29, 22.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85920048d2ad4b6f89f3d91461b02a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:32:16.664875 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 17:32:17.960780 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 17:32:17.961777 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000293"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:31<01:07, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cd9cce1d324b6cb0ebc12358bebf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:53<00:44, 22.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374d5f37945d41a08d243f210b0510c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000398"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:32:46.581798 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 17:32:47.903999 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 17:32:47.903999 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:15<00:22, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02381ca9850743308612f296b400f0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000264"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:16.107074 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 17:33:17.470945 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 17:33:17.470945 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:38<00:00, 22.56s/it]\n",
      "I0120 17:33:27.381761 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.13796524325819134\n",
      "I0120 17:33:27.385750 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 17:33:27.387745 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 17:33:27.388741 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:33:27.388741 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:30.955878 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.27it/s]\n",
      "I0120 17:33:34.876231 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:33:35.007669 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 17:33:35.007669 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:33:35.008666 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ef65c7c9344dcfa21f055b9b475e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:40.207302 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 17:33:40.208301 15348 fine_tuned.py:368]   acc = 0.9238095238095239\n",
      "I0120 17:33:40.209298 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 17:33:40.209298 15348 fine_tuned.py:368]   fp = 15\n",
      "I0120 17:33:40.210295 15348 fine_tuned.py:368]   mcc = 0.8552554095095972\n",
      "I0120 17:33:40.210295 15348 fine_tuned.py:368]   tn = 90\n",
      "I0120 17:33:40.211293 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:33:40.212290 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 17:33:40.212290 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:33:40.213286 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:43.677574 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 54.49it/s]\n",
      "I0120 17:33:48.255980 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:33:48.411563 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 17:33:48.411563 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:33:48.412561 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253b6e4567b649239136fc696f8b5451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:53.539723 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 17:33:53.540720 15348 fine_tuned.py:368]   acc = 0.9857142857142858\n",
      "I0120 17:33:53.540720 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 17:33:53.541718 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 17:33:53.541718 15348 fine_tuned.py:368]   mcc = 0.9714726301433106\n",
      "I0120 17:33:53.542714 15348 fine_tuned.py:368]   tn = 103\n",
      "I0120 17:33:53.542714 15348 fine_tuned.py:368]   tp = 104\n",
      "I0120 17:33:53.543712 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 17:33:53.544709 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:33:53.544709 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:33:56.986798 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.96it/s]\n",
      "I0120 17:34:00.793082 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:34:00.923734 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 17:34:00.923734 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:34:00.924731 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d79fd806504a94b19df3603f86ec67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:06.101716 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 17:34:06.102714 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 17:34:06.102714 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:34:06.102714 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 17:34:06.103712 15348 fine_tuned.py:368]   mcc = 0.9905211130872972\n",
      "I0120 17:34:06.104709 15348 fine_tuned.py:368]   tn = 104\n",
      "I0120 17:34:06.104709 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:34:06.105706 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 17:34:06.106703 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:34:06.107701 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:09.439964 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 62.36it/s]\n",
      "I0120 17:34:13.640448 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:34:13.775058 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 17:34:13.776055 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:34:13.776055 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df283653a47c46f490542b8faf7902ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:18.912839 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 17:34:18.913836 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:34:18.913836 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:34:18.914833 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:34:18.914833 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:34:18.915830 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:34:18.915830 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:34:18.916827 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 17:34:18.916827 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:34:18.917826 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:22.280426 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.15it/s]\n",
      "I0120 17:34:26.574061 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:34:26.731218 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 17:34:26.731218 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:34:26.732215 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d2ede4545a484e8c9c634e0c6ee762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:31.942934 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 17:34:31.943933 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:34:31.944929 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:34:31.944929 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:34:31.945926 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:34:31.945926 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:34:31.946924 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:34:31.947922 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 17:34:31.947922 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:34:31.948918 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:35.149367 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.86it/s]\n",
      "I0120 17:34:38.845136 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:34:38.989747 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 17:34:38.989747 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:34:38.990747 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f9a055fb9647d1a847ed2661d55a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:44.150671 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 17:34:44.151668 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:34:44.152666 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:34:44.152666 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:34:44.152666 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:34:44.153663 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:34:44.153663 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:34:44.154661 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 17:34:44.155658 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:34:44.156656 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:47.469929 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.03it/s]\n",
      "I0120 17:34:51.759128 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:34:51.895273 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 17:34:51.895273 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:34:51.896270 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4df425c38048b687668110681f958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:34:57.039238 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 17:34:57.040235 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:34:57.040235 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:34:57.041233 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:34:57.042230 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:34:57.042230 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:34:57.043227 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:34:57.044224 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 17:34:57.044224 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:34:57.045222 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:00.333640 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.81it/s]\n",
      "I0120 17:35:04.636996 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:35:04.750693 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 17:35:04.751690 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:35:04.752688 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58469c281c5f4e8aac685027edb047d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:09.922431 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 17:35:09.923428 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:35:09.924426 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:35:09.924426 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:35:09.925423 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:35:09.925423 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:35:09.925423 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:35:09.926420 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 17:35:09.927417 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:35:09.927417 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:13.203266 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.90it/s]\n",
      "I0120 17:35:16.992373 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:35:17.116072 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 17:35:17.116072 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:35:17.117070 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48ae55233704c239ffd8319f3ce7f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:22.289580 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 17:35:22.291574 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:35:22.291574 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:35:22.291574 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:35:22.292571 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:35:22.292571 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:35:22.292571 15348 fine_tuned.py:368]   tp = 105\n",
      "I0120 17:35:22.293570 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 17:35:22.294567 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:35:22.295564 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:25.695773 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 61.24it/s]\n",
      "I0120 17:35:29.491533 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:35:29.608220 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 17:35:29.608220 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:35:29.609245 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4174e4e40a2049a894de6f052843cb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:34.705222 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 17:35:34.705222 15348 fine_tuned.py:368]   acc = 0.5238095238095238\n",
      "I0120 17:35:34.706220 15348 fine_tuned.py:368]   fn = 100\n",
      "I0120 17:35:34.706220 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:35:34.707218 15348 fine_tuned.py:368]   mcc = 0.15617376188860607\n",
      "I0120 17:35:34.707218 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:35:34.708215 15348 fine_tuned.py:368]   tp = 5\n",
      "I0120 17:35:34.709212 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 17:35:34.710210 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:35:34.710210 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:37.928225 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.11it/s]\n",
      "I0120 17:35:42.323383 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:35:42.468994 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 17:35:42.469991 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 17:35:42.469991 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc72d5f390da4865840292f652a9b192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:47.492308 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 17:35:47.492308 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:35:47.493305 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:35:47.494302 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:35:47.494302 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:35:47.495300 15348 fine_tuned.py:368]   tn = 105\n",
      "I0120 17:35:47.495300 15348 fine_tuned.py:368]   tp = 105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:35:48.291599 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:35:48.293594 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:35:48.400308 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 17:35:48.401306 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:35:48.402303 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d78181e1544ca58d8895502d52c122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [105 105]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       895\n",
      "           1       1.00      1.00      1.00       895\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 105  TN_H 105  TP_M 892  TN_M 893  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [110 110]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       890\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 110  TN_H 110  TP_M 889  TN_M 888  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [120 110]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       880\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 110  TN_H 120  TP_M 889  TN_M 878  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [126 114]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       874\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 114  TN_H 126  TP_M 885  TN_M 872  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [135 115]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       865\n",
      "           1       1.00      1.00      1.00       885\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 115  TN_H 135  TP_M 884  TN_M 863  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [144 116]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       856\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 116  TN_H 144  TP_M 884  TN_M 854  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [154 116]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       846\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 116  TN_H 154  TP_M 884  TN_M 844  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [164 116]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       836\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 116  TN_H 164  TP_M 884  TN_M 834  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [174 116]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       826\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 116  TN_H 174  TP_M 884  TN_M 824  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [184 116]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       816\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 116  TN_H 184  TP_M 884  TN_M 814  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [194 116]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       806\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 116  TN_H 194  TP_M 884  TN_M 804  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [204 116]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       796\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 116  TN_H 204  TP_M 884  TN_M 794  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [214 116]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       786\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 116  TN_H 214  TP_M 884  TN_M 784  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [224 116]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       776\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 116  TN_H 224  TP_M 884  TN_M 774  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [234 116]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       766\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 116  TN_H 234  TP_M 884  TN_M 764  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [244 116]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       756\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 116  TN_H 244  TP_M 884  TN_M 754  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [254 116]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       746\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 116  TN_H 254  TP_M 884  TN_M 744  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [264 116]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       736\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 116  TN_H 264  TP_M 884  TN_M 734  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [273 117]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       883\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 117  TN_H 273  TP_M 883  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [283 117]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       717\n",
      "           1       1.00      1.00      1.00       883\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 117  TN_H 283  TP_M 883  TN_M 715  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:37:14.312524 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 17:37:14.313521 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:37:15.055045 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:37:15.056043 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:37:15.121904 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 17:37:15.122888 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:37:15.123862 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 17:37:18.312328 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 98.35it/s]\n",
      "I0120 17:37:23.224198 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:37:23.489491 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 17:37:23.489491 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 17:37:23.489491 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 17:37:23.490489 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 17:37:23.490489 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 17:37:23.491486 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d067fca52514a939b81f8ef143e0c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:41<09:47, 41.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7c0250241f44958df7bb176ee8ce9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:38:18.587915 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 17:38:19.882278 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 17:38:19.883274 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:24<09:08, 42.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72923778611426aa12698141c6b64ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:39:15.276637 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 17:39:16.499564 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 17:39:16.500563 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:07<08:29, 42.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aec262905343469f16b0167a5f0e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:40:12.119078 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 17:40:13.438366 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 17:40:13.439364 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:51<07:50, 42.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69b84a8ca194bcdb521f158e6f439fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:32<07:03, 42.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e242ca778449b0ab9e002ee92f2405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:41:08.192344 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 17:41:09.560239 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 17:41:09.561236 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:15<06:22, 42.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d531267906d4722b136a917ce23b502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:42:04.000909 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 17:42:05.269932 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 17:42:05.270929 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [04:58<05:40, 42.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c616763df74cfa856348e1edfd5841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:43:01.027423 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 17:43:02.357088 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 17:43:02.358112 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:42<05:00, 42.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece913962711479ea6281597fda790d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:24<04:16, 42.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568d6a6dd57b469e9dae791baecf8a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:43:58.487136 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 17:43:59.798023 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 17:43:59.799020 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:08<03:34, 42.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217cd014f8f64b509a1208d4f7d97f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:44:55.416882 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 17:44:57.086052 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 17:44:57.087049 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:51<02:52, 43.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb73f57ccdaf4749b8037d81cdada257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:45:52.470340 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 17:45:53.816655 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 17:45:53.817652 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:35<02:09, 43.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcca506d1d84259b48f280e24a5f4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:16<01:25, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfdef14312f4b3eb48803d0685a374c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:46:48.783864 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 17:46:50.124416 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 17:46:50.125413 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [09:59<00:42, 42.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0246073839bf45a98b979d544dfc58aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:47:45.638986 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 17:47:46.998388 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 17:47:46.999386 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:43<00:00, 42.88s/it]\n",
      "I0120 17:48:06.692594 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.007670048862985037\n",
      "I0120 17:48:06.696584 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-350', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 17:48:06.697581 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 17:48:06.697581 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:48:06.698578 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:48:09.880333 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.11it/s]\n",
      "I0120 17:48:14.600617 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:48:15.003338 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 17:48:15.004334 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:48:15.004334 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7773334ca34cd1845a89cef44c36d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:48:24.953353 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 17:48:24.953353 15348 fine_tuned.py:368]   acc = 0.9926829268292683\n",
      "I0120 17:48:24.954349 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 17:48:24.954349 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:48:24.955347 15348 fine_tuned.py:368]   mcc = 0.9820813176533368\n",
      "I0120 17:48:24.955347 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:48:24.956344 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 17:48:24.957345 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:48:24.958339 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:48:24.958339 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:48:28.199999 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.88it/s]\n",
      "I0120 17:48:32.913478 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:48:33.190779 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 17:48:33.192775 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:48:33.192775 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c12f75644b4daf9acfafaf3638428c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:48:43.221823 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 17:48:43.222821 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:48:43.222821 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:48:43.223818 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:48:43.223818 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:48:43.223818 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:48:43.224815 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:48:43.225811 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 17:48:43.226810 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:48:43.226810 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:48:46.466527 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 103.05it/s]\n",
      "I0120 17:48:51.177082 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:48:51.509925 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 17:48:51.510922 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:48:51.510922 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb744cfb00944a19d0a2d438288f64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:01.550367 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 17:49:01.551364 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:49:01.552362 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:49:01.552362 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:49:01.552362 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:49:01.553360 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:49:01.554358 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:49:01.555355 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 17:49:01.556353 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:49:01.556353 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:04.863496 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.05it/s]\n",
      "I0120 17:49:09.081412 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:49:09.357673 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 17:49:09.358670 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:49:09.359668 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382439adb7db4103adb7d2848654d3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:19.426637 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 17:49:19.427635 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:49:19.427635 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:49:19.428632 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:49:19.428632 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:49:19.429630 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:49:19.429630 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:49:19.430627 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 17:49:19.431624 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:49:19.432622 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:22.671904 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.00it/s]\n",
      "I0120 17:49:27.483027 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:49:27.761048 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 17:49:27.762044 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:49:27.762044 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbdce748d0b4622a59f55f86d911fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:37.774458 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 17:49:37.775455 15348 fine_tuned.py:368]   acc = 0.9926829268292683\n",
      "I0120 17:49:37.775455 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 17:49:37.776453 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:49:37.776453 15348 fine_tuned.py:368]   mcc = 0.9820813176533368\n",
      "I0120 17:49:37.777451 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:49:37.778448 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 17:49:37.779444 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 17:49:37.780442 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:49:37.780442 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:41.120559 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 102.40it/s]\n",
      "I0120 17:49:45.928407 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:49:46.166383 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 17:49:46.167382 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:49:46.168378 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34256cfa6e84a24aeae1463b82ec943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:56.245530 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 17:49:56.246527 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:49:56.246527 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:49:56.246527 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:49:56.247525 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:49:56.247525 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:49:56.248522 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:49:56.249520 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 17:49:56.250517 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:49:56.251516 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:49:59.929526 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.25it/s]\n",
      "I0120 17:50:04.758482 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:50:05.052694 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 17:50:05.052694 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:50:05.053719 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09146c5ada844f388bb7b321f1e319d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:15.135709 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 17:50:15.135709 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:50:15.136708 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:50:15.136708 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:50:15.137704 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:50:15.137704 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:50:15.137704 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:50:15.139698 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 17:50:15.140697 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:50:15.141694 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:18.499369 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.15it/s]\n",
      "I0120 17:50:23.309145 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:50:23.566964 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 17:50:23.567961 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:50:23.567961 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadd73391df745a0b474a832659f396c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:33.615212 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 17:50:33.615212 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:50:33.616209 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:50:33.616209 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:50:33.617206 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:50:33.617206 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:50:33.617206 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:50:33.618204 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 17:50:33.619201 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:50:33.620198 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:36.882484 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.19it/s]\n",
      "I0120 17:50:41.315143 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:50:41.578439 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 17:50:41.578439 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:50:41.579436 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b662c9016494e19882c50dbad770329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:51.647492 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 17:50:51.648490 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:50:51.649488 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:50:51.649488 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:50:51.649488 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:50:51.650485 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:50:51.650485 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:50:51.651482 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 17:50:51.652479 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:50:51.653478 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:50:54.899253 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 99.92it/s]\n",
      "I0120 17:50:59.811549 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:51:00.051906 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 17:51:00.051906 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:51:00.052903 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f2f67298dc44c684c0413d6e64b2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:10.108469 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 17:51:10.109467 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:51:10.109467 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:51:10.110465 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:51:10.110465 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:51:10.111461 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:51:10.111461 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:51:10.112460 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 17:51:10.113456 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:51:10.113456 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:13.336580 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.59it/s]\n",
      "I0120 17:51:18.132295 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:51:18.371654 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 17:51:18.372651 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:51:18.372651 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a037a1c139ac4d2eb09e859bbe732834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:28.424709 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 17:51:28.425707 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:51:28.426705 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:51:28.426705 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:51:28.427703 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:51:28.427703 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:51:28.428699 15348 fine_tuned.py:368]   tp = 117\n",
      "I0120 17:51:28.429697 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 17:51:28.430694 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:51:28.430694 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:31.716948 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 103.87it/s]\n",
      "I0120 17:51:36.517389 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:51:36.787079 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 17:51:36.788077 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 17:51:36.788077 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3858b6bd69b43b4a76eb146349cd69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:46.665428 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 17:51:46.666425 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 17:51:46.666425 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 17:51:46.667422 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 17:51:46.667422 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 17:51:46.668420 15348 fine_tuned.py:368]   tn = 293\n",
      "I0120 17:51:46.668420 15348 fine_tuned.py:368]   tp = 117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:51:47.674461 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:51:47.675458 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:51:47.748795 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:51:47.750762 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:51:47.750762 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262906156fb5431b9e051ead574cd561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [293 117]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       707\n",
      "           1       1.00      1.00      1.00       883\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 117  TN_H 293  TP_M 883  TN_M 705  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [302 118]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       698\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 118  TN_H 302  TP_M 882  TN_M 696  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [312 118]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       688\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 118  TN_H 312  TP_M 882  TN_M 686  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [322 118]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       678\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 118  TN_H 322  TP_M 882  TN_M 676  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [332 118]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       668\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 118  TN_H 332  TP_M 882  TN_M 666  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [342 118]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       658\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 118  TN_H 342  TP_M 882  TN_M 656  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [352 118]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       648\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 118  TN_H 352  TP_M 882  TN_M 646  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [362 118]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       638\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 118  TN_H 362  TP_M 882  TN_M 636  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [372 118]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       628\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 118  TN_H 372  TP_M 882  TN_M 626  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [382 118]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       618\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 118  TN_H 382  TP_M 882  TN_M 616  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [392 118]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       608\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 118  TN_H 392  TP_M 882  TN_M 606  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [402 118]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       598\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 118  TN_H 402  TP_M 882  TN_M 596  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [412 118]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       588\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 118  TN_H 412  TP_M 882  TN_M 586  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [422 118]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       578\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 118  TN_H 422  TP_M 882  TN_M 576  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [432 118]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       568\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 118  TN_H 432  TP_M 882  TN_M 566  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [442 118]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       558\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 118  TN_H 442  TP_M 882  TN_M 556  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [452 118]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       548\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 118  TN_H 452  TP_M 882  TN_M 546  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [462 118]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       538\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 118  TN_H 462  TP_M 882  TN_M 536  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [472 118]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       528\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 118  TN_H 472  TP_M 882  TN_M 526  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [482 118]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       518\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 118  TN_H 482  TP_M 882  TN_M 516  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:53:11.423515 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 17:53:11.425509 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:53:12.096731 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 17:53:12.097729 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 17:53:12.176517 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 17:53:12.179510 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 17:53:12.181505 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 17:53:16.146737 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.88it/s]\n",
      "I0120 17:53:21.367899 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 17:53:21.724461 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 17:53:21.725459 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 17:53:21.725459 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 17:53:21.726458 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 17:53:21.726458 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 17:53:21.727455 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244edfc0a3e74978816c65e5cf2784a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:02<14:38, 62.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6291425206434cc6b932f659d5dc8312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:54:44.998754 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 17:54:46.275233 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 17:54:46.276230 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:06<13:38, 62.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d130a10089fe494c93d223d2bc41e02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:56:08.032833 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 17:56:09.339501 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 17:56:09.340498 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:08<12:34, 62.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3762c8bd52334b9aa71b7114aab1cc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:57:30.722121 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 17:57:32.031350 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 17:57:32.032348 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:11<11:30, 62.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04597f2059344687a82b915f9f1010c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:12<10:23, 62.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbff5784d2a34f72bfe03f9c405fbba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 17:58:53.476819 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 17:58:54.715134 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 17:58:54.716132 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:15<09:20, 62.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fd827440f743beab13a11f79acdd13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:00:16.319871 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 18:00:17.556089 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 18:00:17.557112 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:18<08:21, 62.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a046f11d5d4542bf3541aab2f9f7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:01:40.915312 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 18:01:42.141110 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 18:01:42.142107 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:22<07:21, 63.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80366fd626c4122bc112641e6efc38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:24<06:16, 62.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec0cb3dd5824e228920820a9fce8a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:03:04.012435 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 18:03:05.254055 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 18:03:05.255053 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:28<05:15, 63.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a00a8de48c747828e3d7846850f6526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:04:28.629436 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 18:04:29.857521 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 18:04:29.858542 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:31<04:12, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18444f278bc94742a6ddc9ed27d989c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:05:51.559654 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 18:05:52.860182 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 18:05:52.861180 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:34<03:09, 63.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76e4f78716c46c2b98c6cb39f32b515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:35<02:05, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6357f7f53b6147ecbe7bc6c1d5225413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:07:14.186059 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 18:07:15.501283 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 18:07:15.501283 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:38<01:02, 62.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826601b024da4cfe8a527c40953feb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:08:36.642557 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 18:08:37.859542 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 18:08:37.860539 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [15:40<00:00, 62.72s/it]\n",
      "I0120 18:09:02.601137 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.009785863562347064\n",
      "I0120 18:09:02.605126 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 18:09:02.607121 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:09:02.609116 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:09:02.610114 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:09:06.368386 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.93it/s]\n",
      "I0120 18:09:11.753288 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:09:12.132500 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 18:09:12.133498 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:09:12.133498 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91932a51ec204b0cb2630196fb59b360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:09:26.730881 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 18:09:26.731911 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:09:26.732876 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:09:26.732876 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:09:26.732876 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:09:26.733873 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:09:26.733873 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:09:26.734872 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 18:09:26.735869 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:09:26.736866 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:09:31.005976 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.37it/s]\n",
      "I0120 18:09:35.930881 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:09:36.273757 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 18:09:36.274781 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:09:36.275751 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da9247e591242b2b1af1adf0e6cde3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:09:50.878772 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 18:09:50.880766 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:09:50.880766 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:09:50.881763 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:09:50.881763 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:09:50.882760 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:09:50.882760 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:09:50.883758 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 18:09:50.884756 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:09:50.885752 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:09:55.174027 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.52it/s]\n",
      "I0120 18:09:59.845135 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:10:00.229979 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 18:10:00.230957 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:10:00.230957 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a45f09045e499db86f2113f573383c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:10:14.882094 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 18:10:14.883091 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:10:14.884088 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:10:14.884088 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:10:14.885086 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:10:14.886083 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:10:14.887081 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:10:14.888078 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 18:10:14.889075 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:10:14.890073 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:10:19.029980 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.43it/s]\n",
      "I0120 18:10:23.611107 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:10:23.964669 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 18:10:23.964669 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:10:23.965666 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c8ee6645c4b2b987149a02599e54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:10:38.610308 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 18:10:38.612302 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:10:38.612302 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:10:38.613299 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:10:38.613299 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:10:38.614297 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:10:38.615294 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:10:38.616292 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 18:10:38.617289 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:10:38.618287 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:10:42.607576 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 139.06it/s]\n",
      "I0120 18:10:47.321228 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:10:47.662315 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 18:10:47.662315 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:10:47.663312 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1352148923c408682f3fbe459d8259a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:02.318475 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 18:11:02.320470 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:11:02.321468 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:11:02.322466 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:11:02.322466 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:11:02.323463 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:11:02.323463 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:11:02.324460 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 18:11:02.325457 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:11:02.326455 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:06.000831 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 137.56it/s]\n",
      "I0120 18:11:11.228494 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:11:11.582547 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 18:11:11.583544 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:11:11.584542 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208807f130684a4898da34a9b74eb14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:26.337574 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 18:11:26.338570 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:11:26.339567 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:11:26.339567 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:11:26.340565 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:11:26.341563 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:11:26.341563 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:11:26.342560 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 18:11:26.343557 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:11:26.344555 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:29.767673 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.89it/s]\n",
      "I0120 18:11:34.993339 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:11:35.382261 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 18:11:35.383281 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:11:35.383281 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70492b53a0c240f8a64ee7f105ffe577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:50.238020 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 18:11:50.240014 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:11:50.240014 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:11:50.241011 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:11:50.242007 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:11:50.242007 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:11:50.243006 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:11:50.244003 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 18:11:50.245002 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:11:50.245002 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:11:53.437714 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 138.33it/s]\n",
      "I0120 18:11:58.563535 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:11:58.895645 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 18:11:58.895645 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:11:58.896643 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e3b488f790417d9b9207435c3683eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:12:13.649757 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 18:12:13.650755 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:12:13.651751 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:12:13.651751 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:12:13.651751 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:12:13.652749 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:12:13.652749 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:12:13.653747 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 18:12:13.654744 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:12:13.655741 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:12:16.877369 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.34it/s]\n",
      "I0120 18:12:22.164588 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:12:22.516646 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 18:12:22.516646 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:12:22.517643 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f321fe3310c84cbe85ac2959061f5502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:12:37.421995 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 18:12:37.422993 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:12:37.422993 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:12:37.422993 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:12:37.423990 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:12:37.423990 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:12:37.424989 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:12:37.425986 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 18:12:37.425986 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:12:37.426983 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:12:40.563094 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.92it/s]\n",
      "I0120 18:12:45.442062 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:12:45.816620 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 18:12:45.817622 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:12:45.817622 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efcb4dcc2c04acd8e365dd03b26e063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:00.622018 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 18:13:00.623016 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:13:00.623016 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:13:00.624012 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:13:00.624012 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:13:00.625008 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:13:00.626007 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:13:00.627004 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 18:13:00.628001 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:13:00.628001 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:03.903036 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.42it/s]\n",
      "I0120 18:13:09.145306 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:13:09.487393 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 18:13:09.488390 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:13:09.489386 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146b7010773d4225b5eb2e13a6e0aedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:24.371361 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 18:13:24.372358 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:13:24.372358 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:13:24.373355 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:13:24.373355 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:13:24.373355 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:13:24.374352 15348 fine_tuned.py:368]   tp = 118\n",
      "I0120 18:13:24.374352 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 18:13:24.375349 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:13:24.376347 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:27.512717 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 127.46it/s]\n",
      "I0120 18:13:32.662688 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:13:33.031701 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 18:13:33.032698 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:13:33.032698 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4287c48ccd4d9cb67709ccf572ba77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:47.644516 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 18:13:47.645540 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:13:47.645540 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:13:47.646512 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:13:47.646512 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:13:47.647509 15348 fine_tuned.py:368]   tn = 492\n",
      "I0120 18:13:47.647509 15348 fine_tuned.py:368]   tp = 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:13:48.428271 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:13:48.429268 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:13:48.498084 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:13:48.499081 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:13:48.500082 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa0cc0b782648e682254e318ad2a95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [492 118]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 118  TN_H 492  TP_M 882  TN_M 506  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [502 118]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       498\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 118  TN_H 502  TP_M 882  TN_M 496  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [512 118]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       488\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 118  TN_H 512  TP_M 882  TN_M 486  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [522 118]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       478\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 118  TN_H 522  TP_M 882  TN_M 476  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [532 118]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       468\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 118  TN_H 532  TP_M 882  TN_M 466  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [542 118]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       458\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 118  TN_H 542  TP_M 882  TN_M 456  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [552 118]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       448\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 118  TN_H 552  TP_M 882  TN_M 446  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [562 118]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       438\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 118  TN_H 562  TP_M 882  TN_M 436  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [572 118]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       428\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 118  TN_H 572  TP_M 882  TN_M 426  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [582 118]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       418\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 118  TN_H 582  TP_M 882  TN_M 416  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [592 118]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       408\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 118  TN_H 592  TP_M 882  TN_M 406  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [602 118]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       398\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 118  TN_H 602  TP_M 882  TN_M 396  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [612 118]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       388\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 118  TN_H 612  TP_M 882  TN_M 386  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [622 118]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       378\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 118  TN_H 622  TP_M 882  TN_M 376  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [632 118]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       368\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 118  TN_H 632  TP_M 882  TN_M 366  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [642 118]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       358\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 118  TN_H 642  TP_M 882  TN_M 356  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [652 118]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       348\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 118  TN_H 652  TP_M 882  TN_M 346  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [662 118]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       338\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 118  TN_H 662  TP_M 882  TN_M 336  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [672 118]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       328\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 118  TN_H 672  TP_M 882  TN_M 326  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [682 118]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       318\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 118  TN_H 682  TP_M 882  TN_M 316  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [692 118]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       308\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 118  TN_H 692  TP_M 882  TN_M 306  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [702 118]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       298\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 118  TN_H 702  TP_M 882  TN_M 296  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [712 118]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       288\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 118  TN_H 712  TP_M 882  TN_M 286  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [722 118]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       278\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 118  TN_H 722  TP_M 882  TN_M 276  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [732 118]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       268\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 118  TN_H 732  TP_M 882  TN_M 266  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [742 118]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       258\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 118  TN_H 742  TP_M 882  TN_M 256  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [752 118]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       248\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 118  TN_H 752  TP_M 882  TN_M 246  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [762 118]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       238\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 118  TN_H 762  TP_M 882  TN_M 236  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [772 118]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       228\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 118  TN_H 772  TP_M 882  TN_M 226  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [782 118]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       218\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TP_H 118  TN_H 782  TP_M 882  TN_M 216  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [792 118]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       208\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 118  TN_H 792  TP_M 882  TN_M 206  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [802 118]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       198\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      0.99      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 118  TN_H 802  TP_M 882  TN_M 196  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [812 118]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       188\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      0.99      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 118  TN_H 812  TP_M 882  TN_M 186  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [822 118]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       178\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      0.99      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 118  TN_H 822  TP_M 882  TN_M 176  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [832 118]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       168\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      0.99      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 118  TN_H 832  TP_M 882  TN_M 166  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [842 118]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       158\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      0.99      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 118  TN_H 842  TP_M 882  TN_M 156  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [852 118]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       148\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      0.99      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 118  TN_H 852  TP_M 882  TN_M 146  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [862 118]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       138\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      0.99      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 118  TN_H 862  TP_M 882  TN_M 136  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [872 118]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       128\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 118  TN_H 872  TP_M 882  TN_M 126  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [882 118]\n",
      "Number of training examples  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       118\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 118  TN_H 882  TP_M 882  TN_M 116  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [752, 877, 977, 647, 241, 1061, 1384, 1678, 1370, 1767]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.85      0.80       995\n",
      "           1       0.83      0.73      0.78       995\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.79      0.79      0.79      1990\n",
      "weighted avg       0.79      0.79      0.79      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 726  TN_M 846  FP_M 149  FN_M 269\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [10 10]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       990\n",
      "           1       0.97      0.93      0.95       990\n",
      "\n",
      "    accuracy                           0.95      1980\n",
      "   macro avg       0.95      0.95      0.95      1980\n",
      "weighted avg       0.95      0.95      0.95      1980\n",
      "\n",
      "TP_H 10  TN_H 10  TP_M 916  TN_M 959  FP_M 31  FN_M 74\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [12 18]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       988\n",
      "           1       0.96      0.98      0.97       982\n",
      "\n",
      "    accuracy                           0.97      1970\n",
      "   macro avg       0.97      0.97      0.97      1970\n",
      "weighted avg       0.97      0.97      0.97      1970\n",
      "\n",
      "TP_H 18  TN_H 12  TP_M 964  TN_M 952  FP_M 36  FN_M 18\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [18 22]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       982\n",
      "           1       0.99      0.96      0.97       978\n",
      "\n",
      "    accuracy                           0.97      1960\n",
      "   macro avg       0.97      0.97      0.97      1960\n",
      "weighted avg       0.97      0.97      0.97      1960\n",
      "\n",
      "TP_H 22  TN_H 18  TP_M 938  TN_M 971  FP_M 11  FN_M 40\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [20 30]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       980\n",
      "           1       0.97      0.99      0.98       970\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 30  TN_H 20  TP_M 957  TN_M 955  FP_M 25  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [27 33]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       973\n",
      "           1       0.97      0.99      0.98       967\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 33  TN_H 27  TP_M 953  TN_M 943  FP_M 30  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [35 35]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       965\n",
      "           1       0.97      0.99      0.98       965\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "TP_H 35  TN_H 35  TP_M 954  TN_M 940  FP_M 25  FN_M 11\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [41 39]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       959\n",
      "           1       0.98      0.99      0.98       961\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 39  TN_H 41  TP_M 948  TN_M 943  FP_M 16  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [44 46]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       956\n",
      "           1       0.99      0.98      0.99       954\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 46  TN_H 44  TP_M 939  TN_M 945  FP_M 11  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [48 52]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       952\n",
      "           1       0.99      0.99      0.99       948\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 52  TN_H 48  TP_M 935  TN_M 945  FP_M 7  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [54 56]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       946\n",
      "           1       0.98      0.98      0.98       944\n",
      "\n",
      "    accuracy                           0.98      1890\n",
      "   macro avg       0.98      0.98      0.98      1890\n",
      "weighted avg       0.98      0.98      0.98      1890\n",
      "\n",
      "TP_H 56  TN_H 54  TP_M 928  TN_M 929  FP_M 17  FN_M 16\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [59 61]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       941\n",
      "           1       0.99      0.99      0.99       939\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 61  TN_H 59  TP_M 931  TN_M 930  FP_M 11  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [65 65]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       935\n",
      "           1       0.99      0.99      0.99       935\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 65  TN_H 65  TP_M 929  TN_M 926  FP_M 9  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [69 71]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       931\n",
      "           1       0.99      1.00      0.99       929\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 71  TN_H 69  TP_M 925  TN_M 924  FP_M 7  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [75 75]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       925\n",
      "           1       1.00      1.00      1.00       925\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 75  TN_H 75  TP_M 921  TN_M 922  FP_M 3  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [78 82]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       922\n",
      "           1       1.00      1.00      1.00       918\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 82  TN_H 78  TP_M 914  TN_M 920  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [80 90]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       920\n",
      "           1       1.00      1.00      1.00       910\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 90  TN_H 80  TP_M 906  TN_M 918  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [84 96]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       916\n",
      "           1       1.00      1.00      1.00       904\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 96  TN_H 84  TP_M 900  TN_M 914  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [92 98]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       908\n",
      "           1       1.00      1.00      1.00       902\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 98  TN_H 92  TP_M 898  TN_M 906  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [ 97 103]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       903\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 103  TN_H 97  TP_M 893  TN_M 901  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:15:27.367480 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 18:15:27.368486 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:15:28.109775 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:15:28.110767 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:15:28.534817 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 18:15:28.535814 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:15:28.924740 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 18:15:31.854156 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 18:15:31.855152 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 18:15:32.068486 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 55.41it/s]\n",
      "I0120 18:15:36.653828 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:15:36.837366 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 18:15:36.838362 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 18:15:36.838362 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 18:15:36.838362 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 18:15:36.839347 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 18:15:36.839347 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409d84331e1f4aeb806736c89cb58cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.723147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:21<05:07, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b9c0a09c4842349fc1aec9049cbaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.595381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:16:05.781424 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 18:16:07.310574 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 18:16:07.310574 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.642700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:45<04:49, 22.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0f68d976314695b6863d4929b137a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:16:35.969552 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 18:16:38.296549 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 18:16:38.296549 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.896043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:08<04:33, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538a0ba7602846e1829071e3eaeb1322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001266"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:17:06.290169 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 18:17:08.439771 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 18:17:08.440769 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:32<04:12, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc40662f94c47ce9864c596b9e3b72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:53<03:45, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dee0231f844dc0962357ac860043d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:17:36.674741 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 18:17:38.253181 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 18:17:38.254179 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:16<03:23, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d103b2e937c842239dba838458ab59aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:18:06.351311 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 18:18:07.576338 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 18:18:07.577294 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:38<03:00, 22.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de39f759f3b44a3aa041c756f0d295c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:18:35.632377 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 18:18:36.944912 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 18:18:36.944912 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:01<02:37, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4f0d6482540129114a3b76cba01a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:22<02:12, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42f2be84dfb4faa81e1f77a7a16f91d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:19:04.718408 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 18:19:06.018546 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 18:19:06.019512 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:45<01:51, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47695ad10ec4bf5a5a6026ea8e91ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:19:34.084619 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 18:19:35.427002 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 18:19:35.427999 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000184"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:07<01:29, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73b592ade6149f1918ae965c694995b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:20:03.133614 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 18:20:04.420802 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 18:20:04.421771 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:29<01:06, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9708e16fceb94d6cb064b3bdc6de5cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000287"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:51<00:43, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc35fb4bb9c447194827ffb2ac98af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:20:32.385473 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 18:20:33.616774 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 18:20:33.616774 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000602"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:13<00:22, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ada6850594a71bba3694413fe2fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:01.214808 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 18:21:02.505462 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 18:21:02.506459 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:35<00:00, 22.37s/it]\n",
      "I0120 18:21:12.367552 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.0948682429655543\n",
      "I0120 18:21:12.370544 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 18:21:12.371541 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 18:21:12.372538 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:21:12.372538 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:15.512748 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 51.79it/s]\n",
      "I0120 18:21:20.289483 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:21:20.430108 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 18:21:20.431106 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:21:20.432102 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9d14f8a40a4519b1fb3958faa9a9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:25.558102 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 18:21:25.559099 15348 fine_tuned.py:368]   acc = 0.9714285714285714\n",
      "I0120 18:21:25.559099 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 18:21:25.560097 15348 fine_tuned.py:368]   fp = 4\n",
      "I0120 18:21:25.560097 15348 fine_tuned.py:368]   mcc = 0.9428473041596073\n",
      "I0120 18:21:25.561095 15348 fine_tuned.py:368]   tn = 96\n",
      "I0120 18:21:25.561095 15348 fine_tuned.py:368]   tp = 108\n",
      "I0120 18:21:25.562092 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 18:21:25.564086 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:21:25.565083 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:28.858994 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.11it/s]\n",
      "I0120 18:21:32.711752 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:21:32.842403 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 18:21:32.843399 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:21:32.843399 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbd9e342e3d4404aa9850e010398f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:37.921113 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 18:21:37.922111 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:21:37.922111 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:21:37.922111 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:21:37.923108 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:21:37.923108 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:21:37.923108 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:21:37.924105 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 18:21:37.925103 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:21:37.926100 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:41.057726 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.74it/s]\n",
      "I0120 18:21:45.396518 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:21:45.518193 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 18:21:45.518193 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:21:45.519190 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c6d6c62d4b43df9708ae83f8fc1d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:50.575537 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 18:21:50.576534 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:21:50.576534 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:21:50.576534 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:21:50.577531 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:21:50.577531 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:21:50.578529 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:21:50.579527 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 18:21:50.579527 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:21:50.580523 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:21:53.856821 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.17it/s]\n",
      "I0120 18:21:58.123564 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:21:58.268203 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 18:21:58.269172 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:21:58.269172 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c328aea6741f994097f4e1686005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:03.295938 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 18:22:03.296934 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:22:03.296934 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:22:03.297932 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:22:03.297932 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:22:03.297932 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:22:03.298929 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:22:03.299926 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 18:22:03.299926 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:22:03.300924 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:06.432481 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.89it/s]\n",
      "I0120 18:22:10.318154 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:22:10.490694 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 18:22:10.491690 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:22:10.491690 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f9e1e796394c52ba66b927bb2625ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:15.555401 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 18:22:15.556398 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:22:15.557395 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:22:15.557395 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:22:15.557395 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:22:15.558393 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:22:15.558393 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:22:15.559390 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 18:22:15.559390 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:22:15.560388 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:18.800023 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.50it/s]\n",
      "I0120 18:22:23.074431 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:22:23.209070 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 18:22:23.209070 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:22:23.210068 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5492983e3c44ffbf2d47fe9b0b7f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:28.205913 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 18:22:28.205913 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:22:28.206910 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:22:28.206910 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:22:28.207908 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:22:28.207908 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:22:28.207908 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:22:28.208904 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 18:22:28.209902 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:22:28.210900 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:31.381803 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.84it/s]\n",
      "I0120 18:22:35.754332 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:22:35.927719 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 18:22:35.927719 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:22:35.928716 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23378da1fdb84c77986116576ca41b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:40.951686 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 18:22:40.951686 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:22:40.952684 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:22:40.952684 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:22:40.952684 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:22:40.953681 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:22:40.953681 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:22:40.954679 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 18:22:40.954679 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:22:40.955675 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:44.141052 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.10it/s]\n",
      "I0120 18:22:48.513008 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:22:48.641664 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 18:22:48.642661 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:22:48.643659 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e8f667e47d4c80b58c4615da3e9c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:53.654193 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 18:22:53.655189 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:22:53.656186 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:22:53.656186 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:22:53.657185 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:22:53.657185 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:22:53.657185 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:22:53.658181 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 18:22:53.659180 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:22:53.660178 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:22:56.916366 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.58it/s]\n",
      "I0120 18:23:01.285465 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:23:01.431557 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 18:23:01.432554 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:23:01.432554 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6864b5ee0796407491e64d24e1e9c114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:06.472101 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 18:23:06.473098 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:23:06.473098 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:23:06.474095 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:23:06.474095 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:23:06.474095 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:23:06.475093 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:23:06.476090 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 18:23:06.476090 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:23:06.477088 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:09.617210 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.40it/s]\n",
      "I0120 18:23:14.072779 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:23:14.195450 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 18:23:14.196460 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:23:14.197446 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4767351ab1405f836cc8f67921aeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:19.178179 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 18:23:19.178179 15348 fine_tuned.py:368]   acc = 0.9142857142857143\n",
      "I0120 18:23:19.179175 15348 fine_tuned.py:368]   fn = 12\n",
      "I0120 18:23:19.179175 15348 fine_tuned.py:368]   fp = 6\n",
      "I0120 18:23:19.180175 15348 fine_tuned.py:368]   mcc = 0.8300041252121053\n",
      "I0120 18:23:19.180175 15348 fine_tuned.py:368]   tn = 94\n",
      "I0120 18:23:19.180175 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 18:23:19.182169 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 18:23:19.183167 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:23:19.183167 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:22.432622 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.37it/s]\n",
      "I0120 18:23:26.889289 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:23:27.017573 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 18:23:27.018570 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 18:23:27.018570 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06830d9aab2a451dbacab3738d830eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:31.991103 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 18:23:31.991103 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:23:31.991103 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:23:31.992101 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:23:31.992101 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:23:31.992101 15348 fine_tuned.py:368]   tn = 100\n",
      "I0120 18:23:31.993098 15348 fine_tuned.py:368]   tp = 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:23:32.747585 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:23:32.748589 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:23:32.819369 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 18:23:32.820367 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:23:32.820367 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1386269332164316bd0899d5b53ede83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [100 110]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       900\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 110  TN_H 100  TP_M 888  TN_M 898  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [106 114]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       894\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 114  TN_H 106  TP_M 886  TN_M 892  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [116 114]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       884\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 114  TN_H 116  TP_M 886  TN_M 882  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [126 114]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       874\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 114  TN_H 126  TP_M 886  TN_M 872  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [136 114]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       864\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 114  TN_H 136  TP_M 886  TN_M 862  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [146 114]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       854\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 114  TN_H 146  TP_M 886  TN_M 852  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [156 114]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       844\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 114  TN_H 156  TP_M 886  TN_M 842  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [166 114]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       834\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 114  TN_H 166  TP_M 886  TN_M 832  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [176 114]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       824\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 114  TN_H 176  TP_M 886  TN_M 822  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [186 114]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       814\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 114  TN_H 186  TP_M 886  TN_M 812  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [196 114]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       804\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 114  TN_H 196  TP_M 886  TN_M 802  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [206 114]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       794\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 114  TN_H 206  TP_M 886  TN_M 792  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [216 114]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       784\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 114  TN_H 216  TP_M 886  TN_M 782  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [226 114]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       774\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 114  TN_H 226  TP_M 886  TN_M 772  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [236 114]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       764\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 114  TN_H 236  TP_M 886  TN_M 762  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [246 114]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       754\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 114  TN_H 246  TP_M 886  TN_M 752  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [256 114]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       744\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 114  TN_H 256  TP_M 886  TN_M 742  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [266 114]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       734\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 114  TN_H 266  TP_M 886  TN_M 732  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [276 114]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 114  TN_H 276  TP_M 886  TN_M 722  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [286 114]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       714\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 114  TN_H 286  TP_M 886  TN_M 712  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:24:57.357084 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 18:24:57.358078 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:24:58.033685 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:24:58.034650 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:24:58.098625 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 18:24:58.099624 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:24:58.100622 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 18:25:01.767553 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 112.14it/s]\n",
      "I0120 18:25:05.697965 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:25:05.936401 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 18:25:05.937398 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 18:25:05.937398 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 18:25:05.938396 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 18:25:05.938396 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 18:25:05.939393 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ec91310ba74bfb8bc593774b06ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:41<09:42, 41.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d2884b863a4a4a9d3dd920f0d951fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:26:00.743131 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 18:26:01.971869 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 18:26:01.972866 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:23<09:02, 41.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e40b956e394591a13090d2e2c3c315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.240506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:26:55.466301 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 18:26:56.807631 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 18:26:56.808628 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:05<08:21, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8981a0276b34246b88545b2174dfb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:27:51.634132 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 18:27:52.915583 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 18:27:52.915583 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:48<07:43, 42.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0642706dbe054a00b80143f08a89fc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:29<06:59, 41.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf4ed4bdc0449d5adb6285b7d9e0277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:28:47.273725 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 18:28:48.576153 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 18:28:48.576153 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:11<06:17, 41.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9205366e92d4e3da9008859d0ef5b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:29:42.571169 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 18:29:43.870924 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 18:29:43.871922 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [04:54<05:36, 42.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b029f21e4224e0688a8f5fa846c6f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:30:37.582360 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 18:30:39.146924 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 18:30:39.147895 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:36<04:54, 42.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9e2fa9e6ad4d348f39f1644fe4df10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:17<04:10, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890886572b344893ae7f5dd08d3a5b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:31:33.383493 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 18:31:34.606356 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 18:31:34.606356 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [06:59<03:29, 41.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00440b34cbb14913b2e186a898de2acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:32:28.412325 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 18:32:29.643343 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 18:32:29.644341 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:41<02:47, 41.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b66d813ab034c28838177746577eba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:33:24.278845 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 18:33:25.536432 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 18:33:25.537430 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:24<02:06, 42.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10117a171a3247b788335037430b1058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:05<01:23, 41.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8958d078a1774cdc87cf51ee721159e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:34:20.235017 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 18:34:21.481230 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 18:34:21.482242 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [09:48<00:42, 42.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1854a174a9c54b76a76c1be0193efe38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:35:16.217357 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 18:35:17.535908 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 18:35:17.536905 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:31<00:00, 42.08s/it]\n",
      "I0120 18:35:37.209571 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.016690120645904232\n",
      "I0120 18:35:37.213560 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-210', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 18:35:37.213560 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 18:35:37.214557 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:35:37.215554 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:35:40.519013 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.59it/s]\n",
      "I0120 18:35:45.640463 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:35:45.898772 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 18:35:45.898772 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:35:45.899770 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88bcfdd727b477dbe4450d51c5606dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:35:56.049112 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 18:35:56.050110 15348 fine_tuned.py:368]   acc = 0.9951219512195122\n",
      "I0120 18:35:56.051107 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 18:35:56.051107 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:35:56.052104 15348 fine_tuned.py:368]   mcc = 0.9878575175496691\n",
      "I0120 18:35:56.052104 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:35:56.052104 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 18:35:56.053102 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:35:56.054100 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:35:56.055098 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:35:59.470750 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.30it/s]\n",
      "I0120 18:36:04.510408 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:36:04.767720 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 18:36:04.768717 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:36:04.768717 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00978da43ee540b381d655e80f892289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:14.796193 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 18:36:14.797190 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:36:14.798186 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:36:14.798186 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:36:14.799184 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:36:14.799184 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:36:14.799184 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:36:14.800181 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 18:36:14.801179 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:36:14.802176 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:18.092609 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.50it/s]\n",
      "I0120 18:36:23.462348 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:36:23.716667 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 18:36:23.718662 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:36:23.718662 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dfb9312aa0433f9f728e34fe09041c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:33.741339 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 18:36:33.742337 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:36:33.742337 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:36:33.743335 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:36:33.743335 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:36:33.743335 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:36:33.744331 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:36:33.745329 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 18:36:33.746326 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:36:33.747325 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:37.077351 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 95.53it/s]\n",
      "I0120 18:36:42.187937 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:36:42.441259 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 18:36:42.442256 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:36:42.442256 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325a49108fb441f29de45ce8beae9c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:52.610702 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 18:36:52.611699 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:36:52.611699 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:36:52.612697 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:36:52.612697 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:36:52.613693 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:36:52.613693 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:36:52.615689 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 18:36:52.616687 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:36:52.616687 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:36:56.032788 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 97.49it/s]\n",
      "I0120 18:37:01.046816 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:37:01.340033 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 18:37:01.341030 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:37:01.341030 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185ec5800fdd459cb7a12c271eac17ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:11.334231 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 18:37:11.335228 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:37:11.336225 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:37:11.336225 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:37:11.337222 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:37:11.337222 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:37:11.338219 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:37:11.339216 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 18:37:11.340214 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:37:11.340214 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:14.694048 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 97.13it/s]\n",
      "I0120 18:37:19.219206 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:37:19.508450 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 18:37:19.509447 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:37:19.509447 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb21bcb32c794c0f8a6636d23b2d07eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:29.605492 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 18:37:29.606489 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:37:29.607486 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:37:29.607486 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:37:29.608484 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:37:29.608484 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:37:29.609482 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:37:29.610478 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 18:37:29.610478 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:37:29.611476 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:32.924888 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 100.38it/s]\n",
      "I0120 18:37:37.761195 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:37:37.986592 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 18:37:37.986592 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:37:37.987589 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfbae06820e4cb8a0ce5d9c17515dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:47.925115 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 18:37:47.926135 15348 fine_tuned.py:368]   acc = 0.9902439024390244\n",
      "I0120 18:37:47.927110 15348 fine_tuned.py:368]   fn = 4\n",
      "I0120 18:37:47.927110 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:37:47.927110 15348 fine_tuned.py:368]   mcc = 0.9757288473883157\n",
      "I0120 18:37:47.928108 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:37:47.928108 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 18:37:47.929104 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 18:37:47.930103 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:37:47.931100 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:37:51.059711 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.38it/s]\n",
      "I0120 18:37:55.660172 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:37:55.921474 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 18:37:55.922500 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:37:55.922500 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99da7121802444cebbedb52b5d5c9012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:05.839364 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 18:38:05.840363 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:38:05.841360 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:38:05.841360 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:38:05.841360 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:38:05.842357 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:38:05.842357 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:38:05.843354 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 18:38:05.844351 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:38:05.845349 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:09.039047 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.23it/s]\n",
      "I0120 18:38:13.636035 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:38:13.873897 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 18:38:13.874895 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:38:13.874895 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a9154ff1f948ba847a74939de4c1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:23.754992 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 18:38:23.755969 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:38:23.755969 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:38:23.755969 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:38:23.756966 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:38:23.756966 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:38:23.757963 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:38:23.757963 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 18:38:23.758961 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:38:23.759959 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:26.904060 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.72it/s]\n",
      "I0120 18:38:31.022083 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:38:31.256456 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 18:38:31.257454 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:38:31.257454 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8692b229dc436eb16feb70ca5da888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:41.229505 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 18:38:41.230522 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:38:41.231498 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:38:41.231498 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:38:41.231498 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:38:41.232495 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:38:41.232495 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:38:41.233492 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 18:38:41.234491 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:38:41.235487 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:44.314913 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.55it/s]\n",
      "I0120 18:38:48.415145 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:38:48.665475 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 18:38:48.666472 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:38:48.666472 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448cb75fe5014ed4862c640e7b397690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:38:58.554897 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 18:38:58.554897 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:38:58.555895 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:38:58.555895 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:38:58.556892 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:38:58.556892 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:38:58.556892 15348 fine_tuned.py:368]   tp = 114\n",
      "I0120 18:38:58.557889 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 18:38:58.558887 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:38:58.559884 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:39:01.782972 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.50it/s]\n",
      "I0120 18:39:06.373350 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:39:06.621910 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 18:39:06.622873 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 18:39:06.622873 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c7c76a2e0046f982c5810924672413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:39:16.555134 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 18:39:16.555134 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:39:16.556131 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:39:16.556131 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:39:16.557128 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:39:16.557128 15348 fine_tuned.py:368]   tn = 296\n",
      "I0120 18:39:16.557128 15348 fine_tuned.py:368]   tp = 114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:39:17.478930 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:39:17.479902 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:39:17.588120 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:39:17.590115 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:39:17.591113 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb89959b607447e888434929a8ee3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [296 114]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       704\n",
      "           1       1.00      1.00      1.00       886\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 114  TN_H 296  TP_M 886  TN_M 702  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [297 123]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       703\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 123  TN_H 297  TP_M 877  TN_M 701  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [305 125]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       695\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 125  TN_H 305  TP_M 875  TN_M 693  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [313 127]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       687\n",
      "           1       1.00      1.00      1.00       873\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 127  TN_H 313  TP_M 873  TN_M 685  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [321 129]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       679\n",
      "           1       1.00      1.00      1.00       871\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 129  TN_H 321  TP_M 871  TN_M 677  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [328 132]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       672\n",
      "           1       1.00      1.00      1.00       868\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 132  TN_H 328  TP_M 868  TN_M 670  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [336 134]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       664\n",
      "           1       1.00      1.00      1.00       866\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 134  TN_H 336  TP_M 866  TN_M 662  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [345 135]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       655\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 135  TN_H 345  TP_M 865  TN_M 653  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [352 138]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       648\n",
      "           1       1.00      1.00      1.00       862\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 138  TN_H 352  TP_M 862  TN_M 646  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [361 139]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       639\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 139  TN_H 361  TP_M 861  TN_M 637  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [369 141]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       631\n",
      "           1       1.00      1.00      1.00       859\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 141  TN_H 369  TP_M 859  TN_M 629  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [379 141]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       621\n",
      "           1       1.00      1.00      1.00       859\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 141  TN_H 379  TP_M 859  TN_M 619  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [388 142]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       612\n",
      "           1       1.00      1.00      1.00       858\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 142  TN_H 388  TP_M 858  TN_M 610  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [397 143]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       603\n",
      "           1       1.00      1.00      1.00       857\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 143  TN_H 397  TP_M 857  TN_M 601  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [407 143]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       593\n",
      "           1       1.00      1.00      1.00       857\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 143  TN_H 407  TP_M 857  TN_M 591  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [417 143]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       583\n",
      "           1       1.00      1.00      1.00       857\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 143  TN_H 417  TP_M 857  TN_M 581  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [426 144]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       574\n",
      "           1       1.00      1.00      1.00       856\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 144  TN_H 426  TP_M 856  TN_M 572  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [436 144]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       564\n",
      "           1       1.00      1.00      1.00       856\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 144  TN_H 436  TP_M 856  TN_M 562  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [446 144]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       554\n",
      "           1       1.00      1.00      1.00       856\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 144  TN_H 446  TP_M 856  TN_M 552  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [455 145]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       545\n",
      "           1       1.00      1.00      1.00       855\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 145  TN_H 455  TP_M 855  TN_M 543  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:40:41.220681 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 18:40:41.221680 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:40:41.951237 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 18:40:41.952234 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 18:40:42.016064 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:40:42.017061 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:40:42.018058 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 18:40:45.174621 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 144.52it/s]\n",
      "I0120 18:40:50.177954 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:40:50.551691 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 18:40:50.552714 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 18:40:50.553694 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 18:40:50.553694 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 18:40:50.553694 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 18:40:50.554690 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3e12045f9445e5817030c8c538e610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:00<14:07, 60.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a21c6d267048699c882b549759254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:42:10.685315 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 18:42:11.889790 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 18:42:11.890788 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:02<13:11, 60.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a4f7bc81534663820741a759119f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:43:33.009976 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 18:43:34.209342 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 18:43:34.210339 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:04<12:16, 61.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d745a9a050f41b9bf596b564523c613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:44:55.586662 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 18:44:56.774110 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 18:44:56.775108 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:07<11:19, 61.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16be50e9d52247889ba272c50a45c428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:07<10:12, 61.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16f16b85b1541aeb62cbf47b9640ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:46:17.002523 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 18:46:18.217059 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 18:46:18.218057 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:09<09:13, 61.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e132319027a436e832a3f28780fc462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:47:39.005817 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 18:47:40.215621 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 18:47:40.216619 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:11<08:14, 61.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bea30970e94658b5d48f3aeadfda9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:49:01.274623 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 18:49:02.498353 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 18:49:02.499350 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:14<07:13, 61.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26faf175668464fa58aea7a58bb5b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:14<06:09, 61.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5dd071fbd54949a2901ec3ca9300bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:50:22.962045 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 18:50:24.123761 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 18:50:24.123761 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:16<05:08, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfe096666114b07ab1ffcdf0b63b063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:51:44.453406 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 18:51:45.638360 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 18:51:45.638360 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:18<04:06, 61.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f497108aae924ab49fa32bcc47317fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:53:06.033913 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 18:53:07.217462 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 18:53:07.218460 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:20<03:05, 61.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4309a7508b764d5bbf19064d3b1844c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:21<02:02, 61.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac1b6c11f464ea7b3cef6094016ffa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:54:27.941475 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 18:54:29.595079 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 18:54:29.596076 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:23<01:01, 61.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9987d7f40528434695ebb687c93d836e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:55:50.637934 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 18:55:51.868180 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 18:55:51.869178 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [15:25<00:00, 61.73s/it]\n",
      "I0120 18:56:16.444227 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.010222337390083113\n",
      "I0120 18:56:16.448216 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 18:56:16.449214 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 18:56:16.450212 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:56:16.450212 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:56:19.661923 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.78it/s]\n",
      "I0120 18:56:24.247279 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:56:24.600363 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 18:56:24.601359 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:56:24.601359 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0886668cead4d07aff5ab9acf92aaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:56:39.222574 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 18:56:39.223572 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:56:39.224570 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:56:39.225567 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:56:39.225567 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:56:39.226565 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:56:39.227562 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:56:39.228559 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 18:56:39.229556 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:56:39.230555 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:56:43.407127 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 137.60it/s]\n",
      "I0120 18:56:48.643258 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:56:49.039199 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 18:56:49.040205 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:56:49.040205 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2771a478b64b749658bc41b387cbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:03.633360 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 18:57:03.634356 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:57:03.635354 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:57:03.635354 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:57:03.636350 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:57:03.637348 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:57:03.637348 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:57:03.638345 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 18:57:03.639343 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:57:03.640340 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:07.589705 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.44it/s]\n",
      "I0120 18:57:12.332275 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:57:12.727234 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 18:57:12.728231 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:57:12.729228 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b27a9f71114164a66d3ec42d4bbdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:27.406672 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 18:57:27.407669 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:57:27.408666 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:57:27.408666 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:57:27.410661 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:57:27.410661 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:57:27.411658 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:57:27.412656 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 18:57:27.413653 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:57:27.414650 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:31.039688 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.61it/s]\n",
      "I0120 18:57:36.321317 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:57:36.677365 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 18:57:36.678361 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:57:36.679359 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b531c53863c541b9be7af655842c0a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:51.401594 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 18:57:51.402591 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:57:51.402591 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:57:51.403589 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:57:51.403589 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:57:51.404586 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:57:51.404586 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:57:51.405584 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 18:57:51.406580 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:57:51.407578 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:57:54.684744 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 134.96it/s]\n",
      "I0120 18:57:59.482405 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:57:59.823324 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 18:57:59.824321 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:57:59.824321 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dff1a5da5d4371bb17ab058c7c513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:58:14.596452 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 18:58:14.598446 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:58:14.598446 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:58:14.599443 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:58:14.599443 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:58:14.600441 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:58:14.601438 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:58:14.602435 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 18:58:14.603433 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:58:14.603433 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:58:17.899739 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.60it/s]\n",
      "I0120 18:58:23.220003 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:58:23.567045 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 18:58:23.568073 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:58:23.569041 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d17936bd4df45d0b09256d8702d3498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:58:38.402888 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 18:58:38.403886 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:58:38.403886 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:58:38.403886 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:58:38.404883 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:58:38.404883 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:58:38.405880 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:58:38.405880 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 18:58:38.406878 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:58:38.407875 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:58:41.557857 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.13it/s]\n",
      "I0120 18:58:46.279284 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:58:46.631343 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 18:58:46.631343 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:58:46.632341 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51cfbc18e189494180eedde2f82d8531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:01.424208 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 18:59:01.425205 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:59:01.425205 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:59:01.425205 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:59:01.426203 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:59:01.426203 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:59:01.426203 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:59:01.427201 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 18:59:01.428198 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:59:01.428198 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:04.528616 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.69it/s]\n",
      "I0120 18:59:09.641717 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:59:09.985125 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 18:59:09.986123 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:59:09.986123 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d6b01ecc3b4c26bee718b309091f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:24.751141 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 18:59:24.752169 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:59:24.752169 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:59:24.753137 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:59:24.753137 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:59:24.753137 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:59:24.754134 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:59:24.755132 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 18:59:24.756128 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:59:24.757125 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:27.903198 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 138.46it/s]\n",
      "I0120 18:59:33.033934 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:59:33.441884 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 18:59:33.442880 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:59:33.442880 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74c99dc278c46ec9c8c02aed83d9049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:48.240776 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 18:59:48.241774 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 18:59:48.241774 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 18:59:48.242770 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 18:59:48.242770 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 18:59:48.242770 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 18:59:48.243768 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 18:59:48.244765 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 18:59:48.244765 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 18:59:48.245763 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 18:59:51.770844 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.66it/s]\n",
      "I0120 18:59:56.887680 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 18:59:57.262677 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 18:59:57.262677 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 18:59:57.263675 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdb9be634424c7b9b566df2ee48a047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:12.074562 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 19:00:12.074562 15348 fine_tuned.py:368]   acc = 0.9967213114754099\n",
      "I0120 19:00:12.075560 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:00:12.075560 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 19:00:12.076565 15348 fine_tuned.py:368]   mcc = 0.9910773882810443\n",
      "I0120 19:00:12.076565 15348 fine_tuned.py:368]   tn = 462\n",
      "I0120 19:00:12.076565 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 19:00:12.077556 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 19:00:12.078553 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:00:12.078553 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:15.233613 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 139.24it/s]\n",
      "I0120 19:00:20.350459 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:00:20.707502 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 19:00:20.708526 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:00:20.708526 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86062687cba8464aab11f8866dcc7787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:35.491841 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 19:00:35.492838 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:00:35.492838 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:00:35.493836 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:00:35.493836 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:00:35.494833 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 19:00:35.494833 15348 fine_tuned.py:368]   tp = 146\n",
      "I0120 19:00:35.495830 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 19:00:35.496829 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:00:35.497825 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:38.634601 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 141.96it/s]\n",
      "I0120 19:00:43.295664 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:00:43.631765 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 19:00:43.631765 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:00:43.632762 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40401d3e4ff442a9a7453df64e3b700e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:58.381534 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 19:00:58.382532 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:00:58.383529 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:00:58.383529 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:00:58.384527 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:00:58.384527 15348 fine_tuned.py:368]   tn = 464\n",
      "I0120 19:00:58.385524 15348 fine_tuned.py:368]   tp = 146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:00:59.158159 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:00:59.159132 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:00:59.219970 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 19:00:59.221965 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:00:59.222963 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4934443fdb9466fba59f2662a3e70bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [464 146]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       536\n",
      "           1       1.00      1.00      1.00       854\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 146  TN_H 464  TP_M 854  TN_M 534  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [473 147]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       527\n",
      "           1       1.00      1.00      1.00       853\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 147  TN_H 473  TP_M 853  TN_M 525  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [481 149]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       519\n",
      "           1       1.00      1.00      1.00       851\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 149  TN_H 481  TP_M 851  TN_M 517  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [490 150]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       510\n",
      "           1       1.00      1.00      1.00       850\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 150  TN_H 490  TP_M 850  TN_M 508  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [498 152]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       502\n",
      "           1       1.00      1.00      1.00       848\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 152  TN_H 498  TP_M 848  TN_M 500  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [506 154]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       494\n",
      "           1       1.00      1.00      1.00       846\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 154  TN_H 506  TP_M 846  TN_M 492  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [514 156]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       486\n",
      "           1       1.00      1.00      1.00       844\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 156  TN_H 514  TP_M 844  TN_M 484  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [524 156]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       476\n",
      "           1       1.00      1.00      1.00       844\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 156  TN_H 524  TP_M 844  TN_M 474  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [532 158]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       468\n",
      "           1       1.00      1.00      1.00       842\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 158  TN_H 532  TP_M 842  TN_M 466  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [541 159]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       459\n",
      "           1       1.00      1.00      1.00       841\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 159  TN_H 541  TP_M 841  TN_M 457  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [551 159]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       449\n",
      "           1       1.00      1.00      1.00       841\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 159  TN_H 551  TP_M 841  TN_M 447  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [561 159]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       439\n",
      "           1       1.00      1.00      1.00       841\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 159  TN_H 561  TP_M 841  TN_M 437  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [570 160]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       430\n",
      "           1       1.00      1.00      1.00       840\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 160  TN_H 570  TP_M 840  TN_M 428  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [579 161]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       421\n",
      "           1       1.00      1.00      1.00       839\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 161  TN_H 579  TP_M 839  TN_M 419  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [588 162]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       412\n",
      "           1       1.00      1.00      1.00       838\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 162  TN_H 588  TP_M 838  TN_M 410  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [597 163]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       403\n",
      "           1       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 163  TN_H 597  TP_M 837  TN_M 401  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [607 163]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       393\n",
      "           1       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 163  TN_H 607  TP_M 837  TN_M 391  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [617 163]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       383\n",
      "           1       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 163  TN_H 617  TP_M 837  TN_M 381  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [626 164]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       374\n",
      "           1       1.00      1.00      1.00       836\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 164  TN_H 626  TP_M 836  TN_M 372  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [635 165]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       365\n",
      "           1       1.00      1.00      1.00       835\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 165  TN_H 635  TP_M 835  TN_M 363  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [643 167]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       357\n",
      "           1       1.00      1.00      1.00       833\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 167  TN_H 643  TP_M 833  TN_M 355  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [652 168]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       348\n",
      "           1       1.00      1.00      1.00       832\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 168  TN_H 652  TP_M 832  TN_M 346  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [662 168]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       338\n",
      "           1       1.00      1.00      1.00       832\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 168  TN_H 662  TP_M 832  TN_M 336  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [671 169]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       329\n",
      "           1       1.00      1.00      1.00       831\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 169  TN_H 671  TP_M 831  TN_M 327  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [679 171]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       321\n",
      "           1       1.00      1.00      1.00       829\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 171  TN_H 679  TP_M 829  TN_M 319  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [689 171]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       311\n",
      "           1       1.00      1.00      1.00       829\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 171  TN_H 689  TP_M 829  TN_M 309  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [699 171]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       301\n",
      "           1       1.00      1.00      1.00       829\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 171  TN_H 699  TP_M 829  TN_M 299  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [707 173]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       293\n",
      "           1       1.00      1.00      1.00       827\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 173  TN_H 707  TP_M 827  TN_M 291  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [717 173]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       283\n",
      "           1       1.00      1.00      1.00       827\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 173  TN_H 717  TP_M 827  TN_M 281  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [727 173]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       273\n",
      "           1       1.00      1.00      1.00       827\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 173  TN_H 727  TP_M 827  TN_M 271  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [736 174]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       264\n",
      "           1       1.00      1.00      1.00       826\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 174  TN_H 736  TP_M 826  TN_M 262  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [743 177]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       257\n",
      "           1       1.00      1.00      1.00       823\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 177  TN_H 743  TP_M 823  TN_M 255  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [751 179]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       249\n",
      "           1       1.00      1.00      1.00       821\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 179  TN_H 751  TP_M 821  TN_M 247  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [761 179]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       239\n",
      "           1       1.00      1.00      1.00       821\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 179  TN_H 761  TP_M 821  TN_M 237  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [769 181]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       231\n",
      "           1       1.00      1.00      1.00       819\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      1.00      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 181  TN_H 769  TP_M 819  TN_M 229  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [777 183]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       223\n",
      "           1       1.00      1.00      1.00       817\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      1.00      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 183  TN_H 777  TP_M 817  TN_M 221  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [783 187]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       217\n",
      "           1       1.00      1.00      1.00       813\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      1.00      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 187  TN_H 783  TP_M 813  TN_M 215  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [790 190]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       210\n",
      "           1       1.00      1.00      1.00       810\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      1.00      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 190  TN_H 790  TP_M 810  TN_M 208  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [800 190]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       200\n",
      "           1       1.00      1.00      1.00       810\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 190  TN_H 800  TP_M 810  TN_M 198  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [809 191]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       191\n",
      "           1       1.00      1.00      1.00       809\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 191  TN_H 809  TP_M 809  TN_M 189  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  0 th loops---------------\n",
      "initial random chosen samples [146, 739, 735, 382, 896, 1685, 1873, 1869, 1203, 1799]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92       995\n",
      "           1       0.89      0.97      0.93       995\n",
      "\n",
      "    accuracy                           0.93      1990\n",
      "   macro avg       0.93      0.93      0.93      1990\n",
      "weighted avg       0.93      0.93      0.93      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 961  TN_M 881  FP_M 114  FN_M 34\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [13  7]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       987\n",
      "           1       0.98      0.93      0.95       993\n",
      "\n",
      "    accuracy                           0.96      1980\n",
      "   macro avg       0.96      0.96      0.96      1980\n",
      "weighted avg       0.96      0.96      0.96      1980\n",
      "\n",
      "TP_H 7  TN_H 13  TP_M 920  TN_M 972  FP_M 15  FN_M 73\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [18 12]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       982\n",
      "           1       0.98      0.96      0.97       988\n",
      "\n",
      "    accuracy                           0.97      1970\n",
      "   macro avg       0.97      0.97      0.97      1970\n",
      "weighted avg       0.97      0.97      0.97      1970\n",
      "\n",
      "TP_H 12  TN_H 18  TP_M 952  TN_M 966  FP_M 16  FN_M 36\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [19 21]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       981\n",
      "           1       0.96      0.98      0.97       979\n",
      "\n",
      "    accuracy                           0.97      1960\n",
      "   macro avg       0.97      0.97      0.97      1960\n",
      "weighted avg       0.97      0.97      0.97      1960\n",
      "\n",
      "TP_H 21  TN_H 19  TP_M 960  TN_M 936  FP_M 45  FN_M 19\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [25 25]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       975\n",
      "           1       0.98      0.99      0.98       975\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 25  TN_H 25  TP_M 962  TN_M 954  FP_M 21  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [30 30]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       970\n",
      "           1       0.98      0.99      0.99       970\n",
      "\n",
      "    accuracy                           0.99      1940\n",
      "   macro avg       0.99      0.99      0.99      1940\n",
      "weighted avg       0.99      0.99      0.99      1940\n",
      "\n",
      "TP_H 30  TN_H 30  TP_M 961  TN_M 955  FP_M 15  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [37 33]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       963\n",
      "           1       0.99      0.98      0.99       967\n",
      "\n",
      "    accuracy                           0.99      1930\n",
      "   macro avg       0.99      0.99      0.99      1930\n",
      "weighted avg       0.99      0.99      0.99      1930\n",
      "\n",
      "TP_H 33  TN_H 37  TP_M 948  TN_M 954  FP_M 9  FN_M 19\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [42 38]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       958\n",
      "           1       0.99      0.98      0.99       962\n",
      "\n",
      "    accuracy                           0.99      1920\n",
      "   macro avg       0.99      0.99      0.99      1920\n",
      "weighted avg       0.99      0.99      0.99      1920\n",
      "\n",
      "TP_H 38  TN_H 42  TP_M 944  TN_M 950  FP_M 8  FN_M 18\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [44 46]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       956\n",
      "           1       1.00      0.99      0.99       954\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 46  TN_H 44  TP_M 945  TN_M 952  FP_M 4  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [47 53]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       953\n",
      "           1       1.00      0.99      0.99       947\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 53  TN_H 47  TP_M 939  TN_M 949  FP_M 4  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [53 57]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       947\n",
      "           1       1.00      0.99      0.99       943\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 57  TN_H 53  TP_M 935  TN_M 943  FP_M 4  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [57 63]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       943\n",
      "           1       1.00      0.99      0.99       937\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 63  TN_H 57  TP_M 931  TN_M 939  FP_M 4  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [64 66]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       936\n",
      "           1       1.00      0.99      0.99       934\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 66  TN_H 64  TP_M 928  TN_M 932  FP_M 4  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [71 69]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       929\n",
      "           1       1.00      0.99      1.00       931\n",
      "\n",
      "    accuracy                           1.00      1860\n",
      "   macro avg       1.00      1.00      1.00      1860\n",
      "weighted avg       1.00      1.00      1.00      1860\n",
      "\n",
      "TP_H 69  TN_H 71  TP_M 925  TN_M 927  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [74 76]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       926\n",
      "           1       1.00      0.99      1.00       924\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 76  TN_H 74  TP_M 918  TN_M 924  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [77 83]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       923\n",
      "           1       1.00      0.99      1.00       917\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 83  TN_H 77  TP_M 911  TN_M 921  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [84 86]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       916\n",
      "           1       1.00      0.99      1.00       914\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 86  TN_H 84  TP_M 909  TN_M 914  FP_M 2  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [88 92]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       912\n",
      "           1       1.00      0.99      1.00       908\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 92  TN_H 88  TP_M 903  TN_M 910  FP_M 2  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [92 98]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       908\n",
      "           1       1.00      0.99      1.00       902\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 98  TN_H 92  TP_M 897  TN_M 906  FP_M 2  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [ 96 104]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       904\n",
      "           1       1.00      1.00      1.00       896\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 104  TN_H 96  TP_M 892  TN_M 902  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:02:35.208923 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:02:35.209919 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:02:36.010093 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:02:36.011090 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:02:36.474849 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:02:36.476843 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:02:36.853838 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 19:02:39.848442 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 19:02:39.849436 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 19:02:40.038929 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.48it/s]\n",
      "I0120 19:02:43.531379 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:02:43.655048 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 19:02:43.656046 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 19:02:43.657043 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 19:02:43.657043 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 19:02:43.658040 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 19:02:43.658040 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96538563759494ba38b9fb3a74b0188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.593628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:20<04:52, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b48b012d75b4616942426cf0268c54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:03:11.377607 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 19:03:12.624103 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 19:03:12.625101 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:43<04:37, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045209da8c4d4d9c9cf5cb9160ca587f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.078996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:03:40.497481 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 19:03:41.803539 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 19:03:41.804538 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:05<04:20, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180c90cb88224199965d282a2db6bb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:04:09.728440 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 19:04:10.955432 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 19:04:10.955432 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:28<04:00, 21.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2645fdb0336b47ca90f1239d8736c787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:49<03:36, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d4e5ffda3a4d00ae7b894ca23b2f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:04:38.924696 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 19:04:40.253566 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 19:04:40.254564 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:11<03:16, 21.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2361485ee27486ca25ba74b7a6b5e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:05:07.722373 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 19:05:09.031390 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 19:05:09.032388 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:33<02:55, 21.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a64b6c26114bae93e47c39c6d150f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000395"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:05:36.546731 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 19:05:37.782256 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 19:05:37.782256 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000361"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [02:55<02:33, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ccee7d1ed14432a28c7eb1f5019833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:16<02:09, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8dee3440c94967ab5d1e944d7c49bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:06:05.333506 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 19:06:06.514791 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 19:06:06.515787 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000442"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:38<01:49, 21.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a89aea76cc4bd4a4837aec61136c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:06:34.352520 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 19:06:35.683215 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 19:06:35.684212 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:01<01:27, 21.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453cd0e6bac145c585cae5e9f2d9a92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:07:03.314495 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 19:07:04.672345 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 19:07:04.673341 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:23<01:06, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8416faf64fa488999eb98c853e14392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:44<00:43, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84f72d998344b149dd3202d5338521d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000231"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:07:32.401814 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 19:07:33.733757 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 19:07:33.734754 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:07<00:22, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0f38bca07e4d6e8ea32226e0ed88b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:01.816953 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 19:08:03.139414 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 19:08:03.140411 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000308"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:29<00:00, 21.95s/it]\n",
      "I0120 19:08:12.895717 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.1205921118926702\n",
      "I0120 19:08:12.898709 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 19:08:12.900703 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 19:08:12.901701 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:08:12.902699 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:16.013776 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 56.07it/s]\n",
      "I0120 19:08:20.481939 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:08:20.598627 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 19:08:20.599624 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:08:20.599624 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54043d51dd5d492b8327623d7cc255ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:25.632292 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 19:08:25.633290 15348 fine_tuned.py:368]   acc = 0.9714285714285714\n",
      "I0120 19:08:25.633290 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:08:25.634312 15348 fine_tuned.py:368]   fp = 6\n",
      "I0120 19:08:25.634312 15348 fine_tuned.py:368]   mcc = 0.9440444328631419\n",
      "I0120 19:08:25.635286 15348 fine_tuned.py:368]   tn = 93\n",
      "I0120 19:08:25.635286 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:08:25.636306 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 19:08:25.637303 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:08:25.638300 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:28.756422 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.74it/s]\n",
      "I0120 19:08:32.227979 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:08:32.337044 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 19:08:32.338010 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:08:32.338010 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dacf74b7d94afdb32fefccc7149946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:37.399574 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 19:08:37.400573 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 19:08:37.401570 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:08:37.401570 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:08:37.402567 15348 fine_tuned.py:368]   mcc = 0.99048503575804\n",
      "I0120 19:08:37.402567 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 19:08:37.403564 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:08:37.404562 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:08:37.405559 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:08:37.406556 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:40.689278 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.15it/s]\n",
      "I0120 19:08:44.651730 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:08:44.778678 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 19:08:44.779704 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:08:44.779704 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b75c5a97584847acdc1f4090406212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:49.848721 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 19:08:49.848721 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:08:49.849719 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:08:49.849719 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:08:49.850716 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:08:49.850716 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:08:49.850716 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:08:49.851713 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 19:08:49.853708 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:08:49.854705 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:08:53.423605 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.76it/s]\n",
      "I0120 19:08:57.117818 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:08:57.234473 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 19:08:57.234473 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:08:57.235471 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0db80ed5934386a372b5a1c4fbdc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:02.348061 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 19:09:02.349058 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:09:02.349058 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:09:02.349058 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:09:02.350055 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:09:02.350055 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:09:02.351053 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:09:02.352049 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 19:09:02.353047 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:09:02.354045 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:05.608742 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.82it/s]\n",
      "I0120 19:09:09.086918 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:09:09.206238 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 19:09:09.208233 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:09:09.208233 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265fb57e9a2642cfb3b403d853af4621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:14.307044 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 19:09:14.308040 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:09:14.309038 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:09:14.309038 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:09:14.310034 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:09:14.310034 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:09:14.311033 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:09:14.312030 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 19:09:14.313027 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:09:14.313027 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:17.544652 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 64.56it/s]\n",
      "I0120 19:09:21.023928 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:09:21.149621 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 19:09:21.150622 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:09:21.150622 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7226e8df9a2948388579c27505846673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:26.224829 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 19:09:26.225826 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:09:26.225826 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:09:26.226821 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:09:26.226821 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:09:26.226821 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:09:26.227819 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:09:26.228818 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 19:09:26.229816 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:09:26.230813 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:29.476645 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.29it/s]\n",
      "I0120 19:09:33.345284 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:09:33.471340 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 19:09:33.472338 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:09:33.472338 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7575118b01604ab583e16bdffe885145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:38.595071 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 19:09:38.596068 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:09:38.596068 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:09:38.597065 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:09:38.597065 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:09:38.597065 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:09:38.598063 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:09:38.599060 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 19:09:38.600058 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:09:38.600058 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:41.778884 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.70it/s]\n",
      "I0120 19:09:45.742953 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:09:45.853624 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 19:09:45.854655 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:09:45.854655 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00aef6a8d7bf41d8a19478a36fe98cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:50.990551 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 19:09:50.991549 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:09:50.991549 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:09:50.992547 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:09:50.992547 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:09:50.992547 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:09:50.993545 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:09:50.993545 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 19:09:50.994565 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:09:50.995538 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:09:54.090903 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 67.02it/s]\n",
      "I0120 19:09:58.073614 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:09:58.187006 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 19:09:58.187006 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:09:58.187974 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193c18570cce416686d76f901a4315a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:03.361587 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 19:10:03.362610 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:10:03.362610 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:10:03.363582 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:10:03.363582 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:10:03.363582 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:10:03.364578 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:10:03.365576 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 19:10:03.365576 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:10:03.366573 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:06.502416 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 67.06it/s]\n",
      "I0120 19:10:09.988109 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:10:10.101805 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 19:10:10.102802 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:10:10.102802 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28eea3a3ae9a423d8dac5340a89d02e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:15.251614 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 19:10:15.251614 15348 fine_tuned.py:368]   acc = 0.5714285714285714\n",
      "I0120 19:10:15.252610 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:10:15.252610 15348 fine_tuned.py:368]   fp = 90\n",
      "I0120 19:10:15.253609 15348 fine_tuned.py:368]   mcc = 0.2240614375912734\n",
      "I0120 19:10:15.253609 15348 fine_tuned.py:368]   tn = 9\n",
      "I0120 19:10:15.253609 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 19:10:15.254606 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 19:10:15.255604 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:10:15.255604 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:18.346326 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.56it/s]\n",
      "I0120 19:10:22.220278 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:10:22.339186 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 19:10:22.339186 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:10:22.340211 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4adb0ebb0a84756a83a3301a26519ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:27.493302 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 19:10:27.493302 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:10:27.494299 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:10:27.494299 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:10:27.495297 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:10:27.495297 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 19:10:27.496294 15348 fine_tuned.py:368]   tp = 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:10:28.332149 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:10:28.333147 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:10:28.435844 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:10:28.436841 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:10:28.436841 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec648880ce34e1295665c24be9d0ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [ 99 111]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       901\n",
      "           1       1.00      1.00      1.00       889\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 111  TN_H 99  TP_M 887  TN_M 898  FP_M 3  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [101 119]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       899\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 119  TN_H 101  TP_M 881  TN_M 897  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [107 123]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       893\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 123  TN_H 107  TP_M 877  TN_M 891  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [116 124]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       884\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 124  TN_H 116  TP_M 876  TN_M 882  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [123 127]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       877\n",
      "           1       1.00      1.00      1.00       873\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 127  TN_H 123  TP_M 873  TN_M 875  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [131 129]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       869\n",
      "           1       1.00      1.00      1.00       871\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 129  TN_H 131  TP_M 871  TN_M 867  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [138 132]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       862\n",
      "           1       1.00      1.00      1.00       868\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 132  TN_H 138  TP_M 868  TN_M 860  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [145 135]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 135  TN_H 145  TP_M 865  TN_M 853  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [153 137]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       847\n",
      "           1       1.00      1.00      1.00       863\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 137  TN_H 153  TP_M 863  TN_M 845  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [162 138]\n",
      "Number of training examples  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       838\n",
      "           1       1.00      1.00      1.00       862\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 138  TN_H 162  TP_M 862  TN_M 836  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [171 139]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       829\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 139  TN_H 171  TP_M 861  TN_M 827  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [181 139]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       819\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 139  TN_H 181  TP_M 861  TN_M 817  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [191 139]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       809\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 139  TN_H 191  TP_M 861  TN_M 807  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [201 139]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       799\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 139  TN_H 201  TP_M 861  TN_M 797  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [211 139]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       789\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 139  TN_H 211  TP_M 861  TN_M 787  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [221 139]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       779\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 139  TN_H 221  TP_M 861  TN_M 777  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [231 139]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       769\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 139  TN_H 231  TP_M 861  TN_M 767  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [241 139]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       759\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 139  TN_H 241  TP_M 861  TN_M 757  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [251 139]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       749\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 139  TN_H 251  TP_M 861  TN_M 747  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [261 139]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       739\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 139  TN_H 261  TP_M 861  TN_M 737  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:11:52.944542 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:11:52.946536 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:11:53.854238 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:11:53.855210 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:11:53.956965 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:11:53.958959 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:11:53.959931 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 19:11:57.094766 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.72it/s]\n",
      "I0120 19:12:01.657968 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:12:01.936222 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 19:12:01.937220 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 19:12:01.937220 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 19:12:01.938216 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 19:12:01.939215 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 19:12:01.939215 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf2c0f3f66647f0afddbddd744f0b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.001197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000113"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:40<09:30, 40.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbba9a2f37248bab67a4be193c64259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:12:55.801147 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 19:12:57.025409 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 19:12:57.025409 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:22<08:54, 41.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc68ff63d96406da01f779308798925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:13:50.992693 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 19:13:52.232815 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 19:13:52.233813 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:05<08:18, 41.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e970ed2637a84f10aa304e43e300b5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:14:46.421660 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 19:14:47.643621 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 19:14:47.644618 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000277"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:47<07:38, 41.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5509c37422b9451c86a304dc332da4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000021"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:27<06:53, 41.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43f0f6db5374a99b163caef6ef5f830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:15:41.485230 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 19:15:42.839738 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 19:15:42.840734 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:09<06:13, 41.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5cf35ba981401e8d796442de7ae3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:16:36.613501 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 19:16:37.854309 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 19:16:37.855280 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [04:52<05:34, 41.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3c1898d1744638aebdc306be009ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:17:31.585579 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 19:17:32.844778 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 19:17:32.845768 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:33<04:52, 41.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb78837f65448c8a2314ab2c234ccac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:14<04:09, 41.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68e98167b084b30a217c89881c6d4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:18:26.904462 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 19:18:28.101550 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 19:18:28.102547 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [06:57<03:28, 41.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c34bd6b63246e3b2d8043c84044abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:19:22.338730 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 19:19:23.558690 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 19:19:23.559662 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:39<02:47, 41.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0fdc92d34e4a7e9b8560987ac35e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:20:18.190034 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 19:20:19.465188 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 19:20:19.467183 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:22<02:06, 42.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf9cee410ff479f9586ae9373d9a308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:03<01:23, 41.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99b3244c46340208b9f0ee8f621b02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:21:13.613003 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 19:21:14.785661 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 19:21:14.786658 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [09:45<00:41, 41.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1e548d4be546b69e26501d57d318bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:22:08.309846 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 19:22:09.577720 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 19:22:09.578728 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:27<00:00, 41.83s/it]\n",
      "I0120 19:22:29.341981 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.013164035233286206\n",
      "I0120 19:22:29.345971 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-280', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 19:22:29.345971 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:22:29.347966 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:22:29.347966 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:22:32.560189 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 102.30it/s]\n",
      "I0120 19:22:36.863047 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:22:37.111861 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 19:22:37.112856 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:22:37.112856 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04c7baffb3c414180beb2fa51368a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:22:46.945642 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 19:22:46.946613 15348 fine_tuned.py:368]   acc = 0.9951219512195122\n",
      "I0120 19:22:46.946613 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 19:22:46.947610 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:22:46.947610 15348 fine_tuned.py:368]   mcc = 0.9891364484451638\n",
      "I0120 19:22:46.947610 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:22:46.948607 15348 fine_tuned.py:368]   tp = 137\n",
      "I0120 19:22:46.949604 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 19:22:46.950602 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:22:46.951600 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:22:50.118346 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 105.23it/s]\n",
      "I0120 19:22:54.723119 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:22:54.955527 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 19:22:54.956523 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:22:54.956523 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d24aca3ae344fc18d86585bb7faf00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:04.895581 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 19:23:04.896578 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:23:04.897574 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:23:04.897574 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:23:04.897574 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:23:04.898572 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:23:04.898572 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:23:04.899569 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 19:23:04.900567 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:23:04.901565 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:07.972531 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.73it/s]\n",
      "I0120 19:23:12.571602 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:23:12.807996 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 19:23:12.809004 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:23:12.809004 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e98843c47a346af9872bcf6eb259711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:22.763819 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 19:23:22.764817 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:23:22.764817 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:23:22.765814 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:23:22.765814 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:23:22.766812 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:23:22.766812 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:23:22.768807 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 19:23:22.768807 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:23:22.769805 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:25.888859 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.51it/s]\n",
      "I0120 19:23:29.993441 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:23:30.227470 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 19:23:30.227470 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:23:30.228471 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224f6ab3c71c473b939c9cf77b619897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:40.128772 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 19:23:40.129772 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:23:40.130739 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:23:40.130739 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:23:40.130739 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:23:40.131736 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:23:40.131736 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:23:40.132734 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 19:23:40.133732 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:23:40.133732 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:43.270338 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.10it/s]\n",
      "I0120 19:23:47.878338 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:23:48.112740 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 19:23:48.113739 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:23:48.113739 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa35d49753744d693aeb3b83f3b97fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:23:58.083123 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 19:23:58.083123 15348 fine_tuned.py:368]   acc = 0.9975609756097561\n",
      "I0120 19:23:58.084120 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 19:23:58.085118 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:23:58.085118 15348 fine_tuned.py:368]   mcc = 0.9945630871071681\n",
      "I0120 19:23:58.085118 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:23:58.086115 15348 fine_tuned.py:368]   tp = 138\n",
      "I0120 19:23:58.087112 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 19:23:58.088109 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:23:58.089107 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:01.274962 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.39it/s]\n",
      "I0120 19:24:05.375192 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:24:05.612529 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 19:24:05.613527 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:24:05.613527 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d34d8bd17024bc08f080780e694b0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:15.586063 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 19:24:15.587060 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:24:15.588058 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:24:15.588058 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:24:15.589057 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:24:15.589057 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:24:15.590053 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:24:15.590053 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 19:24:15.591075 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:24:15.592048 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:18.746931 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.13it/s]\n",
      "I0120 19:24:22.997859 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:24:23.250211 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 19:24:23.251209 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:24:23.251209 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984cea04557420cb6e0a2b35ec4826f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:33.225235 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 19:24:33.226231 15348 fine_tuned.py:368]   acc = 0.9975609756097561\n",
      "I0120 19:24:33.226231 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:24:33.227230 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:24:33.227230 15348 fine_tuned.py:368]   mcc = 0.9945820546155079\n",
      "I0120 19:24:33.228227 15348 fine_tuned.py:368]   tn = 270\n",
      "I0120 19:24:33.228227 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:24:33.230223 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 19:24:33.231219 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:24:33.232217 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:36.324050 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.54it/s]\n",
      "I0120 19:24:40.531051 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:24:40.784006 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 19:24:40.785004 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:24:40.785004 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca950a0980b84f7682a3c85751ca7867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:50.770994 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 19:24:50.772988 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:24:50.772988 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:24:50.773987 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:24:50.773987 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:24:50.774983 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:24:50.774983 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:24:50.775980 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 19:24:50.776978 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:24:50.776978 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:24:54.012555 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.05it/s]\n",
      "I0120 19:24:58.210643 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:24:58.456651 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 19:24:58.456651 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:24:58.457620 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26b4ad19dcd49aaab1281d19fcc7740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:08.417412 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 19:25:08.417412 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:25:08.418409 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:25:08.418409 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:25:08.419407 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:25:08.419407 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:25:08.419407 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:25:08.420404 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 19:25:08.421402 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:25:08.422400 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:11.514687 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.11it/s]\n",
      "I0120 19:25:15.615567 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:25:15.869860 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 19:25:15.870860 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:25:15.871855 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6049334f03a4d7f9da451d965192226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:25.853883 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 19:25:25.854881 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:25:25.854881 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:25:25.855877 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:25:25.855877 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:25:25.855877 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:25:25.856874 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:25:25.857872 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 19:25:25.858870 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:25:25.858870 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:28.971612 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.50it/s]\n",
      "I0120 19:25:33.563907 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:25:33.800303 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 19:25:33.800303 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:25:33.801301 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9017b97f1185419287a7c69b762b422a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:43.760014 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 19:25:43.761042 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:25:43.761042 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:25:43.762010 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:25:43.762010 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:25:43.763037 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:25:43.763037 15348 fine_tuned.py:368]   tp = 139\n",
      "I0120 19:25:43.764003 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 19:25:43.765000 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:25:43.766000 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:25:46.905381 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 109.98it/s]\n",
      "I0120 19:25:51.389952 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:25:51.633598 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 19:25:51.633598 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 19:25:51.634596 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c72cf7cdbc349b9bfe8ee1c85bb296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:26:01.588445 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 19:26:01.589442 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:26:01.590440 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:26:01.590440 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:26:01.591438 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:26:01.591438 15348 fine_tuned.py:368]   tn = 271\n",
      "I0120 19:26:01.592436 15348 fine_tuned.py:368]   tp = 139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:26:02.502698 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:26:02.503664 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:26:02.607707 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 19:26:02.608706 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:26:02.609703 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473f964c6cc94626ad0a35c943646d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [271 139]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       729\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 139  TN_H 271  TP_M 861  TN_M 726  FP_M 3  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [273 147]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       853\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 147  TN_H 273  TP_M 853  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [273 157]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       843\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 157  TN_H 273  TP_M 843  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [273 167]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       833\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 167  TN_H 273  TP_M 833  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [273 177]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       823\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 177  TN_H 273  TP_M 823  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [273 187]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       813\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 187  TN_H 273  TP_M 813  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [273 197]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       803\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 197  TN_H 273  TP_M 803  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [273 207]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       793\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 207  TN_H 273  TP_M 793  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [273 217]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       783\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 217  TN_H 273  TP_M 783  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [273 227]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       773\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 227  TN_H 273  TP_M 773  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [273 237]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       763\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 237  TN_H 273  TP_M 763  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [273 247]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       753\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 247  TN_H 273  TP_M 753  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [273 257]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       743\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 257  TN_H 273  TP_M 743  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [273 267]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       733\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 267  TN_H 273  TP_M 733  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [273 277]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       723\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 277  TN_H 273  TP_M 723  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [273 287]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       713\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 287  TN_H 273  TP_M 713  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [273 297]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       727\n",
      "           1       1.00      1.00      1.00       703\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 297  TN_H 273  TP_M 703  TN_M 725  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [274 306]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       726\n",
      "           1       1.00      1.00      1.00       694\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 306  TN_H 274  TP_M 694  TN_M 725  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [274 316]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       726\n",
      "           1       1.00      1.00      1.00       684\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 316  TN_H 274  TP_M 684  TN_M 725  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [274 326]\n",
      "Number of training examples  600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       726\n",
      "           1       1.00      1.00      1.00       674\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 326  TN_H 274  TP_M 674  TN_M 725  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:27:26.320322 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:27:26.321319 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:27:27.033442 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:27:27.033442 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:27:27.097266 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 19:27:27.098263 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:27:27.099260 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 19:27:30.234356 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.54it/s]\n",
      "I0120 19:27:35.584677 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:27:35.953718 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 19:27:35.954714 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 19:27:35.954714 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 19:27:35.955712 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 19:27:35.955712 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 19:27:35.955712 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1802bf7bee1b4f8baef36ac8a5b43510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:01<14:14, 61.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357a464780304bd3889b32a14202e3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:28:56.577116 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 19:28:57.804485 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 19:28:57.805482 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:03<13:18, 61.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0062ebdff3dc468fb8b1adc4ec64c1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:30:18.621436 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 19:30:19.838180 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 19:30:19.839177 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:05<12:18, 61.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc160f8323f43348726b28867e1abd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000148"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:31:40.160538 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 19:31:41.428786 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 19:31:41.429757 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:06<11:16, 61.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425c54cbca3a4fc09fc0975e475f4587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:07<10:12, 61.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1da842bf4e544719ada314c3d3fbf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:33:01.628619 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 19:33:02.898296 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 19:33:02.899318 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:10<09:16, 61.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8422d58c2bb844e2ab3baa1913f708ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:34:27.019653 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 19:34:28.298735 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 19:34:28.299731 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:14<08:20, 62.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b615f4a1991845898fbb18489fb8ad3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:35:50.488342 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 19:35:51.721492 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 19:35:51.722489 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:18<07:19, 62.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca864a8d65c4d868a416fa57d6f2dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:19<06:13, 62.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6623e3bbe59043fda5be376edf58ec59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:37:12.917958 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 19:37:14.141222 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 19:37:14.142220 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:22<05:12, 62.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bd4ab8759647268aca8cc5302395a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:38:36.477005 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 19:38:37.764478 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 19:38:37.765476 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:25<04:11, 62.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab72d7f87a4444ed9e5a3c9d68a4e602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:40:01.035506 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 19:40:02.274423 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 19:40:02.275421 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:29<03:09, 63.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d34ddaecc06416c8a245adc48c4edc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:32<02:05, 62.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db9d735d0a842619463e8a8d55bfc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:41:24.923800 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 19:41:26.159513 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 19:41:26.160510 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:35<01:02, 62.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbc7836fb5247f4940abcea6f308eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:42:49.229539 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 19:42:50.575137 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 19:42:50.576134 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [15:40<00:00, 62.68s/it]\n",
      "I0120 19:43:16.094592 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.020027358489098892\n",
      "I0120 19:43:16.101574 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 19:43:16.103568 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 19:43:16.105563 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:43:16.106560 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:43:19.330840 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 114.31it/s]\n",
      "I0120 19:43:25.503507 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:43:25.881523 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 19:43:25.882493 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:43:25.882493 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549d138343ca4dd3aee9aac2a8da1a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:43:40.799717 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 19:43:40.799717 15348 fine_tuned.py:368]   acc = 0.9967213114754099\n",
      "I0120 19:43:40.800716 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:43:40.801713 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 19:43:40.801713 15348 fine_tuned.py:368]   mcc = 0.9933915447148074\n",
      "I0120 19:43:40.802710 15348 fine_tuned.py:368]   tn = 272\n",
      "I0120 19:43:40.802710 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:43:40.803707 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 19:43:40.804704 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:43:40.805702 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:43:44.053905 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 128.73it/s]\n",
      "I0120 19:43:49.026707 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:43:49.412690 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 19:43:49.412690 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:43:49.413687 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b5929babd5429c82ad75dfa397f3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:04.782418 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 19:44:04.782418 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:44:04.783416 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:44:04.783416 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:44:04.784413 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:44:04.784413 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:44:04.784413 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:44:04.785410 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 19:44:04.786408 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:44:04.787405 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:08.053905 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.06it/s]\n",
      "I0120 19:44:13.449173 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:44:13.788062 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 19:44:13.788062 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:44:13.789028 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8957bef7a2942afa1e9a31d66f967be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:29.338775 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 19:44:29.339800 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:44:29.340769 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:44:29.340769 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:44:29.341766 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:44:29.341766 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:44:29.342764 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:44:29.343763 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 19:44:29.344759 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:44:29.345757 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:32.731507 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 124.20it/s]\n",
      "I0120 19:44:38.489181 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:44:38.897270 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 19:44:38.897270 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:44:38.898268 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4eae84b4c5c426a965278cb3614d621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:53.939767 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 19:44:53.940784 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:44:53.940784 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:44:53.941762 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:44:53.941762 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:44:53.942759 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 19:44:53.942759 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:44:53.944286 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 19:44:53.945260 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:44:53.945260 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:44:57.160766 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.57it/s]\n",
      "I0120 19:45:02.450469 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:45:02.810512 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 19:45:02.811476 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:45:02.811476 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161d07d9629d4769846e33786ad05f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:45:17.898922 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 19:45:17.899918 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:45:17.899918 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:45:17.900915 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:45:17.900915 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:45:17.901913 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 19:45:17.901913 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:45:17.902910 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 19:45:17.903907 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:45:17.903907 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:45:21.100200 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.44it/s]\n",
      "I0120 19:45:26.402524 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:45:26.760899 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 19:45:26.760899 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:45:26.761894 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e96204c238f4c4fb959c0fbb5fdb173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:45:41.899641 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 19:45:41.899641 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:45:41.900640 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:45:41.900640 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:45:41.901637 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:45:41.901637 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 19:45:41.902635 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:45:41.903630 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 19:45:41.904628 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:45:41.904628 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:45:45.111696 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.76it/s]\n",
      "I0120 19:45:49.957748 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:45:50.348675 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 19:45:50.350670 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:45:50.350670 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e2de5de170450c80feae7440ad270e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:05.706222 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 19:46:05.706222 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:46:05.707219 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:46:05.707219 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:46:05.707219 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:46:05.708216 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 19:46:05.708216 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:46:05.709213 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 19:46:05.709213 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:46:05.710211 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:08.850816 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.73it/s]\n",
      "I0120 19:46:14.095451 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:46:14.449139 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 19:46:14.449139 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:46:14.450133 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55b6a765f2f4a418c5de341255539b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:29.596759 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 19:46:29.597754 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:46:29.597754 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:46:29.598752 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:46:29.598752 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:46:29.599749 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:46:29.599749 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:46:29.600746 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 19:46:29.600746 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:46:29.601744 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:32.818192 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.29it/s]\n",
      "I0120 19:46:38.159200 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:46:38.520234 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 19:46:38.520234 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:46:38.521231 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0b2b3952844d82ba99975d55b2de7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:53.762419 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 19:46:53.763417 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:46:53.764416 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:46:53.764416 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:46:53.765412 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:46:53.765412 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 19:46:53.765412 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:46:53.766409 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 19:46:53.767407 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:46:53.768404 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:46:57.021009 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.16it/s]\n",
      "I0120 19:47:02.312326 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:47:02.695049 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 19:47:02.695049 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:47:02.696045 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c178ca30de42f386755472d489c55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:47:17.851643 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 19:47:17.852641 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:47:17.852641 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:47:17.853639 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:47:17.853639 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:47:17.853639 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:47:17.854637 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:47:17.855633 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 19:47:17.855633 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:47:17.856630 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:47:20.978094 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 137.29it/s]\n",
      "I0120 19:47:26.194335 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:47:26.555371 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 19:47:26.556368 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:47:26.556368 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde68bd035c240fea05e4a706ea0f9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:47:41.525174 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 19:47:41.527169 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:47:41.527169 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:47:41.528169 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:47:41.528169 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:47:41.529165 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:47:41.529165 15348 fine_tuned.py:368]   tp = 336\n",
      "I0120 19:47:41.530163 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 19:47:41.531159 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:47:41.532180 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:47:44.697575 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 137.05it/s]\n",
      "I0120 19:47:49.471883 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:47:49.843098 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 19:47:49.843098 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 19:47:49.844096 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269f994a6fbf42378c3054902c3ebe4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:48:04.975948 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 19:48:04.976944 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 19:48:04.976944 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:48:04.977943 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:48:04.977943 15348 fine_tuned.py:368]   mcc = 0.99669144457581\n",
      "I0120 19:48:04.977943 15348 fine_tuned.py:368]   tn = 273\n",
      "I0120 19:48:04.978940 15348 fine_tuned.py:368]   tp = 336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:48:05.864731 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:48:05.865728 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:48:05.934544 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 19:48:05.935542 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:48:05.935542 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f75c56aa9b44218b38f2da7a44e98ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [274 336]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       726\n",
      "           1       1.00      1.00      1.00       664\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 336  TN_H 274  TP_M 664  TN_M 725  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [275 345]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       655\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 345  TN_H 275  TP_M 655  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [275 355]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       645\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 355  TN_H 275  TP_M 645  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [275 365]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       635\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 365  TN_H 275  TP_M 635  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [275 375]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       625\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 375  TN_H 275  TP_M 625  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [275 385]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       615\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 385  TN_H 275  TP_M 615  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [275 395]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       605\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 395  TN_H 275  TP_M 605  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [275 405]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       595\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 405  TN_H 275  TP_M 595  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [275 415]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       585\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 415  TN_H 275  TP_M 585  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [275 425]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       575\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 425  TN_H 275  TP_M 575  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [275 435]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       565\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 435  TN_H 275  TP_M 565  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [275 445]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       555\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 445  TN_H 275  TP_M 555  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [275 455]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       545\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 455  TN_H 275  TP_M 545  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [275 465]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       535\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 465  TN_H 275  TP_M 535  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [275 475]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       525\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 475  TN_H 275  TP_M 525  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [275 485]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       515\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 485  TN_H 275  TP_M 515  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [275 495]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       505\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 495  TN_H 275  TP_M 505  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [275 505]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       495\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 505  TN_H 275  TP_M 495  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [275 515]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       485\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 515  TN_H 275  TP_M 485  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [275 525]\n",
      "Number of training examples  800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       475\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 525  TN_H 275  TP_M 475  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [275 535]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       725\n",
      "           1       1.00      1.00      1.00       465\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 535  TN_H 275  TP_M 465  TN_M 724  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [276 544]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       456\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 544  TN_H 276  TP_M 456  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [276 554]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       446\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 554  TN_H 276  TP_M 446  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [276 564]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       436\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 564  TN_H 276  TP_M 436  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [276 574]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       426\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 574  TN_H 276  TP_M 426  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [276 584]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       416\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 584  TN_H 276  TP_M 416  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [276 594]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       406\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 594  TN_H 276  TP_M 406  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [276 604]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       396\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 604  TN_H 276  TP_M 396  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [276 614]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       386\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 614  TN_H 276  TP_M 386  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [276 624]\n",
      "Number of training examples  900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       376\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 624  TN_H 276  TP_M 376  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [276 634]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       366\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 634  TN_H 276  TP_M 366  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [276 644]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       356\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 644  TN_H 276  TP_M 356  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [276 654]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       346\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 654  TN_H 276  TP_M 346  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [276 664]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       336\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 664  TN_H 276  TP_M 336  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [276 674]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       326\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      1.00      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 674  TN_H 276  TP_M 326  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [276 684]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       316\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      1.00      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 684  TN_H 276  TP_M 316  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [276 694]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      1.00      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 694  TN_H 276  TP_M 306  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [276 704]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       296\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      1.00      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 704  TN_H 276  TP_M 296  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [276 714]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       286\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      1.00      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 714  TN_H 276  TP_M 286  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [276 724]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       276\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 724  TN_H 276  TP_M 276  TN_M 724  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [494, 105, 306, 899, 763, 1756, 1601, 1884, 1308, 1613]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96       995\n",
      "           1       0.94      0.99      0.96       995\n",
      "\n",
      "    accuracy                           0.96      1990\n",
      "   macro avg       0.96      0.96      0.96      1990\n",
      "weighted avg       0.96      0.96      0.96      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 987  TN_M 930  FP_M 65  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [13  7]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       987\n",
      "           1       0.94      0.94      0.94       993\n",
      "\n",
      "    accuracy                           0.94      1980\n",
      "   macro avg       0.94      0.94      0.94      1980\n",
      "weighted avg       0.94      0.94      0.94      1980\n",
      "\n",
      "TP_H 7  TN_H 13  TP_M 938  TN_M 928  FP_M 59  FN_M 55\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [18 12]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       982\n",
      "           1       0.95      0.95      0.95       988\n",
      "\n",
      "    accuracy                           0.95      1970\n",
      "   macro avg       0.95      0.95      0.95      1970\n",
      "weighted avg       0.95      0.95      0.95      1970\n",
      "\n",
      "TP_H 12  TN_H 18  TP_M 937  TN_M 930  FP_M 52  FN_M 51\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [22 18]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       978\n",
      "           1       0.98      0.96      0.97       982\n",
      "\n",
      "    accuracy                           0.97      1960\n",
      "   macro avg       0.97      0.97      0.97      1960\n",
      "weighted avg       0.97      0.97      0.97      1960\n",
      "\n",
      "TP_H 18  TN_H 22  TP_M 942  TN_M 962  FP_M 16  FN_M 40\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [25 25]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       975\n",
      "           1       0.98      0.98      0.98       975\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 25  TN_H 25  TP_M 960  TN_M 953  FP_M 22  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [33 27]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       967\n",
      "           1       0.98      0.97      0.98       973\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 27  TN_H 33  TP_M 948  TN_M 948  FP_M 19  FN_M 25\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [35 35]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       965\n",
      "           1       0.98      0.99      0.98       965\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "TP_H 35  TN_H 35  TP_M 951  TN_M 946  FP_M 19  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [43 37]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       957\n",
      "           1       0.98      0.98      0.98       963\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 37  TN_H 43  TP_M 945  TN_M 938  FP_M 19  FN_M 18\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [45 45]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       955\n",
      "           1       0.99      0.96      0.97       955\n",
      "\n",
      "    accuracy                           0.97      1910\n",
      "   macro avg       0.97      0.97      0.97      1910\n",
      "weighted avg       0.97      0.97      0.97      1910\n",
      "\n",
      "TP_H 45  TN_H 45  TP_M 914  TN_M 945  FP_M 10  FN_M 41\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [46 54]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       954\n",
      "           1       0.99      0.99      0.99       946\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 54  TN_H 46  TP_M 932  TN_M 942  FP_M 12  FN_M 14\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [50 60]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       950\n",
      "           1       0.99      0.99      0.99       940\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 60  TN_H 50  TP_M 933  TN_M 937  FP_M 13  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [58 62]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       942\n",
      "           1       0.99      0.99      0.99       938\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 62  TN_H 58  TP_M 930  TN_M 931  FP_M 11  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [64 66]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       936\n",
      "           1       0.99      0.99      0.99       934\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 66  TN_H 64  TP_M 925  TN_M 929  FP_M 7  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [69 71]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       931\n",
      "           1       0.99      0.99      0.99       929\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 71  TN_H 69  TP_M 922  TN_M 926  FP_M 5  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [72 78]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       928\n",
      "           1       1.00      0.99      0.99       922\n",
      "\n",
      "    accuracy                           0.99      1850\n",
      "   macro avg       0.99      0.99      0.99      1850\n",
      "weighted avg       0.99      0.99      0.99      1850\n",
      "\n",
      "TP_H 78  TN_H 72  TP_M 916  TN_M 924  FP_M 4  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [78 82]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       922\n",
      "           1       1.00      0.99      0.99       918\n",
      "\n",
      "    accuracy                           0.99      1840\n",
      "   macro avg       0.99      0.99      0.99      1840\n",
      "weighted avg       0.99      0.99      0.99      1840\n",
      "\n",
      "TP_H 82  TN_H 78  TP_M 912  TN_M 918  FP_M 4  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [83 87]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       917\n",
      "           1       1.00      0.99      1.00       913\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 87  TN_H 83  TP_M 907  TN_M 915  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [92 88]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       908\n",
      "           1       1.00      0.99      1.00       912\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 88  TN_H 92  TP_M 906  TN_M 906  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [96 94]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       904\n",
      "           1       1.00      0.99      1.00       906\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 94  TN_H 96  TP_M 900  TN_M 902  FP_M 2  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [102  98]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       898\n",
      "           1       1.00      0.99      1.00       902\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 98  TN_H 102  TP_M 897  TN_M 896  FP_M 2  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:49:47.789942 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:49:47.790966 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:49:48.554537 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:49:48.555534 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:49:48.989374 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:49:48.990370 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:49:49.370211 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 19:49:52.376713 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 19:49:52.376713 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 19:49:52.573186 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.14it/s]\n",
      "I0120 19:49:56.872579 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:49:57.027165 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 19:49:57.028162 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 19:49:57.028162 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 19:49:57.029160 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 19:49:57.029160 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 19:49:57.029160 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9d9b8ef4804e5398b1c7ab6418f538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.688623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690431"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:21<05:06, 21.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232101b8a8884df7954ef18f4d34e8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:50:25.807304 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 19:50:27.097937 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 19:50:27.098934 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:45<04:50, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f379365007b43c1afde445e7e48f6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:50:56.584098 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 19:50:57.911967 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 19:50:57.912935 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:08<04:30, 22.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36324bbbdbac4144acdfafb157a579fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:51:26.232818 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 19:51:27.455096 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 19:51:27.456062 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:31<04:08, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d0045283814f959bda5d32b6725d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000877"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:52<03:42, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4eadd0461c74774adfb884299bf23ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:51:55.662430 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 19:51:56.984562 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 19:51:56.985560 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:15<03:21, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa806b4a20df463093f39d9f38695ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000419"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:52:25.581151 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 19:52:26.895112 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 19:52:26.896128 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:38<03:00, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902fe1d988f74a768da23b84807c4fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:52:55.269508 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 19:52:56.626907 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 19:52:56.626907 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:01<02:38, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0206a499777e4c4c871cc3952eb8487d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:22<02:14, 22.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59f17ee19644cd99a54ff8c78b9c0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000244"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:53:25.240488 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 19:53:26.568334 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 19:53:26.568334 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:45<01:52, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef35db5dae44b6d96a3ed169f19da64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:53:55.089501 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 19:53:56.248399 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 19:53:56.248399 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:08<01:30, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99b7d101b8e4363b3017c2f69d2efb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:54:24.900331 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 19:54:26.134030 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 19:54:26.135027 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:31<01:08, 22.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03789956f6b4afb8bd54b775fee0f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:52<00:44, 22.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96868444318b436d98043e9b21de4a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:54:54.263048 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 19:54:55.559545 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 19:54:55.559545 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:15<00:22, 22.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43656c897f04ba88e1339ad97fc18d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:55:24.035844 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 19:55:25.338359 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 19:55:25.339357 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:38<00:00, 22.55s/it]\n",
      "I0120 19:55:35.330145 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.10266506284850198\n",
      "I0120 19:55:35.333139 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 19:55:35.334135 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 19:55:35.335132 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:55:35.336157 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:55:38.360037 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.87it/s]\n",
      "I0120 19:55:42.638588 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:55:42.765251 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 19:55:42.767246 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:55:42.767246 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1f9687c1384cea832864236665fa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:55:48.010726 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 19:55:48.011724 15348 fine_tuned.py:368]   acc = 0.9714285714285714\n",
      "I0120 19:55:48.011724 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:55:48.012720 15348 fine_tuned.py:368]   fp = 6\n",
      "I0120 19:55:48.012720 15348 fine_tuned.py:368]   mcc = 0.9444444444444444\n",
      "I0120 19:55:48.012720 15348 fine_tuned.py:368]   tn = 102\n",
      "I0120 19:55:48.013718 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:55:48.014715 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 19:55:48.014715 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:55:48.015712 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:55:51.110430 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 64.77it/s]\n",
      "I0120 19:55:54.589122 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:55:54.733737 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 19:55:54.734764 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:55:54.735758 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6cb819268443a1bee9c9dc9484aafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:55:59.896886 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 19:55:59.896886 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 19:55:59.897911 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:55:59.897911 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 19:55:59.898881 15348 fine_tuned.py:368]   mcc = 0.9905159759426533\n",
      "I0120 19:55:59.898881 15348 fine_tuned.py:368]   tn = 107\n",
      "I0120 19:55:59.898881 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:55:59.899878 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:55:59.900875 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:55:59.901871 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:02.917801 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.70it/s]\n",
      "I0120 19:56:06.900145 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:56:07.037778 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 19:56:07.037778 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:56:07.038775 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1972123bda0d49d08349ce0a7f32ffc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:12.413718 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 19:56:12.414712 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:56:12.414712 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:56:12.415684 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:56:12.415684 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:56:12.416681 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:56:12.416681 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:56:12.417678 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 19:56:12.418676 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:56:12.418676 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:15.776690 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 63.59it/s]\n",
      "I0120 19:56:19.871732 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:56:20.010362 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 19:56:20.011359 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:56:20.011359 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef7ca091b504e9ca6040e4ed2354d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:25.309281 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 19:56:25.310278 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:56:25.310278 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:56:25.311275 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:56:25.311275 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:56:25.311275 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:56:25.312273 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:56:25.313271 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 19:56:25.314268 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:56:25.315264 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:28.699209 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.92it/s]\n",
      "I0120 19:56:32.506024 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:56:32.625727 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 19:56:32.626741 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:56:32.626741 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bb53a374774d48908d44b8c7e62afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:37.833534 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 19:56:37.834530 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:56:37.834530 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:56:37.834530 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:56:37.835528 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:56:37.835528 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:56:37.835528 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:56:37.836524 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 19:56:37.837522 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:56:37.837522 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:41.221467 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 65.60it/s]\n",
      "I0120 19:56:44.712126 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:56:44.842811 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 19:56:44.843804 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:56:44.843804 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70636db2794458b961e0c3f7a51698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:50.103484 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 19:56:50.104481 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:56:50.105478 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:56:50.106476 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:56:50.107473 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:56:50.107473 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:56:50.108470 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:56:50.109467 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 19:56:50.109467 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:56:50.110465 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:56:53.387695 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 63.48it/s]\n",
      "I0120 19:56:56.984073 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:56:57.127714 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 19:56:57.128710 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:56:57.128710 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad30845b1f6546319f8719f12c997d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:02.100137 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 19:57:02.100137 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:57:02.101135 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:57:02.101135 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:57:02.101135 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:57:02.102132 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:57:02.102132 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:57:02.103130 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 19:57:02.104126 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:57:02.104126 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:05.351437 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.65it/s]\n",
      "I0120 19:57:09.332030 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:57:09.444728 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 19:57:09.444728 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:57:09.445726 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564dcd6e8c3f4975b907542c232ebe3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:14.350606 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 19:57:14.351603 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:57:14.351603 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:57:14.352600 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:57:14.352600 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:57:14.352600 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:57:14.353598 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:57:14.353598 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 19:57:14.354594 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:57:14.355591 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:17.631824 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.89it/s]\n",
      "I0120 19:57:21.034719 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:57:21.152405 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 19:57:21.153402 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:57:21.154400 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118805fa57bc414192aea1587151eee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:26.062266 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 19:57:26.063263 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:57:26.063263 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:57:26.064260 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:57:26.064260 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:57:26.064260 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:57:26.065258 15348 fine_tuned.py:368]   tp = 102\n",
      "I0120 19:57:26.066255 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 19:57:26.066255 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:57:26.067253 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:29.312569 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 68.90it/s]\n",
      "I0120 19:57:33.089488 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:57:33.245047 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 19:57:33.246044 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:57:33.246044 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622441c90def4917aa42afef0ef02658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:38.137959 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 19:57:38.138956 15348 fine_tuned.py:368]   acc = 0.5761904761904761\n",
      "I0120 19:57:38.138956 15348 fine_tuned.py:368]   fn = 89\n",
      "I0120 19:57:38.138956 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:57:38.139953 15348 fine_tuned.py:368]   mcc = 0.26433237309062335\n",
      "I0120 19:57:38.139953 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:57:38.140949 15348 fine_tuned.py:368]   tp = 13\n",
      "I0120 19:57:38.140949 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 19:57:38.141948 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:57:38.142945 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:41.415189 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 68.43it/s]\n",
      "I0120 19:57:44.796183 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:57:44.936766 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 19:57:44.937763 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 19:57:44.937763 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ccf828c4984b55afae8dce28b53ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:49.818701 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 19:57:49.818701 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 19:57:49.819701 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 19:57:49.819701 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 19:57:49.819701 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 19:57:49.820698 15348 fine_tuned.py:368]   tn = 108\n",
      "I0120 19:57:49.820698 15348 fine_tuned.py:368]   tp = 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:57:50.532791 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:57:50.532791 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:57:50.605596 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:57:50.607591 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:57:50.607591 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972337c31d0c43ef902bcba9916ca5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [108 102]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       892\n",
      "           1       1.00      1.00      1.00       898\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 102  TN_H 108  TP_M 894  TN_M 890  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [113 107]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       887\n",
      "           1       1.00      1.00      1.00       893\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 107  TN_H 113  TP_M 891  TN_M 885  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [120 110]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       880\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 110  TN_H 120  TP_M 889  TN_M 878  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [125 115]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       875\n",
      "           1       1.00      1.00      1.00       885\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 115  TN_H 125  TP_M 884  TN_M 873  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [132 118]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       868\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 118  TN_H 132  TP_M 881  TN_M 866  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [139 121]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       861\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 121  TN_H 139  TP_M 878  TN_M 859  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [145 125]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 125  TN_H 145  TP_M 874  TN_M 853  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [153 127]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       847\n",
      "           1       1.00      1.00      1.00       873\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 127  TN_H 153  TP_M 872  TN_M 845  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [160 130]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       840\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 130  TN_H 160  TP_M 869  TN_M 838  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [170 130]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       830\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 130  TN_H 170  TP_M 869  TN_M 828  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [180 130]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       820\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 130  TN_H 180  TP_M 869  TN_M 818  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [190 130]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       810\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 130  TN_H 190  TP_M 869  TN_M 808  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [200 130]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       800\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 130  TN_H 200  TP_M 869  TN_M 798  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [209 131]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       791\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 131  TN_H 209  TP_M 869  TN_M 789  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [219 131]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       781\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 131  TN_H 219  TP_M 869  TN_M 779  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [229 131]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       771\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 131  TN_H 229  TP_M 869  TN_M 769  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [239 131]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       761\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 131  TN_H 239  TP_M 869  TN_M 759  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [249 131]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       751\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 131  TN_H 249  TP_M 869  TN_M 749  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [259 131]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       741\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 131  TN_H 259  TP_M 869  TN_M 739  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [267 133]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       733\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 133  TN_H 267  TP_M 867  TN_M 731  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 19:59:16.484764 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 19:59:16.486759 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:59:17.254764 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 19:59:17.254764 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 19:59:17.313607 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 19:59:17.314604 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 19:59:17.315603 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 19:59:20.341503 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 113.53it/s]\n",
      "I0120 19:59:24.275977 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 19:59:24.581161 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 19:59:24.582158 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 19:59:24.582158 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 19:59:24.583155 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 19:59:24.583155 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 19:59:24.584151 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0703828223ad4bcd85710027cf480329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.760354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:40<09:33, 40.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8ef5eee96e46f48b9844bc5c2c1c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:00:18.604720 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 20:00:19.862355 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 20:00:19.863352 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:24<09:02, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da23c26dfdd4504a0371a3708e8d9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:01:14.803548 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 20:01:16.065172 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 20:01:16.065172 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:06<08:20, 41.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35f387bfd584a85b8180e79fceb5a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:02:10.075346 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 20:02:11.388833 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 20:02:11.389830 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:48<07:40, 41.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88e49add03649a097001ca0c567c47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:29<06:55, 41.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d665b8105744e9e9fdcb542be0b6b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:03:05.556849 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 20:03:06.803535 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 20:03:06.804536 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:10<06:13, 41.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6719c80747427fb5cffb4b293fa927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:03:59.219214 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 20:04:00.464909 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 20:04:00.465907 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [04:51<05:31, 41.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a780a7b7154e51a189196f0d5cdc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:04:55.204631 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 20:04:56.487198 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 20:04:56.487198 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:35<04:53, 41.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e70edb0de5400c9419fc4dae0abb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:16<04:10, 41.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd60a135f014146adf44b803fc5b340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:05:51.178965 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 20:05:52.403801 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 20:05:52.404774 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [06:58<03:29, 41.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544178915cb24a91ae02ac05cf9c98c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:06:46.708877 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 20:06:47.912730 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 20:06:47.913697 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:41<02:48, 42.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2167567a70a04172840773188e775e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:07:43.350884 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 20:07:44.631400 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 20:07:44.631400 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:24<02:07, 42.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd4c20dbec74874a476a36a71208e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:06<01:24, 42.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d07689a90744beb66fec5bf8d0e973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:08:39.755820 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 20:08:40.990377 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 20:08:40.991374 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [09:49<00:42, 42.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d4c388e7b54b10b06b66b027750a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:09:35.810618 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 20:09:37.054225 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 20:09:37.055223 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:32<00:00, 42.17s/it]\n",
      "I0120 20:09:57.204909 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.010716124838609911\n",
      "I0120 20:09:57.207901 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-280', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 20:09:57.208897 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 20:09:57.209897 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:09:57.210894 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:00.370397 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:05<00:00, 73.99it/s]\n",
      "I0120 20:10:06.171292 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:10:06.424615 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 20:10:06.425613 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:10:06.425613 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648a25e6f14248f6a51d8cebb9dfe9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:16.081358 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 20:10:16.082357 15348 fine_tuned.py:368]   acc = 0.9902439024390244\n",
      "I0120 20:10:16.082357 15348 fine_tuned.py:368]   fn = 4\n",
      "I0120 20:10:16.083356 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:10:16.083356 15348 fine_tuned.py:368]   mcc = 0.977812892704922\n",
      "I0120 20:10:16.084352 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:10:16.084352 15348 fine_tuned.py:368]   tp = 129\n",
      "I0120 20:10:16.085349 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:10:16.086345 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:10:16.087346 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:19.195774 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.14it/s]\n",
      "I0120 20:10:23.936594 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:10:24.166977 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 20:10:24.166977 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:10:24.167975 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab23ab261a9e46c2b75affd3d7e4ebb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:33.858283 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 20:10:33.859280 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:10:33.860278 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:10:33.860278 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:10:33.860278 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:10:33.861301 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:10:33.861301 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:10:33.863268 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 20:10:33.863268 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:10:33.864295 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:37.011212 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 111.76it/s]\n",
      "I0120 20:10:41.013007 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:10:41.254388 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 20:10:41.254388 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:10:41.255358 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccebaa98d9014b01bf09a6ddf9a35175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:51.395035 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 20:10:51.395035 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:10:51.396033 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:10:51.396033 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:10:51.396033 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:10:51.397030 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:10:51.397030 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:10:51.398026 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 20:10:51.399025 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:10:51.400022 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:10:54.588360 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.13it/s]\n",
      "I0120 20:10:58.791191 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:10:59.035775 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 20:10:59.036772 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:10:59.036772 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b712cecac076486588a2b5557709ff77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:09.163355 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 20:11:09.164353 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:11:09.164353 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:11:09.164353 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:11:09.165350 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:11:09.165350 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:11:09.165350 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:11:09.166350 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 20:11:09.167346 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:11:09.168342 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:12.279096 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 108.69it/s]\n",
      "I0120 20:11:16.845547 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:11:17.081942 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 20:11:17.083908 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:11:17.083908 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab9fcb098874c0abfb303632d7225dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:27.205519 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 20:11:27.205519 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:11:27.206516 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:11:27.206516 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:11:27.207514 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:11:27.207514 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:11:27.207514 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:11:27.208511 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 20:11:27.209508 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:11:27.210505 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:30.504507 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.70it/s]\n",
      "I0120 20:11:34.551616 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:11:34.787404 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 20:11:34.788402 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:11:34.788402 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28927a53f27048a7be5baa7f9f2cb953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:44.968947 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 20:11:44.969946 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:11:44.969946 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:11:44.970943 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:11:44.970943 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:11:44.971941 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:11:44.971941 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:11:44.972938 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 20:11:44.972938 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:11:44.973934 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:11:48.106829 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 109.13it/s]\n",
      "I0120 20:11:52.595533 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:11:52.841935 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 20:11:52.842901 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:11:52.842901 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7262e3315f994e82a07b985e18c3ab37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:02.939271 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 20:12:02.940267 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:12:02.940267 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:12:02.941266 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:12:02.941266 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:12:02.942263 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:12:02.942263 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:12:02.943261 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 20:12:02.943261 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:12:02.944257 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:06.189589 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 111.27it/s]\n",
      "I0120 20:12:10.574781 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:12:10.826589 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 20:12:10.827598 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:12:10.827598 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac3ba3613394a3f806d16a1e3d99910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:20.986633 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 20:12:20.987631 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:12:20.988629 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:12:20.988629 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:12:20.989624 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:12:20.989624 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:12:20.990622 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:12:20.991619 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 20:12:20.991619 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:12:20.992617 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:24.128535 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 111.45it/s]\n",
      "I0120 20:12:28.122123 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:12:28.347498 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 20:12:28.348498 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:12:28.348498 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac898f6ba50471c9951ddb749501c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:38.416643 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 20:12:38.417641 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:12:38.418638 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:12:38.418638 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:12:38.419636 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:12:38.420633 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:12:38.420633 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:12:38.421629 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 20:12:38.422626 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:12:38.423624 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:41.644223 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 111.56it/s]\n",
      "I0120 20:12:45.649693 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:12:45.887629 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 20:12:45.887629 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:12:45.888625 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed5ba1382244b7a9c0c89766650322b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:56.050899 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 20:12:56.051895 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:12:56.051895 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:12:56.052894 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:12:56.052894 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:12:56.053892 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:12:56.053892 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:12:56.055884 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 20:12:56.056884 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:12:56.057879 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:12:59.245063 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 105.45it/s]\n",
      "I0120 20:13:03.378687 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:13:03.683876 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 20:13:03.683876 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:13:03.684873 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0659b76c505a4dee90d5bbeb60dc73f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:13:13.819930 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 20:13:13.820928 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:13:13.820928 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:13:13.821925 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:13:13.821925 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:13:13.822922 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:13:13.822922 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 20:13:13.823920 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 20:13:13.824918 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:13:13.825915 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:13:17.020097 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 108.34it/s]\n",
      "I0120 20:13:21.528128 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:13:21.768355 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 20:13:21.769353 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:13:21.769353 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4462be8cd6455ab26f6906d56d86a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:13:31.903122 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 20:13:31.904119 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:13:31.904119 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:13:31.904119 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:13:31.905117 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:13:31.905117 15348 fine_tuned.py:368]   tn = 277\n",
      "I0120 20:13:31.906114 15348 fine_tuned.py:368]   tp = 133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:13:32.698774 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:13:32.699772 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:13:32.766776 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:13:32.767775 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:13:32.767775 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce3f43b72904e5993b1b15059d050d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [277 133]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 133  TN_H 277  TP_M 867  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [277 143]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       857\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 143  TN_H 277  TP_M 857  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [277 153]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 153  TN_H 277  TP_M 847  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [277 163]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       837\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 163  TN_H 277  TP_M 837  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [277 173]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       827\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 173  TN_H 277  TP_M 827  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [277 183]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       817\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 183  TN_H 277  TP_M 817  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [278 192]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       808\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 192  TN_H 278  TP_M 808  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [278 202]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       798\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 202  TN_H 278  TP_M 798  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [278 212]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 212  TN_H 278  TP_M 788  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [278 222]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       778\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 222  TN_H 278  TP_M 778  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [278 232]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       768\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 232  TN_H 278  TP_M 768  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [278 242]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       758\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 242  TN_H 278  TP_M 758  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [278 252]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       748\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 252  TN_H 278  TP_M 748  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [278 262]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       738\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 262  TN_H 278  TP_M 738  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [278 272]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       728\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 272  TN_H 278  TP_M 728  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [278 282]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       718\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 282  TN_H 278  TP_M 718  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [278 292]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       708\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 292  TN_H 278  TP_M 708  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [278 302]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       698\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 302  TN_H 278  TP_M 698  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [278 312]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       688\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 312  TN_H 278  TP_M 688  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [278 322]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       678\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 322  TN_H 278  TP_M 678  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:14:57.203367 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 20:14:57.204364 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:14:58.004252 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:14:58.005256 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:14:58.065062 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:14:58.067059 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:14:58.068054 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 20:15:01.269027 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.68it/s]\n",
      "I0120 20:15:06.221274 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:15:06.600944 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 20:15:06.601969 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 20:15:06.602940 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 20:15:06.602940 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 20:15:06.603937 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 20:15:06.603937 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c8942fe8144b42952776b18b1f77cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:01<14:26, 61.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdf38db139c4312a237631c396bbe13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:16:28.618031 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 20:16:29.903708 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 20:16:29.904705 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:05<13:29, 62.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129e03096338424e8debdc029e058759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:17:51.412371 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 20:17:52.655520 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 20:17:52.656517 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:07<12:29, 62.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1db371d52c44709bf83da243fdd3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:19:16.397359 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 20:19:17.627812 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 20:19:17.628810 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:12<11:32, 63.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d71330f32a4db4b107914e0a9154f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:15<10:31, 63.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad3f4092e914bcba497ef0854f6810d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:20:41.125551 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 20:20:42.381269 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 20:20:42.382265 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:19<09:29, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b6f8a815d64ea9b1fc0f7243402ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:22:06.567738 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 20:22:07.789505 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 20:22:07.790532 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:24<08:30, 63.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a27b22376d54678abcae9fafc6d541a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:23:30.782871 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 20:23:32.162985 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 20:23:32.163982 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:27<07:26, 63.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9265c51599a472b99c9c7d9e7dae70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:29<06:19, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93afd27ea7674cec8633e97b9d9f200d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:24:54.441444 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 20:24:55.661808 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 20:24:55.661808 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:32<05:15, 63.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62954e6d4fd4eeba58d4c90e769aaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:26:17.165167 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 20:26:18.515389 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 20:26:18.516387 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:35<04:12, 63.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9a2ee373e7453d81293f16484f725c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:27:40.063329 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 20:27:41.376092 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 20:27:41.377087 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:38<03:08, 62.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b745edbe9d5544b0bbb056ce045375af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:39<02:04, 62.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97652857cef0423d88e7c00c7e6f82ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:29:02.365010 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 20:29:03.552967 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 20:29:03.553964 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:41<01:02, 62.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ae442947894727bfcc57de508fb2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:30:26.503268 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 20:30:27.851251 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 20:30:27.851251 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [15:47<00:00, 63.14s/it]\n",
      "I0120 20:30:53.667126 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.009718603960569129\n",
      "I0120 20:30:53.673111 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 20:30:53.675107 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:30:53.676103 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:30:53.677101 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:30:57.362566 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 110.00it/s]\n",
      "I0120 20:31:04.129662 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:31:04.515892 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 20:31:04.515892 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:31:04.516890 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd1c6ea71f14643a3b7fbc2069df910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:31:19.518752 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 20:31:19.519749 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:31:19.519749 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:31:19.519749 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:31:19.520746 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:31:19.520746 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:31:19.521745 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:31:19.522741 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 20:31:19.522741 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:31:19.523739 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:31:22.799501 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 123.88it/s]\n",
      "I0120 20:31:27.988898 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:31:28.368607 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 20:31:28.368607 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:31:28.369605 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80209820c0f9411fb61d48819ab7f068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:31:43.385545 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 20:31:43.386544 15348 fine_tuned.py:368]   acc = 0.9934426229508196\n",
      "I0120 20:31:43.387541 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:31:43.387541 15348 fine_tuned.py:368]   fp = 4\n",
      "I0120 20:31:43.387541 15348 fine_tuned.py:368]   mcc = 0.9868525930577489\n",
      "I0120 20:31:43.388539 15348 fine_tuned.py:368]   tn = 274\n",
      "I0120 20:31:43.389535 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:31:43.390543 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 20:31:43.391529 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:31:43.391529 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:31:46.646332 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 100.86it/s]\n",
      "I0120 20:31:53.444118 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:31:54.038528 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 20:31:54.039525 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:31:54.040522 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1df4d262b9448eebbe0170aed86633b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:32:09.283196 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 20:32:09.284192 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:32:09.284192 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:32:09.285190 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:32:09.285190 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:32:09.285190 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:32:09.286188 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:32:09.287185 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 20:32:09.288183 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:32:09.289180 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:32:12.579967 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 115.57it/s]\n",
      "I0120 20:32:18.137261 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:32:18.767591 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 20:32:18.768589 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:32:18.769586 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb87d41c5654acca9f4158744e2b4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:32:33.852988 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 20:32:33.853984 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:32:33.853984 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:32:33.854981 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:32:33.854981 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:32:33.855979 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:32:33.855979 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:32:33.856976 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 20:32:33.857973 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:32:33.858971 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:32:37.094218 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.92it/s]\n",
      "I0120 20:32:42.629659 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:32:43.191425 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 20:32:43.192411 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:32:43.193408 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4b349fe6994b1f93a2352192437ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:32:58.324060 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 20:32:58.325032 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:32:58.325032 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:32:58.325032 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:32:58.326028 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:32:58.326028 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:32:58.327027 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:32:58.328025 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 20:32:58.329020 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:32:58.329020 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:33:02.169997 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 135.71it/s]\n",
      "I0120 20:33:06.949233 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:33:07.461862 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 20:33:07.462859 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:33:07.463857 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae480772630473dbeb9c06c77d116af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:33:22.665680 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 20:33:22.666693 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:33:22.667647 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:33:22.667647 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:33:22.668644 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:33:22.668644 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:33:22.669643 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:33:22.670639 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 20:33:22.671636 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:33:22.672634 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:33:25.898914 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 93.34it/s]\n",
      "I0120 20:33:33.172781 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:33:33.718357 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 20:33:33.720350 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:33:33.720350 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a19b160cc246f1afbd97c8899d48d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:33:48.949063 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 20:33:48.951057 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:33:48.952054 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:33:48.952054 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:33:48.953052 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:33:48.954050 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:33:48.954050 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:33:48.956043 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 20:33:48.957042 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:33:48.958039 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:33:52.852847 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.00it/s]\n",
      "I0120 20:33:58.278784 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:33:58.814371 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 20:33:58.816367 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:33:58.816367 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1aa3b429f94530b969fa195733529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:34:14.092993 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 20:34:14.092993 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:34:14.093990 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:34:14.093990 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:34:14.094989 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:34:14.095986 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:34:14.095986 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:34:14.096984 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 20:34:14.097981 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:34:14.098977 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:34:17.400607 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.82it/s]\n",
      "I0120 20:34:22.298619 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:34:22.670068 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 20:34:22.671066 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:34:22.671066 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5c32afdc74ce5853307a80e07372d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:34:38.052105 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 20:34:38.053126 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:34:38.053126 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:34:38.054100 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:34:38.054100 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:34:38.055097 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:34:38.055097 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:34:38.056094 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 20:34:38.058089 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:34:38.058089 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:34:41.431892 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 131.94it/s]\n",
      "I0120 20:34:46.820575 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:34:47.189741 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 20:34:47.190739 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:34:47.190739 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe35ce2d80194fbc8368f335c4b0a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:02.419828 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 20:35:02.420827 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:35:02.421823 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:35:02.421823 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:35:02.422822 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:35:02.422822 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:35:02.422822 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:35:02.423818 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 20:35:02.424816 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:35:02.425813 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:05.741550 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 129.79it/s]\n",
      "I0120 20:35:11.181885 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:35:11.537931 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 20:35:11.538928 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:35:11.538928 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599e5d866bd24196871200fa7e2b9b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:26.792199 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 20:35:26.793168 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:35:26.793168 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:35:26.794164 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:35:26.794164 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:35:26.794164 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:35:26.795162 15348 fine_tuned.py:368]   tp = 332\n",
      "I0120 20:35:26.795162 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 20:35:26.796160 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:35:26.798155 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:30.584209 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 124.98it/s]\n",
      "I0120 20:35:35.998177 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:35:36.372467 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 20:35:36.373491 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 20:35:36.373491 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831b08bee4614390b56c938ef2be7cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:51.602398 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 20:35:51.603395 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:35:51.603395 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:35:51.604392 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:35:51.604392 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:35:51.605391 15348 fine_tuned.py:368]   tn = 278\n",
      "I0120 20:35:51.605391 15348 fine_tuned.py:368]   tp = 332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:35:52.367350 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:35:52.368347 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:35:52.438161 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:35:52.440156 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:35:52.441153 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dedb1db23f45f6aa7c055a8be66503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [278 332]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       668\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 332  TN_H 278  TP_M 668  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [278 342]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       658\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 342  TN_H 278  TP_M 658  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [278 352]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       648\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 352  TN_H 278  TP_M 648  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [278 362]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       638\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 362  TN_H 278  TP_M 638  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [278 372]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       628\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 372  TN_H 278  TP_M 628  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [278 382]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       618\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 382  TN_H 278  TP_M 618  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [278 392]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       608\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 392  TN_H 278  TP_M 608  TN_M 720  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [279 401]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       599\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 401  TN_H 279  TP_M 599  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [279 411]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       589\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 411  TN_H 279  TP_M 589  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [279 421]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       579\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 421  TN_H 279  TP_M 579  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [279 431]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       569\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 431  TN_H 279  TP_M 569  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [279 441]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       559\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 441  TN_H 279  TP_M 559  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [279 451]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       549\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 451  TN_H 279  TP_M 549  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [279 461]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       539\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 461  TN_H 279  TP_M 539  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [279 471]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       529\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 471  TN_H 279  TP_M 529  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [279 481]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       519\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 481  TN_H 279  TP_M 519  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [279 491]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       509\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 491  TN_H 279  TP_M 509  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [279 501]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       499\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 501  TN_H 279  TP_M 499  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [279 511]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       489\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 511  TN_H 279  TP_M 489  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [279 521]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       479\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 521  TN_H 279  TP_M 479  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [279 531]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       469\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 531  TN_H 279  TP_M 469  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [279 541]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       459\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 541  TN_H 279  TP_M 459  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [279 551]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       449\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 551  TN_H 279  TP_M 449  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [279 561]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       439\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 561  TN_H 279  TP_M 439  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [279 571]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       429\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 571  TN_H 279  TP_M 429  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [279 581]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       419\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 581  TN_H 279  TP_M 419  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [279 591]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       409\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 591  TN_H 279  TP_M 409  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [279 601]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       399\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 601  TN_H 279  TP_M 399  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 890 unique(labels): [0 1] label counts: [279 611]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       389\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 611  TN_H 279  TP_M 389  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [279 621]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       379\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 621  TN_H 279  TP_M 379  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [279 631]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 631  TN_H 279  TP_M 369  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [279 641]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       359\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 641  TN_H 279  TP_M 359  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [279 651]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       349\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 651  TN_H 279  TP_M 349  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [279 661]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       339\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 661  TN_H 279  TP_M 339  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [279 671]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       329\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      1.00      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 671  TN_H 279  TP_M 329  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [279 681]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       319\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      1.00      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 681  TN_H 279  TP_M 319  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [279 691]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       309\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      1.00      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 691  TN_H 279  TP_M 309  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [279 701]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       299\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      1.00      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 701  TN_H 279  TP_M 299  TN_M 720  FP_M 1  FN_M 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [279 711]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       289\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      1.00      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 711  TN_H 279  TP_M 289  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [279 721]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       279\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 721  TN_H 279  TP_M 279  TN_M 720  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [270, 388, 353, 875, 379, 1246, 1232, 1006, 1226, 1723]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       995\n",
      "           1       0.97      0.81      0.88       995\n",
      "\n",
      "    accuracy                           0.89      1990\n",
      "   macro avg       0.90      0.89      0.89      1990\n",
      "weighted avg       0.90      0.89      0.89      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 801  TN_M 972  FP_M 23  FN_M 194\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [ 6 14]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       994\n",
      "           1       0.95      0.96      0.96       986\n",
      "\n",
      "    accuracy                           0.96      1980\n",
      "   macro avg       0.96      0.96      0.96      1980\n",
      "weighted avg       0.96      0.96      0.96      1980\n",
      "\n",
      "TP_H 14  TN_H 6  TP_M 951  TN_M 948  FP_M 46  FN_M 35\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [14 16]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       986\n",
      "           1       0.93      0.92      0.92       984\n",
      "\n",
      "    accuracy                           0.92      1970\n",
      "   macro avg       0.92      0.92      0.92      1970\n",
      "weighted avg       0.92      0.92      0.92      1970\n",
      "\n",
      "TP_H 16  TN_H 14  TP_M 906  TN_M 913  FP_M 73  FN_M 78\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [20 20]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       980\n",
      "           1       0.98      0.96      0.97       980\n",
      "\n",
      "    accuracy                           0.97      1960\n",
      "   macro avg       0.97      0.97      0.97      1960\n",
      "weighted avg       0.97      0.97      0.97      1960\n",
      "\n",
      "TP_H 20  TN_H 20  TP_M 938  TN_M 963  FP_M 17  FN_M 42\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [24 26]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       976\n",
      "           1       0.99      0.98      0.98       974\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 26  TN_H 24  TP_M 954  TN_M 965  FP_M 11  FN_M 20\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [25 35]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       975\n",
      "           1       0.98      0.99      0.98       965\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 35  TN_H 25  TP_M 952  TN_M 951  FP_M 24  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [32 38]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       968\n",
      "           1       0.99      0.97      0.98       962\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "TP_H 38  TN_H 32  TP_M 935  TN_M 961  FP_M 7  FN_M 27\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [33 47]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       967\n",
      "           1       0.97      0.99      0.98       953\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 47  TN_H 33  TP_M 942  TN_M 942  FP_M 25  FN_M 11\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [38 52]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       962\n",
      "           1       0.99      0.98      0.99       948\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 52  TN_H 38  TP_M 933  TN_M 951  FP_M 11  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [41 59]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       959\n",
      "           1       0.99      0.99      0.99       941\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 59  TN_H 41  TP_M 934  TN_M 946  FP_M 13  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [49 61]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       951\n",
      "           1       0.99      0.99      0.99       939\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 61  TN_H 49  TP_M 932  TN_M 939  FP_M 12  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [56 64]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       944\n",
      "           1       0.99      0.99      0.99       936\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 64  TN_H 56  TP_M 927  TN_M 935  FP_M 9  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [60 70]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       940\n",
      "           1       0.99      0.99      0.99       930\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 70  TN_H 60  TP_M 922  TN_M 931  FP_M 9  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [64 76]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       936\n",
      "           1       0.99      0.99      0.99       924\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 76  TN_H 64  TP_M 919  TN_M 930  FP_M 6  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [73 77]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       927\n",
      "           1       0.99      0.99      0.99       923\n",
      "\n",
      "    accuracy                           0.99      1850\n",
      "   macro avg       0.99      0.99      0.99      1850\n",
      "weighted avg       0.99      0.99      0.99      1850\n",
      "\n",
      "TP_H 77  TN_H 73  TP_M 918  TN_M 922  FP_M 5  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [77 83]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       923\n",
      "           1       0.99      0.99      0.99       917\n",
      "\n",
      "    accuracy                           0.99      1840\n",
      "   macro avg       0.99      0.99      0.99      1840\n",
      "weighted avg       0.99      0.99      0.99      1840\n",
      "\n",
      "TP_H 83  TN_H 77  TP_M 912  TN_M 918  FP_M 5  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [80 90]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       920\n",
      "           1       1.00      0.99      1.00       910\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 90  TN_H 80  TP_M 905  TN_M 918  FP_M 2  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [83 97]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       917\n",
      "           1       1.00      1.00      1.00       903\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 97  TN_H 83  TP_M 899  TN_M 915  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [ 88 102]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       912\n",
      "           1       1.00      1.00      1.00       898\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 102  TN_H 88  TP_M 894  TN_M 910  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [ 93 107]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       907\n",
      "           1       1.00      1.00      1.00       893\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 107  TN_H 93  TP_M 889  TN_M 905  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:37:41.621661 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 20:37:41.622658 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:37:42.756642 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:37:42.757639 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:37:43.293849 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 20:37:43.295844 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:37:43.752622 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 20:37:47.051952 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 20:37:47.052945 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 20:37:47.258559 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 53.97it/s]\n",
      "I0120 20:37:51.997387 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:37:52.156962 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 20:37:52.157960 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 20:37:52.158957 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 20:37:52.158957 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 20:37:52.159952 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 20:37:52.159952 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde5724ff3e240248feb169b96cba7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.558530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:22<05:20, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb645123a2d4b25a817cc7bb83210fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:38:22.092452 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 20:38:23.522451 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 20:38:23.523417 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029814"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:45<04:58, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9f1eed5ab743a3b45ca8e939f9c56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:38:52.031969 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 20:38:53.296383 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 20:38:53.297380 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:09<04:35, 23.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92109a0f72f47ab80b24738b85d24c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:39:22.515488 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 20:39:23.994798 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 20:39:23.995795 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:32<04:14, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cd5249d25c4c5bbcc235bcc33e56ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:54<03:47, 22.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b47299c1cb747a2a9f6db91c84c248d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000439"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:39:52.701912 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 20:39:55.345334 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 20:39:55.346330 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000444"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:18<03:28, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88e941a56bc4be1b3973e8ff512e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:40:24.305547 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 20:40:26.816630 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 20:40:26.816630 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:43<03:08, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52bbf0e538549e0b9ca8eb67e2070be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:40:55.634034 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 20:40:58.226543 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 20:40:58.228536 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:07<02:46, 23.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c353d67e38c47a3b99dfac711177dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:29<02:19, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d71d447e9349f2ba99c66009f9461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:41:26.883649 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 20:41:28.239400 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 20:41:28.240397 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:52<01:56, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabbb627c70c43098b89155138c2e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:41:57.262157 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 20:41:58.885060 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 20:41:58.886059 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:15<01:33, 23.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cafde8e432a4e15a2dbd2e7e6f799ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000218"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:42:27.657328 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 20:42:28.918307 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 20:42:28.919305 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:39<01:09, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfe0e830c394b50bd990e90520a00ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [05:00<00:45, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b0780f400b944e3bb09d8383772bd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:42:57.256514 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 20:42:58.600933 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 20:42:58.601930 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000165"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:24<00:22, 22.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccd87f45d1c43cb84852f3c6bebebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:43:27.640145 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 20:43:28.904810 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 20:43:28.905806 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:47<00:00, 23.14s/it]\n",
      "I0120 20:43:39.248471 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.08218763221359852\n",
      "I0120 20:43:39.257448 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 20:43:39.258445 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 20:43:39.259442 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:43:39.260440 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:43:42.615631 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 56.80it/s]\n",
      "I0120 20:43:47.034584 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:43:47.166233 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 20:43:47.167230 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:43:47.167230 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2ddd01645c408bbd96b985afb1ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:43:52.329431 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 20:43:52.330429 15348 fine_tuned.py:368]   acc = 0.9857142857142858\n",
      "I0120 20:43:52.330429 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 20:43:52.331426 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 20:43:52.331426 15348 fine_tuned.py:368]   mcc = 0.9713272088835889\n",
      "I0120 20:43:52.331426 15348 fine_tuned.py:368]   tn = 96\n",
      "I0120 20:43:52.332423 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 20:43:52.333420 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 20:43:52.333420 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:43:52.334417 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:43:55.813596 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.57it/s]\n",
      "I0120 20:44:00.215181 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:44:00.348855 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 20:44:00.349853 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:44:00.349853 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac679783036647a281d009430ccd34fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:05.556187 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 20:44:05.557185 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:44:05.558181 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:44:05.559179 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:44:05.559179 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:44:05.560176 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:44:05.560176 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:44:05.561173 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 20:44:05.562171 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:44:05.564166 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:08.849151 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.13it/s]\n",
      "I0120 20:44:12.657965 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:44:12.790608 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 20:44:12.791580 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:44:12.791580 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e2c95ba9424aab98769fbf61f2a797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:17.942728 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 20:44:17.943726 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:44:17.943726 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:44:17.944723 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:44:17.944723 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:44:17.944723 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:44:17.945719 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:44:17.946717 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 20:44:17.946717 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:44:17.947714 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:21.776646 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.60it/s]\n",
      "I0120 20:44:25.717859 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:44:25.845543 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 20:44:25.846513 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:44:25.847510 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb01ebcc0b0649af849a98d9d3ddea7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:30.992070 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 20:44:30.993068 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:44:30.993068 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:44:30.993068 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:44:30.994064 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:44:30.994064 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:44:30.995063 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:44:30.996060 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 20:44:30.996060 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:44:30.997057 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:35.087112 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.84it/s]\n",
      "I0120 20:44:39.821444 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:44:39.966057 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 20:44:39.967054 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:44:39.968051 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9293bb3fce484894eecad5045113d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:45.188265 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 20:44:45.189262 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:44:45.189262 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:44:45.190259 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:44:45.190259 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:44:45.190259 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:44:45.191256 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:44:45.192253 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 20:44:45.192253 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:44:45.193249 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:48.653446 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 48.08it/s]\n",
      "I0120 20:44:53.837179 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:44:53.956408 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 20:44:53.957406 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:44:53.957406 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2b5a39883d467a9555438fc80b377c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:44:59.043001 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 20:44:59.043001 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:44:59.043999 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:44:59.043999 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:44:59.044997 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:44:59.045995 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:44:59.045995 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:44:59.046992 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 20:44:59.047988 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:44:59.048986 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:02.459497 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.74it/s]\n",
      "I0120 20:45:06.777796 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:45:06.904329 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 20:45:06.905356 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:45:06.905356 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ca878e54dc451caf98430d9377614e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:12.252173 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 20:45:12.254168 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:45:12.254168 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:45:12.255166 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:45:12.256162 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:45:12.256162 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:45:12.257159 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:45:12.258157 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 20:45:12.259155 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:45:12.260152 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:15.936851 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.75it/s]\n",
      "I0120 20:45:20.193654 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:45:20.332285 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 20:45:20.333281 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:45:20.333281 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f81872e350446f393d8a9b6b15b403c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:25.380037 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 20:45:25.381035 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:45:25.381035 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:45:25.382033 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:45:25.382033 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:45:25.383030 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:45:25.383030 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:45:25.384027 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 20:45:25.385024 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:45:25.386021 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:28.773774 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:05<00:00, 39.10it/s]\n",
      "I0120 20:45:34.451948 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:45:34.583596 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 20:45:34.584624 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:45:34.584624 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8212b181ca4c7b93550199ea86e6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:39.831710 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 20:45:39.831710 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:45:39.832707 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:45:39.832707 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:45:39.833704 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:45:39.833704 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:45:39.833704 15348 fine_tuned.py:368]   tp = 112\n",
      "I0120 20:45:39.834702 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 20:45:39.835700 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:45:39.836697 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:43.076781 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.43it/s]\n",
      "I0120 20:45:47.380435 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:45:47.515416 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 20:45:47.516412 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:45:47.516412 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc8b1d5b8ac43de88415a29e1787dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:52.854248 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 20:45:52.855245 15348 fine_tuned.py:368]   acc = 0.8857142857142857\n",
      "I0120 20:45:52.856242 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 20:45:52.856242 15348 fine_tuned.py:368]   fp = 22\n",
      "I0120 20:45:52.857240 15348 fine_tuned.py:368]   mcc = 0.7822726822857548\n",
      "I0120 20:45:52.858237 15348 fine_tuned.py:368]   tn = 76\n",
      "I0120 20:45:52.858237 15348 fine_tuned.py:368]   tp = 110\n",
      "I0120 20:45:52.860233 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 20:45:52.861230 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:45:52.861230 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:45:57.208258 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.85it/s]\n",
      "I0120 20:46:00.903175 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:46:01.040780 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 20:46:01.041778 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 20:46:01.042775 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbc994d384c49e5a5a4d1851fc6bfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:46:06.299766 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 20:46:06.300762 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:46:06.300762 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:46:06.301760 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:46:06.302757 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:46:06.302757 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 20:46:06.302757 15348 fine_tuned.py:368]   tp = 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:46:07.093646 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:46:07.094644 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:46:07.170576 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 20:46:07.171575 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:46:07.172544 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506886bd99ab47bb95d0ed04a1a30237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [ 98 112]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       902\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 112  TN_H 98  TP_M 885  TN_M 900  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [ 99 121]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       901\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 121  TN_H 99  TP_M 877  TN_M 899  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [109 121]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       891\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 121  TN_H 109  TP_M 877  TN_M 889  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [119 121]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       881\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 121  TN_H 119  TP_M 877  TN_M 879  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [129 121]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       871\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 121  TN_H 129  TP_M 877  TN_M 869  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [139 121]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       861\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 121  TN_H 139  TP_M 877  TN_M 859  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [149 121]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       851\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 121  TN_H 149  TP_M 877  TN_M 849  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [159 121]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       841\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 121  TN_H 159  TP_M 877  TN_M 839  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [169 121]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       831\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 121  TN_H 169  TP_M 877  TN_M 829  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [179 121]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       821\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 121  TN_H 179  TP_M 877  TN_M 819  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [189 121]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       811\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 121  TN_H 189  TP_M 877  TN_M 809  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [199 121]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       801\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 121  TN_H 199  TP_M 877  TN_M 799  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [209 121]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       791\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 121  TN_H 209  TP_M 877  TN_M 789  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [218 122]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       782\n",
      "           1       1.00      1.00      1.00       878\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 122  TN_H 218  TP_M 877  TN_M 780  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [227 123]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       773\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 123  TN_H 227  TP_M 877  TN_M 771  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [237 123]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       763\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 123  TN_H 237  TP_M 877  TN_M 761  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [247 123]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       753\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 123  TN_H 247  TP_M 877  TN_M 751  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [257 123]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       743\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 123  TN_H 257  TP_M 877  TN_M 741  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [267 123]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       733\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 123  TN_H 267  TP_M 877  TN_M 731  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [277 123]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 123  TN_H 277  TP_M 877  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:47:36.672357 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 20:47:36.673352 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:47:37.453090 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 20:47:37.454087 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 20:47:37.520908 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 20:47:37.521905 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:47:37.523900 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 20:47:40.776036 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.30it/s]\n",
      "I0120 20:47:45.921386 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:47:46.287184 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 20:47:46.289480 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 20:47:46.290478 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 20:47:46.290478 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 20:47:46.291475 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 20:47:46.291475 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86e75acc64484b99446c45285e6861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:43<10:13, 43.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e58a637ee0460da8de24e4d4b30666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:48:43.560718 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 20:48:44.809462 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 20:48:44.810431 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:27<09:28, 43.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f24928da2b487696dee43b6723fa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:49:41.379850 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 20:49:42.613441 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 20:49:42.614438 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:11<08:47, 43.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34910278abb64ea28538aa92a5a07a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000020"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:50:39.402224 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 20:50:40.623377 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 20:50:40.624373 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:55<08:03, 43.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0216e11ffd24f908d80077c05c218bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:37<07:12, 43.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d940aae875ff4867818580a0d59725ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:51:35.609105 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 20:51:36.868251 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 20:51:36.869249 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:20<06:29, 43.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe911c1cda524fe5a64196f411c1513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:52:32.156766 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 20:52:33.439926 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 20:52:33.440925 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [05:03<05:46, 43.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d0b04842f6430e8a582cd195956e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:53:28.452592 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 20:53:29.651005 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 20:53:29.652999 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:46<05:01, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39cc5ea04804e11b80f1a3e37127d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:28<04:15, 42.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83b12febb3947efb07089866d5ee55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:54:24.776393 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 20:54:25.968424 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 20:54:25.969421 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:11<03:33, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4337f2f11a4661bd2f1f8e36432cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:55:20.732387 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 20:55:21.973872 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 20:55:21.974870 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:53<02:50, 42.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2668edcd7834326b7b7e90d3c7155ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:56:17.729654 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 20:56:18.963024 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 20:56:18.964021 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:37<02:09, 43.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e660f9e7804b3686f1680d1d226d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:20<01:25, 42.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1337ce1abd8a487bb9876a973132712a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:57:14.683793 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 20:57:15.912857 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 20:57:15.912857 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [10:03<00:42, 42.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b662f580a0e147dfb279368cdc71a4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:58:11.777365 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 20:58:13.034404 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 20:58:13.034404 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:46<00:00, 43.11s/it]\n",
      "I0120 20:58:32.953274 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.01216640682667976\n",
      "I0120 20:58:32.957264 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-210', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 20:58:32.958262 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 20:58:32.959258 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:58:32.960257 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:58:36.277371 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:05<00:00, 75.36it/s]\n",
      "I0120 20:58:42.614536 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:58:42.853406 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 20:58:42.854405 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:58:42.854405 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5f35fd8822416e9b788ad08aee5bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:58:53.117108 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 20:58:53.117108 15348 fine_tuned.py:368]   acc = 0.9926829268292683\n",
      "I0120 20:58:53.118107 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 20:58:53.119102 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:58:53.119102 15348 fine_tuned.py:368]   mcc = 0.982607368881035\n",
      "I0120 20:58:53.120101 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 20:58:53.120101 15348 fine_tuned.py:368]   tp = 120\n",
      "I0120 20:58:53.121099 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 20:58:53.122096 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:58:53.123094 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:58:56.601433 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.49it/s]\n",
      "I0120 20:59:01.643703 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:59:01.885664 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 20:59:01.885664 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:59:01.886662 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ab89ce17b345b69080b2bf710b62cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:12.141377 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 20:59:12.142375 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:59:12.142375 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:59:12.143372 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:59:12.143372 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:59:12.144369 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 20:59:12.144369 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 20:59:12.145367 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 20:59:12.146364 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:59:12.147362 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:15.448521 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 96.03it/s]\n",
      "I0120 20:59:20.605576 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:59:20.977581 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 20:59:20.978578 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:59:20.979578 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35e4b9dd5ed4627b4c3804acf62324a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:31.159077 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 20:59:31.160073 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:59:31.160073 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:59:31.161070 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:59:31.161070 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:59:31.162067 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 20:59:31.162067 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 20:59:31.163065 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 20:59:31.164061 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:59:31.164061 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:34.405433 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.97it/s]\n",
      "I0120 20:59:39.577245 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 20:59:39.824615 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 20:59:39.825613 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 20:59:39.825613 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81346b109fad4c18858b803e006e593f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:49.920776 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 20:59:49.922771 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 20:59:49.923768 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 20:59:49.923768 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 20:59:49.924766 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 20:59:49.926799 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 20:59:49.928783 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 20:59:49.929780 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 20:59:49.931775 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 20:59:49.932773 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 20:59:54.656168 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.88it/s]\n",
      "I0120 20:59:59.756311 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:00:00.021602 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 21:00:00.023596 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:00:00.024595 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64050e5d1a1949dd9e854a18c299f2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:10.487351 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 21:00:10.489346 15348 fine_tuned.py:368]   acc = 0.9975609756097561\n",
      "I0120 21:00:10.489346 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 21:00:10.490342 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:00:10.491341 15348 fine_tuned.py:368]   mcc = 0.9941961204540711\n",
      "I0120 21:00:10.491341 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:00:10.492338 15348 fine_tuned.py:368]   tp = 122\n",
      "I0120 21:00:10.493334 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 21:00:10.494333 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:00:10.495330 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:14.753222 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.93it/s]\n",
      "I0120 21:00:19.834975 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:00:20.085137 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 21:00:20.085137 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:00:20.086134 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd2beb9c9004849ab0479b3960a4b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:30.271831 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 21:00:30.272829 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:00:30.273827 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:00:30.273827 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:00:30.274823 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:00:30.275821 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:00:30.275821 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 21:00:30.277815 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 21:00:30.278813 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:00:30.278813 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:34.409225 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 88.47it/s]\n",
      "I0120 21:00:39.832825 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:00:40.131026 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 21:00:40.132024 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:00:40.132024 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c042a78b0fab477cb53ca293fc226059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:50.293238 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 21:00:50.295234 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:00:50.296231 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:00:50.297228 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:00:50.298225 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:00:50.299221 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:00:50.300219 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 21:00:50.302213 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 21:00:50.303211 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:00:50.304209 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:00:53.896653 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 89.47it/s]\n",
      "I0120 21:00:58.811702 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:00:59.063568 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 21:00:59.063568 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:00:59.064565 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35824022292e4945a8507e62345ecd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:09.328421 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 21:01:09.330416 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:01:09.332411 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:01:09.333409 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:01:09.333409 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:01:09.334406 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:01:09.335402 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 21:01:09.337397 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 21:01:09.338395 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:01:09.339393 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:13.138111 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:05<00:00, 81.07it/s]\n",
      "I0120 21:01:19.070357 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:01:19.340215 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 21:01:19.341183 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:01:19.341183 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea130bbc4654c65b6241e0aad1ac233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:29.666585 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 21:01:29.667582 15348 fine_tuned.py:368]   acc = 0.9951219512195122\n",
      "I0120 21:01:29.668580 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 21:01:29.668580 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:01:29.669576 15348 fine_tuned.py:368]   mcc = 0.9883986793042009\n",
      "I0120 21:01:29.669576 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:01:29.670574 15348 fine_tuned.py:368]   tp = 121\n",
      "I0120 21:01:29.671573 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 21:01:29.671573 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:01:29.672570 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:33.175420 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 85.71it/s]\n",
      "I0120 21:01:38.804867 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:01:39.035250 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 21:01:39.036248 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:01:39.036248 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706b8b0f3a6c41b5912b7e9c49b032e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:49.380582 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 21:01:49.381581 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:01:49.382578 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:01:49.383575 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:01:49.383575 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:01:49.384572 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:01:49.385570 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 21:01:49.386568 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 21:01:49.387564 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:01:49.388562 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:01:53.044336 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:05<00:00, 79.75it/s]\n",
      "I0120 21:01:59.096767 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:01:59.409928 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 21:01:59.410926 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:01:59.410926 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d0fb201594c42bce5c5b388d4d23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:02:09.838956 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 21:02:09.839949 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:02:09.839949 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:02:09.840945 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:02:09.841944 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:02:09.841944 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:02:09.842941 15348 fine_tuned.py:368]   tp = 123\n",
      "I0120 21:02:09.843938 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 21:02:09.844936 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:02:09.845933 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:02:13.532502 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 84.85it/s]\n",
      "I0120 21:02:19.233604 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:02:19.515850 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 21:02:19.516849 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:02:19.517844 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72601090bd08436c80b613e2f206d537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:02:29.970269 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 21:02:29.971265 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:02:29.972263 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:02:29.972263 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:02:29.973259 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:02:29.973259 15348 fine_tuned.py:368]   tn = 287\n",
      "I0120 21:02:29.974257 15348 fine_tuned.py:368]   tp = 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:02:30.913237 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:02:30.914235 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:02:30.984047 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:02:30.986042 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:02:30.987041 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6554c82bad4578b14dc7a31950ecef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [287 123]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       713\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 123  TN_H 287  TP_M 877  TN_M 711  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [287 133]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       713\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 133  TN_H 287  TP_M 867  TN_M 711  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [297 133]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       703\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 133  TN_H 297  TP_M 867  TN_M 701  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [307 133]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       693\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 133  TN_H 307  TP_M 867  TN_M 691  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [317 133]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       683\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 133  TN_H 317  TP_M 867  TN_M 681  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [327 133]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       673\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 133  TN_H 327  TP_M 867  TN_M 671  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [337 133]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       663\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 133  TN_H 337  TP_M 867  TN_M 661  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [347 133]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       653\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 133  TN_H 347  TP_M 867  TN_M 651  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [357 133]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       643\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 133  TN_H 357  TP_M 867  TN_M 641  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [367 133]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       633\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 133  TN_H 367  TP_M 867  TN_M 631  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [377 133]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       623\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 133  TN_H 377  TP_M 867  TN_M 621  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [387 133]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       613\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 133  TN_H 387  TP_M 867  TN_M 611  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [397 133]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       603\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 133  TN_H 397  TP_M 867  TN_M 601  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [407 133]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       593\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 133  TN_H 407  TP_M 867  TN_M 591  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [417 133]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       583\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 133  TN_H 417  TP_M 867  TN_M 581  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [427 133]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       573\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 133  TN_H 427  TP_M 867  TN_M 571  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [437 133]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       563\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 133  TN_H 437  TP_M 867  TN_M 561  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [447 133]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       553\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 133  TN_H 447  TP_M 867  TN_M 551  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [457 133]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       543\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 133  TN_H 457  TP_M 867  TN_M 541  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [467 133]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       533\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 133  TN_H 467  TP_M 867  TN_M 531  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:04:01.752934 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 21:04:01.754928 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:04:02.517508 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:04:02.518481 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:04:02.618216 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:04:02.621206 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:04:02.622203 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 21:04:05.943928 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:07<00:00, 78.02it/s]\n",
      "I0120 21:04:14.571743 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:04:14.996613 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 21:04:14.997611 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 21:04:14.997611 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 21:04:14.998607 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 21:04:14.998607 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 21:04:14.999604 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd4568f925543b5b6e63e18a3b2fd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:04<14:59, 64.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede197864cff48f4a9ccc161191acad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:05:39.610674 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 21:05:40.950513 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 21:05:40.951511 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:08<13:54, 64.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fa8572dbe3437a8c4c6b6bc5399fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:07:04.533517 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 21:07:05.857172 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 21:07:05.858164 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:12<12:51, 64.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf483f67bc14448f89c4c7722bc3fd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:08:28.784954 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 21:08:30.113269 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 21:08:30.114267 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:16<11:44, 64.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f6651e1b214ceaaebdcb86e63796ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:19<10:37, 63.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50eea3a61d84f80823cde5748bab4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:09:53.657129 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 21:09:55.015422 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 21:09:55.016420 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:22<09:32, 63.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d5ec5c2a3d406898ea258c36e59ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:11:17.495247 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 21:11:18.714819 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 21:11:18.715816 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:26<08:29, 63.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f4b51dc68c4566bd42747a984af3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:12:42.433262 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 21:12:43.849234 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 21:12:43.850232 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:31<07:27, 63.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f32017d37b14e74b308f619b52a6328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:34<06:22, 63.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8cbdbee7f4c5b97b56a14b7689c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:14:07.744978 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 21:14:09.521881 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 21:14:09.522878 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:40<05:21, 64.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be227dfe2ff498fae1b86054911a626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:15:33.914001 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 21:15:35.166070 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 21:15:35.167068 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:43<04:16, 64.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af335388233433c843f9a76d4ab7977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:16:58.150012 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 21:16:59.490054 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 21:16:59.490054 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:48<03:12, 64.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a4ce9f80cb445e82e487205ffe5cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [13:51<02:08, 64.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3787a3fbf846dab1601d4b0b40f804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:18:24.142638 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 21:18:25.468762 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 21:18:25.469760 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [14:57<01:04, 64.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bdb9a294fb4d94bbbf3c4706ac985e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:19:49.372305 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 21:19:50.721527 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 21:19:50.722525 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [16:01<00:00, 64.09s/it]\n",
      "I0120 21:20:16.415936 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.0017999982522204031\n",
      "I0120 21:20:16.419926 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 21:20:16.420923 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:20:16.421920 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:20:16.422918 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:20:19.735528 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 98.86it/s]\n",
      "I0120 21:20:26.940339 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:20:27.289405 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 21:20:27.290402 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:20:27.291400 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a16686bf75f41d1affce98dc4d92cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:20:41.716764 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 21:20:41.716764 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:20:41.717761 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:20:41.717761 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:20:41.717761 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:20:41.718758 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:20:41.718758 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:20:41.719755 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 21:20:41.720753 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:20:41.720753 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:20:44.883318 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 130.93it/s]\n",
      "I0120 21:20:50.328126 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:20:50.654254 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 21:20:50.655252 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:20:50.655252 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1c0c26898548698935ae5548b3fe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:21:04.986945 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 21:21:04.987943 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:21:04.987943 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:21:04.988940 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:21:04.988940 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:21:04.989936 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:21:04.989936 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:21:04.990935 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 21:21:04.991932 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:21:04.991932 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:21:08.202147 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 89.33it/s]\n",
      "I0120 21:21:15.853662 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:21:16.198312 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 21:21:16.198312 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:21:16.199310 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d652f5b07840bfbc63a2ef92dc0799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:21:31.297935 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 21:21:31.298931 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:21:31.299929 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:21:31.299929 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:21:31.300928 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:21:31.301924 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:21:31.301924 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:21:31.302921 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 21:21:31.304440 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:21:31.304965 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:21:35.304758 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 131.52it/s]\n",
      "I0120 21:21:40.793113 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:21:41.156141 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 21:21:41.157139 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:21:41.157139 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e5f5e267c4d2880da8125887e4866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:21:57.069129 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 21:21:57.070123 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:21:57.071122 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:21:57.071122 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:21:57.072118 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:21:57.072118 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:21:57.073115 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:21:57.074114 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 21:21:57.075111 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:21:57.076108 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:22:00.411424 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.92it/s]\n",
      "I0120 21:22:05.767779 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:22:06.132801 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 21:22:06.132801 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:22:06.133798 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ed94028d4e40a691e3916eafe4ef83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:22:21.302589 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 21:22:21.302589 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:22:21.303587 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:22:21.303587 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:22:21.303587 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:22:21.304583 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:22:21.304583 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:22:21.305581 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 21:22:21.306579 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:22:21.307575 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:22:24.539724 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 123.44it/s]\n",
      "I0120 21:22:30.237493 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:22:30.610661 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 21:22:30.611659 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:22:30.611659 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc777e43b594965a9e2be0b76f53dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:22:45.568497 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 21:22:45.569494 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:22:45.569494 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:22:45.570495 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:22:45.570495 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:22:45.571487 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:22:45.571487 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:22:45.572486 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 21:22:45.572486 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:22:45.573510 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:22:48.700266 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 119.94it/s]\n",
      "I0120 21:22:54.204343 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:22:54.720396 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 21:22:54.721393 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:22:54.722389 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb55e91cc204b538df6ae202c46f9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:23:10.038992 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 21:23:10.039990 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:23:10.040987 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:23:10.040987 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:23:10.041985 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:23:10.041985 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:23:10.042981 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:23:10.043979 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 21:23:10.043979 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:23:10.044976 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:23:14.157804 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 114.17it/s]\n",
      "I0120 21:23:20.665753 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:23:21.017810 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 21:23:21.018807 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:23:21.018807 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bca94a8671491c815f955bf979d25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:23:36.376280 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 21:23:36.378275 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:23:36.379272 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:23:36.379272 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:23:36.380269 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:23:36.381268 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:23:36.381268 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:23:36.383261 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 21:23:36.384306 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:23:36.385286 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:23:40.368048 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.27it/s]\n",
      "I0120 21:23:45.286753 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:23:45.653098 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 21:23:45.654068 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:23:45.654068 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce10e633f8074bdfb489f477a51a2805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:01.011596 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 21:24:01.012593 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:24:01.012593 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:24:01.013590 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:24:01.013590 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:24:01.014588 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:24:01.014588 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:24:01.015586 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 21:24:01.016583 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:24:01.017580 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:05.326809 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 131.87it/s]\n",
      "I0120 21:24:10.725630 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:24:11.081677 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 21:24:11.082675 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:24:11.083673 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1cd30ed52c4dbb983e5a47ac34d80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:26.469085 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 21:24:26.470082 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:24:26.470082 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:24:26.471081 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:24:26.472077 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:24:26.472077 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:24:26.473075 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:24:26.475069 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 21:24:26.476066 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:24:26.477064 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:29.731418 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:07<00:00, 80.99it/s]\n",
      "I0120 21:24:37.505429 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:24:37.989136 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 21:24:37.990133 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:24:37.990133 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410c35dacbe54bd0be558de5e5616991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:53.329020 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 21:24:53.330044 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:24:53.330044 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:24:53.330044 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:24:53.331014 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:24:53.331014 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:24:53.332011 15348 fine_tuned.py:368]   tp = 133\n",
      "I0120 21:24:53.333008 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 21:24:53.334006 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:24:53.335003 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:24:56.799191 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 127.09it/s]\n",
      "I0120 21:25:02.388261 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:25:02.813942 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 21:25:02.814942 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 21:25:02.814942 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8501f289a874e88a894db94833e6fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:25:18.039961 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 21:25:18.040958 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:25:18.040958 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:25:18.040958 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:25:18.041955 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:25:18.041955 15348 fine_tuned.py:368]   tn = 477\n",
      "I0120 21:25:18.042953 15348 fine_tuned.py:368]   tp = 133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:25:18.881775 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:25:18.881775 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:25:18.952789 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:25:18.953788 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:25:18.954785 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d32bd29c9c74c5aa19ca1ba6ee7efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [477 133]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       523\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 133  TN_H 477  TP_M 867  TN_M 521  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [487 133]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       513\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 133  TN_H 487  TP_M 867  TN_M 511  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [497 133]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       503\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 133  TN_H 497  TP_M 867  TN_M 501  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [507 133]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       493\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 133  TN_H 507  TP_M 867  TN_M 491  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [517 133]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       483\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 133  TN_H 517  TP_M 867  TN_M 481  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [527 133]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       473\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 133  TN_H 527  TP_M 867  TN_M 471  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [537 133]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       463\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 133  TN_H 537  TP_M 867  TN_M 461  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [547 133]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       453\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 133  TN_H 547  TP_M 867  TN_M 451  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [557 133]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       443\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 133  TN_H 557  TP_M 867  TN_M 441  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [567 133]\n",
      "Number of training examples  700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       433\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 133  TN_H 567  TP_M 867  TN_M 431  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [577 133]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       423\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 133  TN_H 577  TP_M 867  TN_M 421  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [587 133]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       413\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 133  TN_H 587  TP_M 867  TN_M 411  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [597 133]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       403\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 133  TN_H 597  TP_M 867  TN_M 401  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [607 133]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       393\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 133  TN_H 607  TP_M 867  TN_M 391  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [617 133]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       383\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 133  TN_H 617  TP_M 867  TN_M 381  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [627 133]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       373\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 133  TN_H 627  TP_M 867  TN_M 371  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [637 133]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       363\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 133  TN_H 637  TP_M 867  TN_M 361  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [647 133]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       353\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 133  TN_H 647  TP_M 867  TN_M 351  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [657 133]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       343\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 133  TN_H 657  TP_M 867  TN_M 341  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [667 133]\n",
      "Number of training examples  800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       333\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 133  TN_H 667  TP_M 867  TN_M 331  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [677 133]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       323\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 133  TN_H 677  TP_M 867  TN_M 321  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [687 133]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       313\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 133  TN_H 687  TP_M 867  TN_M 311  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [697 133]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       303\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 133  TN_H 697  TP_M 867  TN_M 301  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [707 133]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       293\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 133  TN_H 707  TP_M 867  TN_M 291  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [717 133]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       283\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 133  TN_H 717  TP_M 867  TN_M 281  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [727 133]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       273\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 133  TN_H 727  TP_M 867  TN_M 271  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [737 133]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       263\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 133  TN_H 737  TP_M 867  TN_M 261  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [747 133]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       253\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 133  TN_H 747  TP_M 867  TN_M 251  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [757 133]\n",
      "Number of training examples  890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       243\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 133  TN_H 757  TP_M 867  TN_M 241  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [767 133]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       233\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 133  TN_H 767  TP_M 867  TN_M 231  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [777 133]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       223\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 133  TN_H 777  TP_M 867  TN_M 221  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [787 133]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       213\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 133  TN_H 787  TP_M 867  TN_M 211  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [797 133]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       203\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 133  TN_H 797  TP_M 867  TN_M 201  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [807 133]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       193\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      0.99      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 133  TN_H 807  TP_M 867  TN_M 191  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [817 133]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       183\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      0.99      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 133  TN_H 817  TP_M 867  TN_M 181  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [827 133]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       173\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      0.99      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 133  TN_H 827  TP_M 867  TN_M 171  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [837 133]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       163\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      0.99      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 133  TN_H 837  TP_M 867  TN_M 161  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [847 133]\n",
      "Number of training examples  980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       153\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      0.99      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 133  TN_H 847  TP_M 867  TN_M 151  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [857 133]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       143\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 133  TN_H 857  TP_M 867  TN_M 141  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [867 133]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       133\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 133  TN_H 867  TP_M 867  TN_M 131  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [926, 900, 605, 889, 591, 1904, 1241, 1592, 1171, 1826]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       995\n",
      "           1       0.90      0.93      0.92       995\n",
      "\n",
      "    accuracy                           0.91      1990\n",
      "   macro avg       0.92      0.91      0.91      1990\n",
      "weighted avg       0.92      0.91      0.91      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 926  TN_M 894  FP_M 101  FN_M 69\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [ 9 11]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       991\n",
      "           1       0.90      0.99      0.94       989\n",
      "\n",
      "    accuracy                           0.94      1980\n",
      "   macro avg       0.95      0.94      0.94      1980\n",
      "weighted avg       0.95      0.94      0.94      1980\n",
      "\n",
      "TP_H 11  TN_H 9  TP_M 981  TN_M 881  FP_M 110  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [19 11]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       981\n",
      "           1       0.98      0.89      0.94       989\n",
      "\n",
      "    accuracy                           0.94      1970\n",
      "   macro avg       0.94      0.94      0.94      1970\n",
      "weighted avg       0.94      0.94      0.94      1970\n",
      "\n",
      "TP_H 11  TN_H 19  TP_M 882  TN_M 966  FP_M 15  FN_M 107\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [24 16]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       976\n",
      "           1       0.96      0.98      0.97       984\n",
      "\n",
      "    accuracy                           0.97      1960\n",
      "   macro avg       0.97      0.97      0.97      1960\n",
      "weighted avg       0.97      0.97      0.97      1960\n",
      "\n",
      "TP_H 16  TN_H 24  TP_M 962  TN_M 939  FP_M 37  FN_M 22\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [28 22]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       972\n",
      "           1       0.99      0.98      0.98       978\n",
      "\n",
      "    accuracy                           0.98      1950\n",
      "   macro avg       0.98      0.98      0.98      1950\n",
      "weighted avg       0.98      0.98      0.98      1950\n",
      "\n",
      "TP_H 22  TN_H 28  TP_M 955  TN_M 959  FP_M 13  FN_M 23\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [32 28]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       968\n",
      "           1       0.98      0.98      0.98       972\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 28  TN_H 32  TP_M 952  TN_M 949  FP_M 19  FN_M 20\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [37 33]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       963\n",
      "           1       0.99      0.98      0.99       967\n",
      "\n",
      "    accuracy                           0.99      1930\n",
      "   macro avg       0.99      0.99      0.99      1930\n",
      "weighted avg       0.99      0.99      0.99      1930\n",
      "\n",
      "TP_H 33  TN_H 37  TP_M 952  TN_M 952  FP_M 11  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [43 37]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       957\n",
      "           1       0.99      0.98      0.99       963\n",
      "\n",
      "    accuracy                           0.99      1920\n",
      "   macro avg       0.99      0.99      0.99      1920\n",
      "weighted avg       0.99      0.99      0.99      1920\n",
      "\n",
      "TP_H 37  TN_H 43  TP_M 946  TN_M 951  FP_M 6  FN_M 17\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [45 45]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       955\n",
      "           1       0.99      0.97      0.98       955\n",
      "\n",
      "    accuracy                           0.98      1910\n",
      "   macro avg       0.98      0.98      0.98      1910\n",
      "weighted avg       0.98      0.98      0.98      1910\n",
      "\n",
      "TP_H 45  TN_H 45  TP_M 928  TN_M 942  FP_M 13  FN_M 27\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [47 53]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       953\n",
      "           1       0.99      0.98      0.99       947\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 53  TN_H 47  TP_M 924  TN_M 948  FP_M 5  FN_M 23\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [49 61]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       951\n",
      "           1       0.99      0.99      0.99       939\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 61  TN_H 49  TP_M 927  TN_M 942  FP_M 9  FN_M 12\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [55 65]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       945\n",
      "           1       0.99      0.99      0.99       935\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 65  TN_H 55  TP_M 925  TN_M 939  FP_M 6  FN_M 10\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [57 73]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       943\n",
      "           1       1.00      0.99      0.99       927\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 73  TN_H 57  TP_M 921  TN_M 939  FP_M 4  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [61 79]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       939\n",
      "           1       0.99      0.99      0.99       921\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 79  TN_H 61  TP_M 916  TN_M 933  FP_M 6  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [69 81]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       931\n",
      "           1       1.00      1.00      1.00       919\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 81  TN_H 69  TP_M 915  TN_M 927  FP_M 4  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [72 88]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       928\n",
      "           1       1.00      1.00      1.00       912\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 88  TN_H 72  TP_M 908  TN_M 924  FP_M 4  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [79 91]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       921\n",
      "           1       1.00      1.00      1.00       909\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 91  TN_H 79  TP_M 905  TN_M 918  FP_M 3  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [83 97]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       917\n",
      "           1       1.00      1.00      1.00       903\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 97  TN_H 83  TP_M 899  TN_M 915  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [ 89 101]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       911\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 101  TN_H 89  TP_M 895  TN_M 909  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [ 94 106]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       906\n",
      "           1       1.00      1.00      1.00       894\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 106  TN_H 94  TP_M 891  TN_M 904  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:27:11.970282 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 21:27:11.971280 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:27:12.754981 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:27:12.755979 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:27:13.198620 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 21:27:13.200615 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:27:13.577445 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 21:27:17.084856 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 21:27:17.085853 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 21:27:17.295957 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 52.78it/s]\n",
      "I0120 21:27:21.543888 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:27:21.677535 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 21:27:21.678532 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 21:27:21.679528 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 21:27:21.680527 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 21:27:21.680527 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 21:27:21.681524 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38751499259e4642a6fa324474549754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.722033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:22<05:19, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ebf7edfeeab4fc3aedead91bc111156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:27:51.662726 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 21:27:52.937623 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 21:27:52.937623 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:46<04:58, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc698baa963447a481356658e2bb64d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.372685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:28:22.030333 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 21:28:23.261104 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 21:28:23.262103 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.462553"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:09<04:35, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a8e02f187f4ba89bab4b970aade83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:28:51.463680 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 21:28:52.863234 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 21:28:52.864231 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:31<04:11, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137c064c6cf04a54af6c20db8ede183b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:54<03:47, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e29fc4dea841b0b49048da8978d617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:29:22.534162 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 21:29:23.907585 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 21:29:23.908582 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:17<03:26, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac27e94e4d14a14b49b9469fcc1b525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:29:52.668195 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 21:29:54.007738 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 21:29:54.007738 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000331"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:41<03:04, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78bd676eb0242569661f2d18caa06eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:30:23.217535 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 21:30:24.503915 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 21:30:24.504912 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:04<02:41, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a73fb4ce2c5472db2aaa69486258d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:26<02:16, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08bfb90a7e7140478116799a98882a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:30:53.232722 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 21:30:54.668985 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 21:30:54.669983 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:50<01:55, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f62cb08caa42d0a00f2fd0cb9a1931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:31:24.507673 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 21:31:25.882513 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 21:31:25.883510 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:13<01:32, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0768ce385efc44f2b78496686d165f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:31:54.967632 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 21:31:56.627757 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 21:31:56.629751 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:37<01:10, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533c45b17f45448a8be06d751c3410a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:59<00:45, 22.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e421da4c37f452cbf9941f664153e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:32:25.311886 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 21:32:26.671103 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 21:32:26.672099 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:22<00:22, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69061a0de5f84d7eabf64dbac8f1445c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:32:55.562566 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 21:32:57.468831 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 21:32:57.468831 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:46<00:00, 23.08s/it]\n",
      "I0120 21:33:07.939860 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.10646330279374272\n",
      "I0120 21:33:07.943850 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 21:33:07.945844 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 21:33:07.946841 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:33:07.946841 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:12.021108 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.77it/s]\n",
      "I0120 21:33:15.842615 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:33:15.962876 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 21:33:15.963847 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:33:15.963847 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f96a0449ad747ca9c60df9c15dd3a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:21.132161 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 21:33:21.133159 15348 fine_tuned.py:368]   acc = 0.9809523809523809\n",
      "I0120 21:33:21.133159 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 21:33:21.133159 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 21:33:21.134156 15348 fine_tuned.py:368]   mcc = 0.9619969427322334\n",
      "I0120 21:33:21.134156 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 21:33:21.135154 15348 fine_tuned.py:368]   tp = 108\n",
      "I0120 21:33:21.135154 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 21:33:21.136151 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:33:21.137149 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:24.353368 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 45.22it/s]\n",
      "I0120 21:33:29.801077 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:33:29.912777 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 21:33:29.913774 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:33:29.914773 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61e0d3b3bb04977b63f0b61b4f6aaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:35.140005 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 21:33:35.141002 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 21:33:35.141999 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:33:35.141999 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 21:33:35.141999 15348 fine_tuned.py:368]   mcc = 0.99048503575804\n",
      "I0120 21:33:35.142996 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 21:33:35.143993 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:33:35.144991 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 21:33:35.144991 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:33:35.145989 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:38.430966 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.90it/s]\n",
      "I0120 21:33:42.716088 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:33:42.850734 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 21:33:42.851732 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:33:42.852699 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abe610ea93745d29217106cb6c443d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:48.385010 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 21:33:48.386007 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 21:33:48.387005 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:33:48.387005 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 21:33:48.388002 15348 fine_tuned.py:368]   mcc = 0.99048503575804\n",
      "I0120 21:33:48.388002 15348 fine_tuned.py:368]   tn = 98\n",
      "I0120 21:33:48.388999 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:33:48.389997 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 21:33:48.390995 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:33:48.391992 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:33:51.710639 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.01it/s]\n",
      "I0120 21:33:55.648253 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:33:55.796856 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 21:33:55.798851 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:33:55.798851 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1235cbf05244a2d9da182a4770c8416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:00.948208 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 21:34:00.949207 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:34:00.949207 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:34:00.950203 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:34:00.950203 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:34:00.951200 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:34:00.952198 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:34:00.953194 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 21:34:00.954192 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:34:00.955190 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:04.337450 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:06<00:00, 34.18it/s]\n",
      "I0120 21:34:10.804804 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:34:10.938478 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 21:34:10.939471 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:34:10.940441 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0238ef5624cfaaa8e37a6d53a3cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:16.239480 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 21:34:16.240477 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:34:16.240477 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:34:16.241474 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:34:16.241474 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:34:16.242472 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:34:16.242472 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:34:16.244467 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 21:34:16.244467 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:34:16.245465 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:19.785751 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 56.30it/s]\n",
      "I0120 21:34:23.922660 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:34:24.060410 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 21:34:24.060410 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:34:24.061407 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e6119257fd4e7b8c760f128bdbfe75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:29.354036 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 21:34:29.355034 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:34:29.356030 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:34:29.357028 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:34:29.357028 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:34:29.358024 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:34:29.358024 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:34:29.360019 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 21:34:29.361016 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:34:29.362014 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:33.950880 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.10it/s]\n",
      "I0120 21:34:37.765578 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:34:37.888593 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 21:34:37.888593 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:34:37.889619 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e514eb8b884482dac34e1bd5c299b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:43.053119 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 21:34:43.054114 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:34:43.055113 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:34:43.055113 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:34:43.055113 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:34:43.056111 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:34:43.056111 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:34:43.057108 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 21:34:43.058105 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:34:43.059103 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:46.392659 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 61.68it/s]\n",
      "I0120 21:34:50.579118 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:34:50.705750 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 21:34:50.706747 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:34:50.707744 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d194e4fa23144e65b1bde30f310834a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:56.049805 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 21:34:56.050803 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:34:56.050803 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:34:56.051801 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:34:56.051801 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:34:56.052798 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:34:56.052798 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:34:56.053797 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 21:34:56.054794 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:34:56.054794 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:34:59.285780 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.13it/s]\n",
      "I0120 21:35:03.096458 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:35:03.227393 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 21:35:03.228361 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:35:03.228361 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e2ef618aa2447fbda4b6c794d51480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:08.507938 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 21:35:08.508907 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:35:08.508907 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:35:08.509903 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:35:08.509903 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:35:08.509903 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:35:08.510926 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:35:08.511898 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 21:35:08.511898 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:35:08.512896 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:11.814841 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.33it/s]\n",
      "I0120 21:35:15.579700 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:35:15.711376 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 21:35:15.711376 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:35:15.712373 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f2e20e61264ecc92a3817da2c51298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:21.031044 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 21:35:21.032041 15348 fine_tuned.py:368]   acc = 0.5476190476190477\n",
      "I0120 21:35:21.033038 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:35:21.033038 15348 fine_tuned.py:368]   fp = 95\n",
      "I0120 21:35:21.033038 15348 fine_tuned.py:368]   mcc = 0.14755036140162425\n",
      "I0120 21:35:21.034036 15348 fine_tuned.py:368]   tn = 4\n",
      "I0120 21:35:21.034036 15348 fine_tuned.py:368]   tp = 111\n",
      "I0120 21:35:21.035034 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 21:35:21.036031 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:35:21.037028 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:24.436717 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.25it/s]\n",
      "I0120 21:35:28.736273 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:35:28.915793 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 21:35:28.916790 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 21:35:28.917788 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887708b4d90342df950a636903bf9a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:34.238353 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 21:35:34.239352 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:35:34.240349 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:35:34.240349 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:35:34.241344 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:35:34.241344 15348 fine_tuned.py:368]   tn = 99\n",
      "I0120 21:35:34.242343 15348 fine_tuned.py:368]   tp = 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:35:35.069164 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:35:35.070161 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:35:35.153937 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 21:35:35.156212 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:35:35.156929 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82790362b6e4e908a1d4d0c7477fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [ 99 111]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       901\n",
      "           1       1.00      1.00      1.00       889\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 111  TN_H 99  TP_M 888  TN_M 899  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [102 118]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       898\n",
      "           1       1.00      1.00      1.00       882\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 118  TN_H 102  TP_M 882  TN_M 896  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [111 119]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       889\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 119  TN_H 111  TP_M 881  TN_M 887  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [120 120]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       880\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 120  TN_H 120  TP_M 880  TN_M 878  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [130 120]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       870\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 120  TN_H 130  TP_M 880  TN_M 868  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [140 120]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       860\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 120  TN_H 140  TP_M 880  TN_M 858  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [150 120]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       850\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 120  TN_H 150  TP_M 880  TN_M 848  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [160 120]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       840\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 120  TN_H 160  TP_M 880  TN_M 838  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [170 120]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       830\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 120  TN_H 170  TP_M 880  TN_M 828  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [180 120]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       820\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 120  TN_H 180  TP_M 880  TN_M 818  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [188 122]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       812\n",
      "           1       1.00      1.00      1.00       878\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 122  TN_H 188  TP_M 878  TN_M 810  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [197 123]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       803\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 123  TN_H 197  TP_M 877  TN_M 801  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [207 123]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       793\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 123  TN_H 207  TP_M 877  TN_M 791  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [216 124]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       784\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 124  TN_H 216  TP_M 876  TN_M 782  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [226 124]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       774\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 124  TN_H 226  TP_M 876  TN_M 772  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [236 124]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       764\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 124  TN_H 236  TP_M 876  TN_M 762  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [246 124]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       754\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 124  TN_H 246  TP_M 876  TN_M 752  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [256 124]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       744\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 124  TN_H 256  TP_M 876  TN_M 742  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [266 124]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       734\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 124  TN_H 266  TP_M 876  TN_M 732  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [276 124]\n",
      "Number of training examples  400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       876\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 124  TN_H 276  TP_M 876  TN_M 722  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:37:04.287523 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 21:37:04.288520 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:37:05.062995 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:37:05.063992 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:37:05.122834 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 21:37:05.124830 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:37:05.124830 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 21:37:09.031673 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 95.60it/s]\n",
      "I0120 21:37:13.733898 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:37:14.017145 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 21:37:14.017145 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 21:37:14.018142 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 21:37:14.018142 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 21:37:14.019141 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 21:37:14.019141 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eff9558a07406aabc793f203075aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000072"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:42<09:52, 42.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb479c286f1475b9628ae2739d8eede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:38:10.046674 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 21:38:11.692301 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 21:38:11.694296 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:26<09:17, 42.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dc27d618744ead84330825babff263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:39:07.944048 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 21:39:09.205244 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 21:39:09.207239 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:10<08:37, 43.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d413cc97167146e1b143c834588d9c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:40:04.414401 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 21:40:05.665007 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 21:40:05.666032 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:53<07:53, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c71bc52cd14ff3a643c1463cbffcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:34<07:06, 42.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030e0cc37bdb497390c655b388ead921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:41:00.953810 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 21:41:02.603967 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 21:41:02.604965 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:19<06:28, 43.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb2e545327849cea4c0171e36a74412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:41:59.114929 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 21:42:00.397713 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 21:42:00.397713 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [05:02<05:46, 43.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff6904edec84efa94e8471aad803c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:42:55.911065 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 21:42:57.118880 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 21:42:57.119877 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:46<05:03, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af7c11eb98f40d8bda04d3e489b0358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:28<04:18, 43.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadc034f10334bc0b5621aaa651b0af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:43:53.231680 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 21:43:54.487684 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 21:43:54.488683 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:13<03:37, 43.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c79505dd0c4364af087f1431087f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:44:50.963807 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 21:44:52.256679 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 21:44:52.257677 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:56<02:53, 43.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16e2a53b1ac41b78fa506c55611c639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:45:47.663614 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 21:45:48.907488 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 21:45:48.907488 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:39<02:10, 43.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc9b883055a40b9b716d31522141711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:22<01:26, 43.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a729bdd79a4ad990079a30774e0f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:46:44.706256 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 21:46:45.988547 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 21:46:45.988547 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [10:05<00:43, 43.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c446ffd587234130ad5c0c9aa18ea5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:47:42.462914 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 21:47:43.825838 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 21:47:43.825838 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:50<00:00, 43.34s/it]\n",
      "I0120 21:48:04.107537 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.011935110443232515\n",
      "I0120 21:48:04.111526 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-350', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 21:48:04.112524 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 21:48:04.113522 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:48:04.113522 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:48:07.319603 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 88.11it/s]\n",
      "I0120 21:48:12.297774 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:48:12.549655 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 21:48:12.550653 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:48:12.550653 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3def0a2aed414a8b0c42d7f1eb1dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:48:22.774158 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 21:48:22.775156 15348 fine_tuned.py:368]   acc = 0.9975609756097561\n",
      "I0120 21:48:22.776153 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 21:48:22.776153 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:48:22.777150 15348 fine_tuned.py:368]   mcc = 0.9942491984062489\n",
      "I0120 21:48:22.777150 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:48:22.778148 15348 fine_tuned.py:368]   tp = 124\n",
      "I0120 21:48:22.779145 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:48:22.780142 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:48:22.781140 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:48:25.990929 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 98.37it/s]\n",
      "I0120 21:48:30.926850 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:48:31.175186 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 21:48:31.176182 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:48:31.176182 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfda2ee9773f447a8839bc7639188d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:48:41.219231 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 21:48:41.220246 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:48:41.220246 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:48:41.221226 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:48:41.221226 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:48:41.222222 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:48:41.223221 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:48:41.223221 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 21:48:41.224218 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:48:41.225215 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:48:44.483122 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:06<00:00, 64.21it/s]\n",
      "I0120 21:48:51.196179 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:48:51.465464 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 21:48:51.465464 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:48:51.466460 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9321e77a18340fbb35ef4f3f75ccd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:01.358482 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 21:49:01.358482 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:49:01.359479 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:49:01.359479 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:49:01.360477 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:49:01.360477 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:49:01.360477 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:49:01.361474 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 21:49:01.362471 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:49:01.362471 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:04.659597 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 97.07it/s]\n",
      "I0120 21:49:09.677601 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:49:09.918517 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 21:49:09.919514 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:49:09.919514 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e4b50106fd45509b2a85851a858482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:19.954831 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 21:49:19.955828 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:49:19.956826 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:49:19.956826 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:49:19.957823 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:49:19.957823 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:49:19.958821 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:49:19.959819 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 21:49:19.960816 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:49:19.960816 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:23.485263 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 92.34it/s]\n",
      "I0120 21:49:28.318942 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:49:28.600190 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 21:49:28.601188 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:49:28.601188 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239b045ca1f34c0588e154a062b73bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:38.578437 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 21:49:38.579435 15348 fine_tuned.py:368]   acc = 0.9926829268292683\n",
      "I0120 21:49:38.579435 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:49:38.580432 15348 fine_tuned.py:368]   fp = 3\n",
      "I0120 21:49:38.580432 15348 fine_tuned.py:368]   mcc = 0.9829968945713116\n",
      "I0120 21:49:38.581429 15348 fine_tuned.py:368]   tn = 282\n",
      "I0120 21:49:38.581429 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:49:38.582426 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 21:49:38.584421 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:49:38.585419 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:41.905420 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.01it/s]\n",
      "I0120 21:49:47.223569 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:49:47.640889 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 21:49:47.641887 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:49:47.641887 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f8de9095d964bfe941dc3cf6d3f43bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:49:58.197506 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 21:49:58.198504 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:49:58.198504 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:49:58.199500 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:49:58.200499 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:49:58.201495 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:49:58.201495 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:49:58.204487 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 21:49:58.205484 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:49:58.207479 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:01.850000 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 98.83it/s]\n",
      "I0120 21:50:06.372555 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:50:06.717267 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 21:50:06.718265 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:50:06.718265 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcbefe2cfef488eb8a975e904b19269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:16.901122 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 21:50:16.901122 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:50:16.902118 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:50:16.903117 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:50:16.903117 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:50:16.904114 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:50:16.905111 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:50:16.906109 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 21:50:16.907106 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:50:16.908103 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:20.348497 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 95.01it/s]\n",
      "I0120 21:50:24.952079 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:50:25.202040 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 21:50:25.203042 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:50:25.203042 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7117b24321874db1b93f48f2431f3960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:35.527300 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 21:50:35.529295 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:50:35.529295 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:50:35.529295 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:50:35.530291 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:50:35.530291 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:50:35.531288 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:50:35.531288 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 21:50:35.532285 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:50:35.533282 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:39.147659 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 95.94it/s]\n",
      "I0120 21:50:44.206679 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:50:44.457829 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 21:50:44.458800 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:50:44.458800 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef18f77c8b94a4a9d3411880cbda632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:54.720463 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 21:50:54.721461 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:50:54.722457 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:50:54.722457 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:50:54.722457 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:50:54.723455 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:50:54.723455 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:50:54.724452 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 21:50:54.725449 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:50:54.726447 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:50:58.390738 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 89.76it/s]\n",
      "I0120 21:51:03.864709 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:51:04.107614 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 21:51:04.107614 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:51:04.108611 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c623df530f4133acb19d95c264c763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:14.436779 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 21:51:14.437791 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:51:14.437791 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:51:14.437791 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:51:14.438774 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:51:14.438774 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:51:14.439792 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:51:14.440767 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 21:51:14.441766 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:51:14.441766 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:18.107824 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 87.44it/s]\n",
      "I0120 21:51:23.803423 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:51:24.108185 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 21:51:24.108185 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:51:24.108185 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e1a81a258c4495b545f0b226b27fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:34.584245 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 21:51:34.585243 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:51:34.585243 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:51:34.586240 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:51:34.586240 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:51:34.587237 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:51:34.587237 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 21:51:34.588236 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 21:51:34.588236 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:51:34.589233 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:38.240028 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 89.68it/s]\n",
      "I0120 21:51:43.768152 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:51:44.076901 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 21:51:44.077899 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 21:51:44.078897 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2219ce33045109f0d237ce9986c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:54.661833 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 21:51:54.661833 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 21:51:54.662829 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 21:51:54.662829 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 21:51:54.663827 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 21:51:54.663827 15348 fine_tuned.py:368]   tn = 285\n",
      "I0120 21:51:54.664823 15348 fine_tuned.py:368]   tp = 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:51:55.391508 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:51:55.391508 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:51:55.501720 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:51:55.502719 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:51:55.503715 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1625a8f47904a438fbbcd4f65fcf13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [285 125]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 125  TN_H 285  TP_M 875  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [285 135]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 135  TN_H 285  TP_M 865  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [285 145]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       855\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 145  TN_H 285  TP_M 855  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [285 155]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       845\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 155  TN_H 285  TP_M 845  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [285 165]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       835\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 165  TN_H 285  TP_M 835  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [285 175]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       715\n",
      "           1       1.00      1.00      1.00       825\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 175  TN_H 285  TP_M 825  TN_M 713  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [286 184]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       714\n",
      "           1       1.00      1.00      1.00       816\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 184  TN_H 286  TP_M 816  TN_M 712  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [288 192]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       712\n",
      "           1       1.00      1.00      1.00       808\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 192  TN_H 288  TP_M 808  TN_M 710  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [290 200]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       800\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 200  TN_H 290  TP_M 800  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [290 210]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       790\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 210  TN_H 290  TP_M 790  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [290 220]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       780\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 220  TN_H 290  TP_M 780  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [290 230]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       770\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 230  TN_H 290  TP_M 770  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [290 240]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       760\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 240  TN_H 290  TP_M 760  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [290 250]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 250  TN_H 290  TP_M 750  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [290 260]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       740\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 260  TN_H 290  TP_M 740  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [290 270]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       730\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 270  TN_H 290  TP_M 730  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [290 280]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       720\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 280  TN_H 290  TP_M 720  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [290 290]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       710\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 290  TN_H 290  TP_M 710  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [290 300]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 300  TN_H 290  TP_M 700  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [290 310]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       690\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 310  TN_H 290  TP_M 690  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:53:30.444976 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 21:53:30.446971 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:53:31.503145 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 21:53:31.504168 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 21:53:31.564979 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 21:53:31.567972 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 21:53:31.568970 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 21:53:34.591878 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 128.52it/s]\n",
      "I0120 21:53:39.636858 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 21:53:39.971002 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 21:53:39.971999 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 21:53:39.971999 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 21:53:39.972996 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 21:53:39.972996 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 21:53:39.973994 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b845d33c79944255b5363f1652046c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2.899194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:05<15:18, 65.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586ae89cdf064b5f8d009ba8cc7b51e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:55:06.894294 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 21:55:08.496034 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 21:55:08.498028 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:11<14:14, 65.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd1802b94d840f58ab9fd86d23cc21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000161"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:56:34.054507 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 21:56:35.260324 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 21:56:35.261317 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000067"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:17<13:09, 65.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0c15d6f3ab4a9083253cba63432c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:58:01.047984 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 21:58:02.278538 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 21:58:02.279536 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:23<12:04, 65.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed3e54073f4463fa8f05f0c2f984ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:28<10:55, 65.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bee6bc2c96745faa4675317d794a104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 21:59:28.192288 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 21:59:29.386389 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 21:59:29.388385 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:34<09:52, 65.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c34ff9d1ef847ccbcb6856c95bdb39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:00:56.017106 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 22:00:57.227943 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 22:00:57.228940 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:40<08:46, 65.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6183fff9ea7442968de0a7bc594dca69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:02:22.398440 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 22:02:24.023124 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 22:02:24.025118 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:46<07:40, 65.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4c944a4dfe43c6abbd4ce9a33bde0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:52<06:35, 65.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41954522647462d95dbc597fcbe4d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:03:51.430454 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 22:03:52.657858 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 22:03:52.658855 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:58<05:30, 66.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96e3f94b90c42b3915db1faa121eb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:05:19.069267 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 22:05:20.260290 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 22:05:20.261262 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [12:05<04:24, 66.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997b316d028a4203abd3fb21447f322b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:06:46.199195 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 22:06:47.876710 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 22:06:47.877708 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [13:11<03:18, 66.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1416ebeb0c5e43bdb2f1b0cf0d9617cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [14:16<02:11, 65.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d10b942b9a4138b673b720d0f28313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:08:13.777841 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 22:08:15.382953 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 22:08:15.383951 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [15:23<01:06, 66.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844e00e132a9458aa561a3ae83928e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:09:41.780419 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 22:09:42.976826 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 22:09:42.977824 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [16:29<00:00, 65.95s/it]\n",
      "I0120 22:10:09.156045 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.013906516592487012\n",
      "I0120 22:10:09.160034 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 22:10:09.161032 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 22:10:09.162030 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:10:09.163025 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:10:12.326809 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 610/610 [00:06<00:00, 97.59it/s]\n",
      "I0120 22:10:19.356008 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:10:19.752692 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 22:10:19.753734 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:10:19.753734 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9d33a7df054f58aac36d1faab70f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:10:35.423166 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 22:10:35.424162 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:10:35.424162 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:10:35.424162 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:10:35.425159 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:10:35.425159 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:10:35.426155 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:10:35.427152 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 22:10:35.427152 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:10:35.428152 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:10:38.712126 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 132.38it/s]\n",
      "I0120 22:10:44.164606 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:10:44.506725 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 22:10:44.507717 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:10:44.507717 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b6d99e92eb45ed95ffe8493ff05a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:00.118033 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 22:11:00.119031 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:11:00.120028 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:11:00.121026 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:11:00.121026 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:11:00.122024 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:11:00.122024 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:11:00.123021 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 22:11:00.124018 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:11:00.124018 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:03.816825 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 127.31it/s]\n",
      "I0120 22:11:09.397730 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:11:09.739815 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 22:11:09.740811 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:11:09.740811 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a6944880a049c9a35979793179d7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:25.546066 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 22:11:25.547572 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:11:25.547572 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:11:25.548569 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:11:25.548569 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:11:25.549567 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:11:25.550564 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:11:25.551560 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 22:11:25.552558 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:11:25.553556 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:28.933515 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 127.61it/s]\n",
      "I0120 22:11:34.490615 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:11:34.840854 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 22:11:34.841852 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:11:34.841852 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ded6ad426141348492950c1d9790b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:50.788115 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 22:11:50.789113 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:11:50.790110 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:11:50.790110 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:11:50.790110 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:11:50.791108 15348 fine_tuned.py:368]   tn = 290\n",
      "I0120 22:11:50.791108 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:11:50.792105 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 22:11:50.794099 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:11:50.794099 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:11:54.015883 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 119.70it/s]\n",
      "I0120 22:11:59.995965 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:12:00.405764 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 22:12:00.405764 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:12:00.406762 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5678d33411146e7b2eff41d1ad11d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:12:16.475793 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 22:12:16.476790 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:12:16.477787 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:12:16.477787 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:12:16.478785 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:12:16.478785 15348 fine_tuned.py:368]   tn = 290\n",
      "I0120 22:12:16.479781 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:12:16.480780 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 22:12:16.480780 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:12:16.481777 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:12:19.594547 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 128.31it/s]\n",
      "I0120 22:12:25.209232 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:12:25.692159 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 22:12:25.693156 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:12:25.693156 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db662b6a55f447bb3767bde4b7b8c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:12:41.613874 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 22:12:41.615869 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:12:41.615869 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:12:41.616866 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:12:41.617864 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:12:41.618861 15348 fine_tuned.py:368]   tn = 290\n",
      "I0120 22:12:41.618861 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:12:41.620855 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 22:12:41.621853 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:12:41.621853 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:12:44.894608 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 119.93it/s]\n",
      "I0120 22:12:50.210093 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:12:50.613349 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 22:12:50.613349 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:12:50.614346 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dd634b90014480bb5a3cae95515fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:13:06.521155 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 22:13:06.522152 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:13:06.522152 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:13:06.523149 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:13:06.524147 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:13:06.525146 15348 fine_tuned.py:368]   tn = 290\n",
      "I0120 22:13:06.525146 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:13:06.527139 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 22:13:06.528137 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:13:06.529134 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:13:09.750279 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 121.74it/s]\n",
      "I0120 22:13:15.654199 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:13:16.035180 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 22:13:16.036177 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:13:16.036177 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2f13a04ff64c46a5e594662f332dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:13:31.933339 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 22:13:31.934336 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:13:31.935333 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:13:31.935333 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:13:31.936333 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:13:31.936333 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:13:31.937329 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:13:31.937329 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 22:13:31.938326 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:13:31.939323 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:13:35.275321 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 102.46it/s]\n",
      "I0120 22:13:42.062544 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:13:42.427567 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 22:13:42.428565 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:13:42.428565 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd63af16b9ad424694af232a8e59c151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:13:58.404842 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 22:13:58.405838 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:13:58.405838 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:13:58.406836 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:13:58.406836 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:13:58.407834 15348 fine_tuned.py:368]   tn = 290\n",
      "I0120 22:13:58.407834 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:13:58.408832 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 22:13:58.409829 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:13:58.410825 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:14:01.831951 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 111.05it/s]\n",
      "I0120 22:14:08.035070 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:14:08.461872 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 22:14:08.461872 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:14:08.462870 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61360496968a4da0b6e21e54e7d22b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:14:24.417971 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 22:14:24.418967 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:14:24.419964 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:14:24.420962 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:14:24.420962 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:14:24.421960 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:14:24.422955 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:14:24.423953 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 22:14:24.424950 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:14:24.425948 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:14:27.958213 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 109.97it/s]\n",
      "I0120 22:14:34.285871 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:14:34.713726 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 22:14:34.714723 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:14:34.714723 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1dca7e0de64b09a126fbb79fce88e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:14:50.777936 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 22:14:50.778934 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:14:50.779932 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:14:50.779932 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:14:50.779932 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:14:50.780929 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:14:50.781928 15348 fine_tuned.py:368]   tp = 320\n",
      "I0120 22:14:50.782922 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 22:14:50.782922 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:14:50.783922 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:14:54.321612 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 105.06it/s]\n",
      "I0120 22:15:00.907710 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:15:01.259917 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 22:15:01.260915 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:15:01.260915 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cae5f5dc754600b6285fab223b7002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:15:17.114161 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 22:15:17.115158 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 22:15:17.115158 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:15:17.116156 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:15:17.117154 15348 fine_tuned.py:368]   mcc = 0.9967182157625235\n",
      "I0120 22:15:17.117154 15348 fine_tuned.py:368]   tn = 289\n",
      "I0120 22:15:17.118151 15348 fine_tuned.py:368]   tp = 320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:15:17.886629 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:15:17.887628 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:15:17.953453 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 22:15:17.954449 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:15:17.955447 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fdf88ef35d404b928a2cd601432eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [290 320]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       680\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 320  TN_H 290  TP_M 680  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [290 330]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       670\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 330  TN_H 290  TP_M 670  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [290 340]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       660\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 340  TN_H 290  TP_M 660  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [290 350]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       650\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 350  TN_H 290  TP_M 650  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [290 360]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       640\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 360  TN_H 290  TP_M 640  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [290 370]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       630\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 370  TN_H 290  TP_M 630  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [290 380]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       620\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 380  TN_H 290  TP_M 620  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [290 390]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       610\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 390  TN_H 290  TP_M 610  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [290 400]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 400  TN_H 290  TP_M 600  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [290 410]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       590\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TP_H 410  TN_H 290  TP_M 590  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [290 420]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       580\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 420  TN_H 290  TP_M 580  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [290 430]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       570\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 430  TN_H 290  TP_M 570  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [290 440]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       560\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 440  TN_H 290  TP_M 560  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [290 450]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       550\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 450  TN_H 290  TP_M 550  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [290 460]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       540\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 460  TN_H 290  TP_M 540  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [290 470]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       530\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 470  TN_H 290  TP_M 530  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [290 480]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       520\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 480  TN_H 290  TP_M 520  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [290 490]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       510\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 490  TN_H 290  TP_M 510  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [290 500]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 500  TN_H 290  TP_M 500  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [290 510]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       490\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 510  TN_H 290  TP_M 490  TN_M 709  FP_M 1  FN_M 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [290 520]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       480\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 520  TN_H 290  TP_M 480  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [290 530]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       470\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 530  TN_H 290  TP_M 470  TN_M 709  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [291 539]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       461\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 539  TN_H 291  TP_M 461  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [291 549]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       451\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 549  TN_H 291  TP_M 451  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [291 559]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       441\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 559  TN_H 291  TP_M 441  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [291 569]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       431\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 569  TN_H 291  TP_M 431  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [291 579]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       421\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 579  TN_H 291  TP_M 421  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [291 589]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       411\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 589  TN_H 291  TP_M 411  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [291 599]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       401\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 599  TN_H 291  TP_M 401  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 900 unique(labels): [0 1] label counts: [291 609]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       391\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 609  TN_H 291  TP_M 391  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [291 619]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       381\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 619  TN_H 291  TP_M 381  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [291 629]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       371\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 629  TN_H 291  TP_M 371  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [291 639]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       361\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 639  TN_H 291  TP_M 361  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [291 649]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       351\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 649  TN_H 291  TP_M 351  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [291 659]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       341\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      1.00      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 659  TN_H 291  TP_M 341  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [291 669]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       331\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      1.00      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 669  TN_H 291  TP_M 331  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [291 679]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       321\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      1.00      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 679  TN_H 291  TP_M 321  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [291 689]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      1.00      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 689  TN_H 291  TP_M 311  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [291 699]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       301\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      1.00      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 699  TN_H 291  TP_M 301  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [291 709]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       709\n",
      "           1       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 709  TN_H 291  TP_M 291  TN_M 709  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [750, 404, 14, 873, 71, 1489, 1789, 1409, 1635, 1687]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.75       995\n",
      "           1       0.72      0.96      0.82       995\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.83      0.79      0.79      1990\n",
      "weighted avg       0.83      0.79      0.79      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 958  TN_M 621  FP_M 374  FN_M 37\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [14  6]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93       986\n",
      "           1       0.92      0.96      0.94       994\n",
      "\n",
      "    accuracy                           0.94      1980\n",
      "   macro avg       0.94      0.94      0.94      1980\n",
      "weighted avg       0.94      0.94      0.94      1980\n",
      "\n",
      "TP_H 6  TN_H 14  TP_M 953  TN_M 901  FP_M 85  FN_M 41\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [20 10]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       980\n",
      "           1       0.97      0.92      0.95       990\n",
      "\n",
      "    accuracy                           0.95      1970\n",
      "   macro avg       0.95      0.95      0.95      1970\n",
      "weighted avg       0.95      0.95      0.95      1970\n",
      "\n",
      "TP_H 10  TN_H 20  TP_M 914  TN_M 955  FP_M 25  FN_M 76\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [23 17]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       977\n",
      "           1       0.92      0.99      0.96       983\n",
      "\n",
      "    accuracy                           0.95      1960\n",
      "   macro avg       0.96      0.95      0.95      1960\n",
      "weighted avg       0.96      0.95      0.95      1960\n",
      "\n",
      "TP_H 17  TN_H 23  TP_M 976  TN_M 893  FP_M 84  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [30 20]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       970\n",
      "           1       0.92      0.99      0.96       980\n",
      "\n",
      "    accuracy                           0.96      1950\n",
      "   macro avg       0.96      0.96      0.96      1950\n",
      "weighted avg       0.96      0.96      0.96      1950\n",
      "\n",
      "TP_H 20  TN_H 30  TP_M 973  TN_M 890  FP_M 80  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [39 21]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       961\n",
      "           1       0.97      0.99      0.98       979\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 21  TN_H 39  TP_M 970  TN_M 926  FP_M 35  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [45 25]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       955\n",
      "           1       0.96      0.99      0.98       975\n",
      "\n",
      "    accuracy                           0.98      1930\n",
      "   macro avg       0.98      0.98      0.98      1930\n",
      "weighted avg       0.98      0.98      0.98      1930\n",
      "\n",
      "TP_H 25  TN_H 45  TP_M 968  TN_M 918  FP_M 37  FN_M 7\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [54 26]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       946\n",
      "           1       0.97      0.99      0.98       974\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 26  TN_H 54  TP_M 969  TN_M 921  FP_M 25  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [64 26]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       936\n",
      "           1       0.99      0.99      0.99       974\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 26  TN_H 64  TP_M 961  TN_M 922  FP_M 14  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [68 32]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       932\n",
      "           1       0.98      0.98      0.98       968\n",
      "\n",
      "    accuracy                           0.98      1900\n",
      "   macro avg       0.98      0.98      0.98      1900\n",
      "weighted avg       0.98      0.98      0.98      1900\n",
      "\n",
      "TP_H 32  TN_H 68  TP_M 952  TN_M 913  FP_M 19  FN_M 16\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [72 38]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       928\n",
      "           1       0.99      0.99      0.99       962\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 38  TN_H 72  TP_M 952  TN_M 916  FP_M 12  FN_M 10\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [76 44]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       924\n",
      "           1       0.99      0.99      0.99       956\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 44  TN_H 76  TP_M 950  TN_M 914  FP_M 10  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [81 49]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       919\n",
      "           1       0.99      1.00      0.99       951\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 49  TN_H 81  TP_M 948  TN_M 910  FP_M 9  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [90 50]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       910\n",
      "           1       0.99      1.00      0.99       950\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 50  TN_H 90  TP_M 946  TN_M 903  FP_M 7  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [94 56]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       906\n",
      "           1       0.99      1.00      1.00       944\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 56  TN_H 94  TP_M 941  TN_M 901  FP_M 5  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [99 61]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       901\n",
      "           1       0.99      1.00      1.00       939\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 61  TN_H 99  TP_M 936  TN_M 896  FP_M 5  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [103  67]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       897\n",
      "           1       1.00      1.00      1.00       933\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 67  TN_H 103  TP_M 931  TN_M 894  FP_M 3  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [109  71]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       891\n",
      "           1       1.00      1.00      1.00       929\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 71  TN_H 109  TP_M 927  TN_M 889  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [110  80]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       890\n",
      "           1       1.00      1.00      1.00       920\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 80  TN_H 110  TP_M 918  TN_M 888  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [112  88]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       888\n",
      "           1       1.00      1.00      1.00       912\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 88  TN_H 112  TP_M 910  TN_M 886  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:17:07.235117 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 22:17:07.237112 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:17:07.998902 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:17:08.000896 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:17:08.484724 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 22:17:08.486718 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:17:08.861587 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 22:17:12.513255 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 22:17:12.514251 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 22:17:12.705857 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.31it/s]\n",
      "I0120 22:17:17.007614 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:17:17.172200 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 22:17:17.173200 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 22:17:17.174168 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 22:17:17.174168 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 22:17:17.175192 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 22:17:17.175192 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a301ff1f594a4603b1993f9e290be3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.686013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.645226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:23<05:25, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f876b9eebb314dd8bf3230e5072a1e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.554621"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:17:47.892786 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 22:17:49.147680 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 22:17:49.148677 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011487"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:47<05:06, 23.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12455c9c676c4762b62c4c53fdeac2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:18:18.956097 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 22:18:20.227805 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 22:18:20.228802 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003118"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:10<04:41, 23.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740a2fdbe6184d23b610149f8fa04f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:18:49.555156 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 22:18:50.778027 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 22:18:50.779024 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001565"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:34<04:18, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4400fcd4afeb481c9031cea9627dc3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:56<03:51, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48fa1151fd4420f869793fa6f73bbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:19:20.342770 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 22:19:21.644924 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 22:19:21.645921 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:20<03:29, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6ea32f48104dc09d8300f4f3fc816f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:19:50.968041 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 22:19:52.265380 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 22:19:52.265380 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:44<03:07, 23.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d99b3453ef403b9d709c421577c58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:20:22.054914 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 22:20:23.577832 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 22:20:23.578830 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:07<02:45, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca5a90ad6f04ffb9bd18293c8d729e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:30<02:19, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a381679108ff444eba6fe5206d7c9801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:20:53.340129 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 22:20:54.629475 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 22:20:54.630475 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:54<01:57, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.001241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61f2720590b4754b4d248b6b159fe67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:21:24.093269 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 22:21:25.326940 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 22:21:25.327963 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:17<01:33, 23.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cfba381c074b64adc05600792b2aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:21:54.983842 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 22:21:56.217943 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 22:21:56.218940 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:41<01:10, 23.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30176970cb3f4575a01001dff56fdde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000205"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [05:03<00:46, 23.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d812c4b52704166bba6d48e6cc97809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:22:25.800450 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 22:22:27.064586 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 22:22:27.065574 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:27<00:23, 23.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89662e9ed0b9459cbe41a9361cd228d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:22:56.632567 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 22:22:57.825045 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 22:22:57.826042 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:51<00:00, 23.41s/it]\n",
      "I0120 22:23:08.353189 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.09305587142893354\n",
      "I0120 22:23:08.357178 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 22:23:08.359171 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 22:23:08.360169 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:23:08.361167 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:11.539803 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 48.82it/s]\n",
      "I0120 22:23:16.638367 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:23:16.785561 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 22:23:16.786558 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:23:16.786558 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a96e16cdc34ddb9b6d3d2ff68023c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:22.291076 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 22:23:22.292103 15348 fine_tuned.py:368]   acc = 0.9809523809523809\n",
      "I0120 22:23:22.292103 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 22:23:22.293073 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 22:23:22.293073 15348 fine_tuned.py:368]   mcc = 0.9612152553329024\n",
      "I0120 22:23:22.294067 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 22:23:22.294067 15348 fine_tuned.py:368]   tp = 89\n",
      "I0120 22:23:22.295066 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 22:23:22.296063 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:23:22.296063 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:26.333977 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:04<00:00, 48.62it/s]\n",
      "I0120 22:23:31.286938 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:23:31.402662 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 22:23:31.403666 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:23:31.403666 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359fc20ba0ea476bbd86df449b9bf28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:36.754249 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 22:23:36.755246 15348 fine_tuned.py:368]   acc = 0.9857142857142858\n",
      "I0120 22:23:36.756244 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 22:23:36.757241 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:23:36.759237 15348 fine_tuned.py:368]   mcc = 0.9709195467257716\n",
      "I0120 22:23:36.760233 15348 fine_tuned.py:368]   tn = 118\n",
      "I0120 22:23:36.760233 15348 fine_tuned.py:368]   tp = 89\n",
      "I0120 22:23:36.763227 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 22:23:36.764223 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:23:36.765221 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:39.957132 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 62.07it/s]\n",
      "I0120 22:23:44.141406 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:23:44.268552 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 22:23:44.269549 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:23:44.269549 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382f0d2c99b04d59901fe677c76e1714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:49.669106 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 22:23:49.670104 15348 fine_tuned.py:368]   acc = 0.9952380952380953\n",
      "I0120 22:23:49.670104 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:23:49.671102 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 22:23:49.671102 15348 fine_tuned.py:368]   mcc = 0.9903627690509426\n",
      "I0120 22:23:49.672099 15348 fine_tuned.py:368]   tn = 118\n",
      "I0120 22:23:49.672099 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:23:49.674094 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 22:23:49.675091 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:23:49.675091 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:23:52.934660 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.26it/s]\n",
      "I0120 22:23:57.115749 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:23:57.230443 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 22:23:57.231441 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:23:57.231441 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c0f1e410f4436c900fafe3233bd3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:02.694191 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 22:24:02.695188 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:24:02.695188 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:24:02.696186 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:24:02.696186 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:24:02.697184 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:24:02.697184 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:24:02.698180 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 22:24:02.699177 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:24:02.700175 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:05.932952 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.64it/s]\n",
      "I0120 22:24:10.266741 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:24:10.412351 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 22:24:10.413350 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:24:10.414346 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2900666f504dbe88312a1fda362458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:15.850144 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 22:24:15.851142 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:24:15.851142 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:24:15.852139 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:24:15.852139 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:24:15.853136 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:24:15.853136 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:24:15.854134 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 22:24:15.855129 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:24:15.856129 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:19.232882 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.12it/s]\n",
      "I0120 22:24:23.034970 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:24:23.162170 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 22:24:23.163166 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:24:23.164165 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12273cb02271409d9f2513ab1ea275c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:28.651976 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 22:24:28.652973 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:24:28.653970 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:24:28.653970 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:24:28.654966 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:24:28.654966 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:24:28.655965 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:24:28.656962 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 22:24:28.657959 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:24:28.658956 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:32.202998 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.78it/s]\n",
      "I0120 22:24:36.581083 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:24:36.715698 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 22:24:36.716695 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:24:36.716695 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b718190afc48b4a7f6d4df4df6d585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:42.263062 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 22:24:42.264059 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:24:42.265057 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:24:42.265057 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:24:42.266055 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:24:42.266055 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:24:42.267053 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:24:42.268049 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 22:24:42.269048 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:24:42.270045 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:45.708397 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.77it/s]\n",
      "I0120 22:24:50.080654 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:24:50.195348 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 22:24:50.196345 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:24:50.196345 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41560df12771441bbf028943bdf51948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:55.725582 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 22:24:55.726579 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:24:55.727576 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:24:55.728575 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:24:55.728575 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:24:55.729570 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:24:55.729570 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:24:55.730569 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 22:24:55.731567 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:24:55.732563 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:24:59.280750 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 56.45it/s]\n",
      "I0120 22:25:03.310917 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:25:03.439644 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 22:25:03.440645 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:25:03.440645 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394ad1d3e88e4f5bb53756b3ac5ba783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:09.014109 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 22:25:09.014109 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:25:09.015107 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:25:09.015107 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:25:09.016104 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:25:09.016104 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:25:09.017101 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 22:25:09.018096 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 22:25:09.019095 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:25:09.019095 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:12.548928 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.83it/s]\n",
      "I0120 22:25:16.577017 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:25:16.690717 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 22:25:16.690717 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:25:16.691714 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de4c5bdf71644aa8e2aea52ab7499c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:22.253625 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 22:25:22.254622 15348 fine_tuned.py:368]   acc = 0.8809523809523809\n",
      "I0120 22:25:22.255621 15348 fine_tuned.py:368]   fn = 23\n",
      "I0120 22:25:22.256618 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 22:25:22.256618 15348 fine_tuned.py:368]   mcc = 0.7678374119922546\n",
      "I0120 22:25:22.257615 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 22:25:22.258613 15348 fine_tuned.py:368]   tp = 68\n",
      "I0120 22:25:22.259610 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 22:25:22.260605 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:25:22.261604 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:25.808974 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 58.04it/s]\n",
      "I0120 22:25:30.250218 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:25:30.385855 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 22:25:30.386853 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 22:25:30.387850 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a385d49cedf45d08d61e05ed8dc7f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:35.890674 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 22:25:35.891672 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:25:35.891672 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:25:35.891672 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:25:35.892669 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:25:35.892669 15348 fine_tuned.py:368]   tn = 119\n",
      "I0120 22:25:35.893665 15348 fine_tuned.py:368]   tp = 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:25:36.698678 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:25:36.699675 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:25:36.807392 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 22:25:36.808390 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:25:36.809387 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3530f341f67941c2b1bc0c4335286609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [119  91]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       881\n",
      "           1       1.00      1.00      1.00       909\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 91  TN_H 119  TP_M 906  TN_M 879  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [120 100]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       880\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 100  TN_H 120  TP_M 900  TN_M 878  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [130 100]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       870\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 100  TN_H 130  TP_M 900  TN_M 868  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [140 100]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       860\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 100  TN_H 140  TP_M 900  TN_M 858  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [149 101]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       851\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 101  TN_H 149  TP_M 899  TN_M 849  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [159 101]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       841\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 101  TN_H 159  TP_M 899  TN_M 839  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [169 101]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       831\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 101  TN_H 169  TP_M 899  TN_M 829  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [179 101]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       821\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 101  TN_H 179  TP_M 899  TN_M 819  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [189 101]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       811\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 101  TN_H 189  TP_M 899  TN_M 809  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [199 101]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       801\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 101  TN_H 199  TP_M 899  TN_M 799  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [208 102]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       792\n",
      "           1       1.00      1.00      1.00       898\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 102  TN_H 208  TP_M 898  TN_M 790  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [217 103]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       783\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 103  TN_H 217  TP_M 897  TN_M 781  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [227 103]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       773\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 103  TN_H 227  TP_M 897  TN_M 771  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [237 103]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       763\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 103  TN_H 237  TP_M 897  TN_M 761  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [247 103]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       753\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 103  TN_H 247  TP_M 897  TN_M 751  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [257 103]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       743\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 103  TN_H 257  TP_M 897  TN_M 741  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [267 103]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       733\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 103  TN_H 267  TP_M 897  TN_M 731  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [277 103]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       723\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 103  TN_H 277  TP_M 897  TN_M 721  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [287 103]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       713\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 103  TN_H 287  TP_M 897  TN_M 711  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [297 103]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       703\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n",
      "TP_H 103  TN_H 297  TP_M 897  TN_M 701  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:27:06.097994 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 22:27:06.099990 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:27:06.862725 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:27:06.863723 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:27:06.923564 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 22:27:06.924561 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:27:06.924561 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 22:27:10.007997 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:05<00:00, 77.21it/s]\n",
      "I0120 22:27:16.140535 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:27:16.412274 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 22:27:16.413272 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 22:27:16.413272 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 22:27:16.414269 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 22:27:16.415267 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 22:27:16.415267 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa29ce3ff3dd4ef1b59e6d05e66583b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000038"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:44<10:18, 44.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824047c2cb4b4367b25e61b8062ad689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:28:14.990603 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 22:28:16.677784 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 22:28:16.677784 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:29<09:40, 44.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ff28b7acb6490bb460e90d06e097e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:29:13.782473 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 22:29:15.089842 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 22:29:15.089842 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:14<08:54, 44.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c45dea5a277460ab4bf9aea6553cf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:30:12.702290 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 22:30:14.011497 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 22:30:14.012495 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:59<08:11, 44.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aa25234fb74a799a6e3549f6f15218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:41<07:18, 43.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c2b6f3e91641cb809a4fa0c54199d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:31:09.464082 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 22:31:10.732282 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 22:31:10.733279 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:24<06:32, 43.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d7a3b30be242d2898fcd86d9bb40f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:32:05.754718 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 22:32:06.985980 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 22:32:06.986978 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [05:07<05:48, 43.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb87ad49af94e80b45547170350d8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:33:02.387350 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 22:33:04.094908 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 22:33:04.095905 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:50<05:04, 43.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed62f63f3e74a3a8f68ef55f1561eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:33<04:19, 43.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5889dfe94483423882eee1fcd121c4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:33:59.875279 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 22:34:01.110514 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 22:34:01.111511 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:16<03:36, 43.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581fe511795b428196931bb6ee9cf582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:34:56.924370 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 22:34:58.140164 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 22:34:58.141162 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [08:00<02:53, 43.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302977730a224bef986bda60ebd49357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:35:55.127382 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 22:35:56.401087 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 22:35:56.402086 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:44<02:10, 43.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f4258a45ef4cb4bed31ecd0188d1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:27<01:26, 43.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962d163168f04609b0a000daed50fa60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:36:52.910620 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 22:36:54.103209 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 22:36:54.104206 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [10:11<00:43, 43.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01afd4a212e54c8f9e69527aed6958a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:37:50.197333 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 22:37:51.449541 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 22:37:51.450514 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:55<00:00, 43.69s/it]\n",
      "I0120 22:38:11.840637 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.012461065513030611\n",
      "I0120 22:38:11.843630 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-350', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 22:38:11.844626 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 22:38:11.845624 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:38:11.846622 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:38:15.053383 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.84it/s]\n",
      "I0120 22:38:19.671599 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:38:19.891038 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 22:38:19.892037 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:38:19.893007 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ba79451e8d414eb233168f0edc7e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:38:30.225716 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 22:38:30.226714 15348 fine_tuned.py:368]   acc = 0.9926829268292683\n",
      "I0120 22:38:30.227710 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 22:38:30.227710 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:38:30.227710 15348 fine_tuned.py:368]   mcc = 0.9805499648850532\n",
      "I0120 22:38:30.228708 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:38:30.229706 15348 fine_tuned.py:368]   tp = 100\n",
      "I0120 22:38:30.230702 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 22:38:30.231700 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:38:30.232697 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:38:33.307552 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 101.24it/s]\n",
      "I0120 22:38:37.668412 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:38:37.956619 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 22:38:37.957617 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:38:37.958614 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0584de6d644c94badc09ab6b8af553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:38:48.296211 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 22:38:48.296211 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:38:48.297208 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:38:48.297208 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:38:48.298205 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:38:48.298205 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:38:48.298205 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:38:48.299204 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 22:38:48.300201 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:38:48.300201 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:38:51.317749 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.96it/s]\n",
      "I0120 22:38:55.918269 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:38:56.144253 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 22:38:56.145250 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:38:56.145250 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0bc7933bf447b9b8a0aa3e270cac52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:06.489113 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 22:39:06.490110 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:39:06.490110 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:39:06.490110 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:39:06.491108 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:39:06.491108 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:39:06.492105 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:39:06.492105 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 22:39:06.493102 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:39:06.494100 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:09.555057 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 107.65it/s]\n",
      "I0120 22:39:14.143208 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:39:14.411731 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 22:39:14.411731 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:39:14.412727 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed10fac9f544b30add641fe1a7630d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:24.710460 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 22:39:24.711458 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:39:24.711458 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:39:24.712455 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:39:24.712455 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:39:24.712455 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:39:24.713452 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:39:24.714449 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 22:39:24.715447 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:39:24.715447 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:28.097496 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 93.00it/s]\n",
      "I0120 22:39:32.841998 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:39:33.073353 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 22:39:33.074350 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:39:33.074350 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32820385cd744a2395ea18751605d14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:43.424044 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 22:39:43.425041 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:39:43.425041 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:39:43.426038 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:39:43.426038 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:39:43.426038 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:39:43.427036 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:39:43.428034 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 22:39:43.428034 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:39:43.429031 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:39:46.800975 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.86it/s]\n",
      "I0120 22:39:51.667433 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:39:51.896245 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 22:39:51.897242 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:39:51.898239 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea81148aabb4453bc8a29190f4ca467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:02.321912 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 22:40:02.322909 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:40:02.323907 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:40:02.323907 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:40:02.324904 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:40:02.325903 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:40:02.325903 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:40:02.327896 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 22:40:02.327896 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:40:02.328893 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:05.616326 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 88.00it/s]\n",
      "I0120 22:40:10.709698 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:40:10.931105 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 22:40:10.932131 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:40:10.932131 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73242c58f694c759fb2fb4a3ab3c0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:21.470419 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 22:40:21.471417 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:40:21.472414 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:40:21.472414 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:40:21.473411 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:40:21.473411 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:40:21.473411 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:40:21.474407 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 22:40:21.475406 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:40:21.475406 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:24.736388 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.18it/s]\n",
      "I0120 22:40:29.553453 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:40:29.779848 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 22:40:29.779848 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:40:29.780845 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c7a86c6783478cbbb5a73e47fc7654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:40.246523 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 22:40:40.247520 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:40:40.247520 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:40:40.248696 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:40:40.248696 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:40:40.249667 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:40:40.249667 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:40:40.250662 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 22:40:40.250662 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:40:40.251662 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:43.553499 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.58it/s]\n",
      "I0120 22:40:48.369372 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:40:48.581077 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 22:40:48.582074 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:40:48.582074 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec743c39bc5743449584fc32fdb7c080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:40:59.045972 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 22:40:59.046970 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:40:59.047966 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:40:59.047966 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:40:59.048962 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:40:59.048962 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:40:59.049962 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:40:59.050958 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 22:40:59.051954 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:40:59.051954 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:02.558045 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 86.33it/s]\n",
      "I0120 22:41:08.263554 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:41:08.510892 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 22:41:08.511890 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:41:08.512888 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b5146110ec419ca39bfb20cc607aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:19.337802 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 22:41:19.338799 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:41:19.338799 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:41:19.338799 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:41:19.339796 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:41:19.339796 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:41:19.340794 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:41:19.341791 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 22:41:19.341791 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:41:19.342787 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:22.980174 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 90.19it/s]\n",
      "I0120 22:41:28.254684 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:41:28.500050 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 22:41:28.501048 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:41:28.501048 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43836a0ebbe5443eb6b33cc307ba3cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:39.235766 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 22:41:39.235766 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:41:39.236763 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:41:39.236763 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:41:39.237761 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:41:39.237761 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:41:39.237761 15348 fine_tuned.py:368]   tp = 103\n",
      "I0120 22:41:39.238758 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 22:41:39.239755 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:41:39.240752 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:43.216240 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 106.28it/s]\n",
      "I0120 22:41:47.384626 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:41:47.619000 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 22:41:47.619997 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 22:41:47.619997 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f131ac749642cca3a7e80d54b4d65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:58.255940 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 22:41:58.256937 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 22:41:58.256937 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 22:41:58.257934 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 22:41:58.257934 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 22:41:58.258931 15348 fine_tuned.py:368]   tn = 307\n",
      "I0120 22:41:58.258931 15348 fine_tuned.py:368]   tp = 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:41:59.240306 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:41:59.241304 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:41:59.370085 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 22:41:59.372079 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:41:59.373076 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a085a5cfa2ce40b6b0184c9d6d7d7573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [307 103]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       693\n",
      "           1       1.00      1.00      1.00       897\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 103  TN_H 307  TP_M 897  TN_M 691  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [313 107]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       687\n",
      "           1       1.00      1.00      1.00       893\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 107  TN_H 313  TP_M 893  TN_M 685  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [321 109]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       679\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 109  TN_H 321  TP_M 891  TN_M 677  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [328 112]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       672\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 112  TN_H 328  TP_M 888  TN_M 670  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [334 116]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       666\n",
      "           1       1.00      1.00      1.00       884\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 116  TN_H 334  TP_M 884  TN_M 664  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [343 117]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       657\n",
      "           1       1.00      1.00      1.00       883\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 117  TN_H 343  TP_M 883  TN_M 655  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [351 119]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       649\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 119  TN_H 351  TP_M 881  TN_M 647  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [361 119]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       639\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 119  TN_H 361  TP_M 881  TN_M 637  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [371 119]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       629\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 119  TN_H 371  TP_M 881  TN_M 627  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [381 119]\n",
      "Number of training examples  500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       619\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 119  TN_H 381  TP_M 881  TN_M 617  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [391 119]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       609\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 119  TN_H 391  TP_M 881  TN_M 607  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [401 119]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       599\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 119  TN_H 401  TP_M 881  TN_M 597  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [411 119]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       589\n",
      "           1       1.00      1.00      1.00       881\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 119  TN_H 411  TP_M 881  TN_M 587  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [420 120]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       580\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 120  TN_H 420  TP_M 880  TN_M 578  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [430 120]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       570\n",
      "           1       1.00      1.00      1.00       880\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 120  TN_H 430  TP_M 880  TN_M 568  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [439 121]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       561\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 121  TN_H 439  TP_M 879  TN_M 559  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [447 123]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       553\n",
      "           1       1.00      1.00      1.00       877\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 123  TN_H 447  TP_M 877  TN_M 551  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [455 125]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       545\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 125  TN_H 455  TP_M 875  TN_M 543  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [465 125]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       535\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 125  TN_H 465  TP_M 875  TN_M 533  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [475 125]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       525\n",
      "           1       1.00      1.00      1.00       875\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 125  TN_H 475  TP_M 875  TN_M 523  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:43:25.945010 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 22:43:25.946002 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:43:26.983420 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 22:43:26.984417 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 22:43:27.045255 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 22:43:27.047250 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:43:27.047250 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 22:43:30.088171 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 133.31it/s]\n",
      "I0120 22:43:34.931055 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:43:35.298117 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 22:43:35.299113 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 22:43:35.299113 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 22:43:35.300110 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 22:43:35.300110 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 22:43:35.301107 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63da5134d6fe46d1acd78017c2956705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [01:05<15:21, 65.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3932e4005c49838a4fe3806cf94fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:45:03.096508 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 22:45:04.407016 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 22:45:04.408013 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [02:13<14:22, 66.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22cdd0a1095b4e9b965cd5a457e8906d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:46:31.249584 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 22:46:32.549342 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 22:46:32.550340 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [03:19<13:15, 66.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3f71a01a114a8ab5b086a42690a229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:47:57.011640 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 22:47:58.768186 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 22:47:58.768186 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [04:24<12:05, 65.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23998da1f9ed4d198880f5b27b4848d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [05:28<10:53, 65.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a57d876c314ad4880c831710a561ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:49:23.456591 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 22:49:24.778160 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 22:49:24.779157 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [06:33<09:46, 65.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba26b803f1484e4a83ac10c884acee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:50:49.282314 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 22:50:50.593559 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 22:50:50.594532 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [07:38<08:41, 65.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db4ac48a95b49249a450a952cd2a413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:52:15.744123 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 22:52:16.963607 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 22:52:16.964605 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [08:44<07:37, 65.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d46e39bc14347868c259440ab7e0664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [09:46<06:27, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d0c7d3c69940f8b1e8b0f3f7be95ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:53:40.442621 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 22:53:41.977278 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 22:53:41.978275 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [10:52<05:23, 64.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76148e4545f64379ab8b457498909b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:55:05.178653 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 22:55:06.529367 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 22:55:06.530364 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [11:53<04:15, 63.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcb0267231e431ea4dda69c61ec9fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:56:27.265958 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 22:56:28.687850 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 22:56:28.688848 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [12:56<03:10, 63.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24daa88ee89f4c769ac175d3077c7393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [14:02<02:08, 64.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f8d614ab0a4a979d866d57409b34fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:57:55.155555 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 22:57:56.341085 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 22:57:56.342084 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [15:07<01:04, 64.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549dc6e6b83a4225a2e56159d20e0726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:59:20.698084 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 22:59:21.952835 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 22:59:21.953833 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [16:12<00:00, 64.83s/it]\n",
      "I0120 22:59:47.684237 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.008078355071071965\n",
      "I0120 22:59:47.689222 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 22:59:47.690218 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 22:59:47.692214 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 22:59:47.694209 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 22:59:50.719376 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 114.12it/s]\n",
      "I0120 22:59:56.846230 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 22:59:57.195296 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 22:59:57.196293 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 22:59:57.196293 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eebab1355ded457f902ff8013046ad87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:00:13.145306 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 23:00:13.145306 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:00:13.146303 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:00:13.146303 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:00:13.146303 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:00:13.147301 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:00:13.147301 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:00:13.148298 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 23:00:13.149296 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:00:13.150295 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:00:16.291652 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 131.81it/s]\n",
      "I0120 23:00:21.284538 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:00:21.690451 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 23:00:21.691448 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:00:21.691448 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75c935d3f914a02aaa39400a8f198e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:00:37.478285 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 23:00:37.479283 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:00:37.479283 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:00:37.480280 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:00:37.480280 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:00:37.481278 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:00:37.481278 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:00:37.482275 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 23:00:37.483271 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:00:37.484295 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:00:40.587763 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.10it/s]\n",
      "I0120 23:00:45.339983 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:00:45.660629 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 23:00:45.661628 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:00:45.661628 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6940e6e97ed4bca9341f92472c3df08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:01.448138 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 23:01:01.449135 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:01:01.449135 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:01:01.450132 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:01:01.450132 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:01:01.451130 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:01:01.451130 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:01:01.452127 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 23:01:01.452127 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:01:01.453124 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:04.668224 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 138.66it/s]\n",
      "I0120 23:01:09.380532 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:01:09.721617 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 23:01:09.722614 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:01:09.723612 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9953236a8e4b37b0df9b8359b65e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:25.467223 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 23:01:25.467223 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:01:25.468220 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:01:25.468220 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:01:25.468220 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:01:25.469217 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:01:25.469217 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:01:25.470215 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 23:01:25.471212 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:01:25.471212 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:28.566345 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 138.56it/s]\n",
      "I0120 23:01:33.299954 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:01:33.621978 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 23:01:33.622976 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:01:33.622976 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32edfc52ebd4fa29b8678815de5a906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:49.570670 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 23:01:49.571692 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:01:49.571692 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:01:49.571692 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:01:49.572667 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:01:49.572667 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:01:49.572667 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:01:49.573664 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 23:01:49.574661 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:01:49.574661 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:01:52.627057 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 137.19it/s]\n",
      "I0120 23:01:57.834846 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:01:58.176459 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 23:01:58.177488 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:01:58.177488 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa6c5aa4354464f9385b4fd5ea47f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:02:14.464540 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 23:02:14.465537 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:02:14.466535 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:02:14.466535 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:02:14.466535 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:02:14.467533 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:02:14.467533 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:02:14.468530 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 23:02:14.469527 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:02:14.469527 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:02:17.641778 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.13it/s]\n",
      "I0120 23:02:22.501352 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:02:22.823821 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 23:02:22.823821 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:02:22.824818 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec73c6c850a04f2993d2dc93d8528ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:02:38.840003 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 23:02:38.841000 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:02:38.841000 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:02:38.841997 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:02:38.841997 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:02:38.841997 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:02:38.842995 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:02:38.842995 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 23:02:38.843992 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:02:38.844990 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:02:41.921537 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 140.46it/s]\n",
      "I0120 23:02:47.026175 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:02:47.368292 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 23:02:47.369258 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:02:47.370257 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36db92eb884499eb107f8b4f7ed1072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:03.475457 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 23:03:03.476454 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:03:03.477452 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:03:03.477452 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:03:03.478451 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:03:03.478451 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:03:03.478451 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:03:03.479448 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 23:03:03.480444 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:03:03.481443 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:06.587126 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 136.74it/s]\n",
      "I0120 23:03:11.888572 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:03:12.212705 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 23:03:12.212705 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:03:12.213703 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817c17896ccf4a14b7f5bf29ad5b595f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:27.892387 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 23:03:27.893384 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:03:27.893384 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:03:27.894381 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:03:27.894381 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:03:27.894381 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:03:27.895379 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:03:27.895379 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 23:03:27.896377 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:03:27.897374 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:30.972943 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 139.70it/s]\n",
      "I0120 23:03:35.620774 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:03:35.980452 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 23:03:35.981449 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:03:35.981449 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c81a8b52ff8409a812b1f383618d7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:51.970563 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 23:03:51.971561 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:03:51.972557 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:03:51.972557 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:03:51.972557 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:03:51.973555 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:03:51.973555 15348 fine_tuned.py:368]   tp = 126\n",
      "I0120 23:03:51.974552 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 23:03:51.975549 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:03:51.975549 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:03:55.490078 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 138.64it/s]\n",
      "I0120 23:04:00.648820 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:04:00.987913 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 23:04:00.987913 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:04:00.988910 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb9623ce78d44e0ae86a31bc78e6cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:04:16.672935 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 23:04:16.672935 15348 fine_tuned.py:368]   acc = 0.9983606557377049\n",
      "I0120 23:04:16.673933 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 23:04:16.673933 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:04:16.674931 15348 fine_tuned.py:368]   mcc = 0.9949964825703047\n",
      "I0120 23:04:16.674931 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:04:16.674931 15348 fine_tuned.py:368]   tp = 125\n",
      "I0120 23:04:16.675928 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 23:04:16.676925 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:04:16.676925 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:04:19.752954 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 139.40it/s]\n",
      "I0120 23:04:24.872897 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:04:25.293771 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 23:04:25.294769 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:04:25.295767 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0f6ee3f8ca427495554002e6ac568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:04:41.510120 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 23:04:41.511118 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:04:41.512115 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:04:41.512115 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:04:41.512115 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:04:41.513112 15348 fine_tuned.py:368]   tn = 484\n",
      "I0120 23:04:41.513112 15348 fine_tuned.py:368]   tp = 126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:04:42.351235 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:04:42.352207 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:04:42.416037 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:04:42.417035 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:04:42.418032 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11174f15d1aa4a0da5a72c0b4276700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [484 126]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       516\n",
      "           1       1.00      1.00      1.00       874\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 126  TN_H 484  TP_M 874  TN_M 514  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [492 128]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       508\n",
      "           1       1.00      1.00      1.00       872\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 128  TN_H 492  TP_M 872  TN_M 506  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [502 128]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       498\n",
      "           1       1.00      1.00      1.00       872\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 128  TN_H 502  TP_M 872  TN_M 496  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [512 128]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       488\n",
      "           1       1.00      1.00      1.00       872\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 128  TN_H 512  TP_M 872  TN_M 486  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [522 128]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       478\n",
      "           1       1.00      1.00      1.00       872\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 128  TN_H 522  TP_M 872  TN_M 476  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [530 130]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       470\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 130  TN_H 530  TP_M 870  TN_M 468  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [540 130]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       460\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 130  TN_H 540  TP_M 870  TN_M 458  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [550 130]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       450\n",
      "           1       1.00      1.00      1.00       870\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 130  TN_H 550  TP_M 870  TN_M 448  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [559 131]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       441\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 131  TN_H 559  TP_M 869  TN_M 439  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [569 131]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       431\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 131  TN_H 569  TP_M 869  TN_M 429  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [578 132]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       422\n",
      "           1       1.00      1.00      1.00       868\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 132  TN_H 578  TP_M 868  TN_M 420  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [588 132]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       412\n",
      "           1       1.00      1.00      1.00       868\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 132  TN_H 588  TP_M 868  TN_M 410  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [598 132]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       402\n",
      "           1       1.00      1.00      1.00       868\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 132  TN_H 598  TP_M 868  TN_M 400  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [607 133]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       393\n",
      "           1       1.00      1.00      1.00       867\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 133  TN_H 607  TP_M 867  TN_M 391  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [616 134]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       384\n",
      "           1       1.00      1.00      1.00       866\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 134  TN_H 616  TP_M 866  TN_M 382  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [626 134]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       374\n",
      "           1       1.00      1.00      1.00       866\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 134  TN_H 626  TP_M 866  TN_M 372  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [635 135]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       365\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 135  TN_H 635  TP_M 865  TN_M 363  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [645 135]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       355\n",
      "           1       1.00      1.00      1.00       865\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 135  TN_H 645  TP_M 865  TN_M 353  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [654 136]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       346\n",
      "           1       1.00      1.00      1.00       864\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 136  TN_H 654  TP_M 864  TN_M 344  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [664 136]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       336\n",
      "           1       1.00      1.00      1.00       864\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 136  TN_H 664  TP_M 864  TN_M 334  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [673 137]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       327\n",
      "           1       1.00      1.00      1.00       863\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 137  TN_H 673  TP_M 863  TN_M 325  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [683 137]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       317\n",
      "           1       1.00      1.00      1.00       863\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 137  TN_H 683  TP_M 863  TN_M 315  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [692 138]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       308\n",
      "           1       1.00      1.00      1.00       862\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 138  TN_H 692  TP_M 862  TN_M 306  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [701 139]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       299\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 139  TN_H 701  TP_M 861  TN_M 297  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [711 139]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       289\n",
      "           1       1.00      1.00      1.00       861\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 139  TN_H 711  TP_M 861  TN_M 287  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [719 141]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       281\n",
      "           1       1.00      1.00      1.00       859\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 141  TN_H 719  TP_M 859  TN_M 279  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [727 143]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       273\n",
      "           1       1.00      1.00      1.00       857\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 143  TN_H 727  TP_M 857  TN_M 271  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [736 144]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       264\n",
      "           1       1.00      1.00      1.00       856\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 144  TN_H 736  TP_M 856  TN_M 262  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [746 144]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       254\n",
      "           1       1.00      1.00      1.00       856\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 144  TN_H 746  TP_M 856  TN_M 252  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [754 146]\n",
      "Number of training examples  900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       246\n",
      "           1       1.00      1.00      1.00       854\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 146  TN_H 754  TP_M 854  TN_M 244  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [764 146]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       236\n",
      "           1       1.00      1.00      1.00       854\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 146  TN_H 764  TP_M 854  TN_M 234  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [771 149]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       229\n",
      "           1       1.00      1.00      1.00       851\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 149  TN_H 771  TP_M 851  TN_M 227  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [781 149]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       219\n",
      "           1       1.00      1.00      1.00       851\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 149  TN_H 781  TP_M 851  TN_M 217  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [791 149]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       209\n",
      "           1       1.00      1.00      1.00       851\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 149  TN_H 791  TP_M 851  TN_M 207  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [800 150]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       200\n",
      "           1       1.00      1.00      1.00       850\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      0.99      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 150  TN_H 800  TP_M 850  TN_M 198  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [810 150]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       190\n",
      "           1       1.00      1.00      1.00       850\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      0.99      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 150  TN_H 810  TP_M 850  TN_M 188  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [817 153]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       183\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      0.99      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 153  TN_H 817  TP_M 847  TN_M 181  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [827 153]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       173\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      0.99      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 153  TN_H 827  TP_M 847  TN_M 171  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [837 153]\n",
      "Number of training examples  990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       163\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 153  TN_H 837  TP_M 847  TN_M 161  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [847 153]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       153\n",
      "           1       1.00      1.00      1.00       847\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 153  TN_H 847  TP_M 847  TN_M 151  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [910, 271, 465, 305, 20, 1049, 1166, 1609, 1685, 1180]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.58      0.73       995\n",
      "           1       0.70      0.99      0.82       995\n",
      "\n",
      "    accuracy                           0.78      1990\n",
      "   macro avg       0.84      0.78      0.77      1990\n",
      "weighted avg       0.84      0.78      0.77      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 984  TN_M 576  FP_M 419  FN_M 11\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [14  6]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       986\n",
      "           1       0.97      0.92      0.95       994\n",
      "\n",
      "    accuracy                           0.95      1980\n",
      "   macro avg       0.95      0.95      0.95      1980\n",
      "weighted avg       0.95      0.95      0.95      1980\n",
      "\n",
      "TP_H 6  TN_H 14  TP_M 918  TN_M 956  FP_M 30  FN_M 76\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [20 10]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96       980\n",
      "           1       0.97      0.96      0.96       990\n",
      "\n",
      "    accuracy                           0.96      1970\n",
      "   macro avg       0.96      0.96      0.96      1970\n",
      "weighted avg       0.96      0.96      0.96      1970\n",
      "\n",
      "TP_H 10  TN_H 20  TP_M 949  TN_M 949  FP_M 31  FN_M 41\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [21 19]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       979\n",
      "           1       0.94      0.98      0.96       981\n",
      "\n",
      "    accuracy                           0.96      1960\n",
      "   macro avg       0.96      0.96      0.96      1960\n",
      "weighted avg       0.96      0.96      0.96      1960\n",
      "\n",
      "TP_H 19  TN_H 21  TP_M 960  TN_M 919  FP_M 60  FN_M 21\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [29 21]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       971\n",
      "           1       0.96      0.98      0.97       979\n",
      "\n",
      "    accuracy                           0.97      1950\n",
      "   macro avg       0.97      0.97      0.97      1950\n",
      "weighted avg       0.97      0.97      0.97      1950\n",
      "\n",
      "TP_H 21  TN_H 29  TP_M 962  TN_M 927  FP_M 44  FN_M 17\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [33 27]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       967\n",
      "           1       0.97      0.98      0.98       973\n",
      "\n",
      "    accuracy                           0.97      1940\n",
      "   macro avg       0.97      0.97      0.97      1940\n",
      "weighted avg       0.97      0.97      0.97      1940\n",
      "\n",
      "TP_H 27  TN_H 33  TP_M 958  TN_M 933  FP_M 34  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [36 34]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       964\n",
      "           1       0.93      0.99      0.96       966\n",
      "\n",
      "    accuracy                           0.96      1930\n",
      "   macro avg       0.96      0.96      0.96      1930\n",
      "weighted avg       0.96      0.96      0.96      1930\n",
      "\n",
      "TP_H 34  TN_H 36  TP_M 958  TN_M 888  FP_M 76  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [44 36]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       956\n",
      "           1       0.96      0.99      0.98       964\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 36  TN_H 44  TP_M 955  TN_M 918  FP_M 38  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [50 40]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       950\n",
      "           1       0.98      0.99      0.99       960\n",
      "\n",
      "    accuracy                           0.98      1910\n",
      "   macro avg       0.99      0.98      0.98      1910\n",
      "weighted avg       0.99      0.98      0.98      1910\n",
      "\n",
      "TP_H 40  TN_H 50  TP_M 955  TN_M 926  FP_M 24  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [57 43]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       943\n",
      "           1       0.98      0.99      0.99       957\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 43  TN_H 57  TP_M 951  TN_M 923  FP_M 20  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [63 47]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       937\n",
      "           1       0.99      0.99      0.99       953\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 47  TN_H 63  TP_M 945  TN_M 925  FP_M 12  FN_M 8\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [66 54]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       934\n",
      "           1       0.99      1.00      0.99       946\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 54  TN_H 66  TP_M 942  TN_M 924  FP_M 10  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [73 57]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       927\n",
      "           1       0.99      1.00      0.99       943\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 57  TN_H 73  TP_M 939  TN_M 919  FP_M 8  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [78 62]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       922\n",
      "           1       0.99      1.00      0.99       938\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 62  TN_H 78  TP_M 934  TN_M 915  FP_M 7  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [85 65]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       915\n",
      "           1       0.99      1.00      0.99       935\n",
      "\n",
      "    accuracy                           0.99      1850\n",
      "   macro avg       0.99      0.99      0.99      1850\n",
      "weighted avg       0.99      0.99      0.99      1850\n",
      "\n",
      "TP_H 65  TN_H 85  TP_M 931  TN_M 909  FP_M 6  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [89 71]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       911\n",
      "           1       0.99      1.00      0.99       929\n",
      "\n",
      "    accuracy                           0.99      1840\n",
      "   macro avg       0.99      0.99      0.99      1840\n",
      "weighted avg       0.99      0.99      0.99      1840\n",
      "\n",
      "TP_H 71  TN_H 89  TP_M 925  TN_M 905  FP_M 6  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [99 71]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       901\n",
      "           1       1.00      1.00      1.00       929\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 71  TN_H 99  TP_M 925  TN_M 898  FP_M 3  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [104  76]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       896\n",
      "           1       1.00      1.00      1.00       924\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 76  TN_H 104  TP_M 920  TN_M 893  FP_M 3  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [109  81]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       891\n",
      "           1       1.00      1.00      1.00       919\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 81  TN_H 109  TP_M 915  TN_M 889  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [113  87]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       887\n",
      "           1       1.00      1.00      1.00       913\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 87  TN_H 113  TP_M 910  TN_M 885  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:06:23.797348 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:06:23.799343 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:06:24.542878 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:06:24.543903 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:06:24.988717 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:06:24.989714 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:06:25.358508 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 23:06:28.249347 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 23:06:28.250344 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 23:06:28.442829 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 64.14it/s]\n",
      "I0120 23:06:31.943252 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:06:32.059938 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 23:06:32.060935 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 23:06:32.060935 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 23:06:32.060935 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 23:06:32.061933 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 23:06:32.061933 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfde20812474db18aab8c5f0896037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.721920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.474727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:23<05:26, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dbe102544a04d8ea70efd944c0b6b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.526254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:07:02.623428 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 23:07:04.102514 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 23:07:04.102514 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107894"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:46<05:04, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd757e5304b4bde9104947d1ff513eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004223"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:07:33.108243 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 23:07:34.489603 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 23:07:34.489603 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002357"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:10<04:40, 23.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aeffa9b46e48fe880242dc77c374c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:08:03.958467 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 23:08:05.251659 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 23:08:05.252656 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000862"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:33<04:18, 23.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7b5ada53674ef4bcd43f58152894c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:55<03:50, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08115bf7b3a74c6bb6a6d2f69a926edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000623"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:08:34.295801 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 23:08:35.502822 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 23:08:35.502822 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:18<03:27, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471d621a577b48faa63640b383bc850f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:09:04.405833 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 23:09:05.637606 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 23:09:05.637606 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:42<03:04, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fe2cef238d4bcea0faac4d94b4d324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:09:34.424423 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 23:09:35.636497 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 23:09:35.637494 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [03:05<02:41, 23.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d92b04f27104fb381ddc5d82d954ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:27<02:16, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc64389dfb44007a9b805d419bd5951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:10:04.536777 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 23:10:05.750075 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 23:10:05.751072 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:50<01:54, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077e2fcf232f4cfea3ce18d89d3f2dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:10:35.093921 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 23:10:36.394363 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 23:10:36.394363 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [04:13<01:32, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4eab7164294560a7c71de65dde16b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:11:05.272670 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 23:11:06.592930 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 23:11:06.593897 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:36<01:09, 23.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d13e465351c420189de7df3f1e059d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000251"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:58<00:45, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f8123340d54ffa9de68820d5e70eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:11:35.518364 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 23:11:36.757326 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 23:11:36.758323 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [05:21<00:22, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e093d48a134d3aaa53eaeb271ad60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:05.753011 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 23:12:06.984699 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 23:12:06.985694 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:45<00:00, 23.01s/it]\n",
      "I0120 23:12:17.247113 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.09441632797133248\n",
      "I0120 23:12:17.250106 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 23:12:17.251102 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 23:12:17.252101 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:12:17.253098 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:20.375608 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 57.67it/s]\n",
      "I0120 23:12:24.853315 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:12:24.977982 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 23:12:24.978980 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:12:24.979978 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed0c7311b7143ff8ba10fd36f587403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:30.387625 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 23:12:30.388622 15348 fine_tuned.py:368]   acc = 0.9666666666666667\n",
      "I0120 23:12:30.388622 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 23:12:30.389620 15348 fine_tuned.py:368]   fp = 5\n",
      "I0120 23:12:30.389620 15348 fine_tuned.py:368]   mcc = 0.9330623065984991\n",
      "I0120 23:12:30.390618 15348 fine_tuned.py:368]   tn = 112\n",
      "I0120 23:12:30.390618 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 23:12:30.391615 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 23:12:30.392612 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:12:30.392612 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:33.501734 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.04it/s]\n",
      "I0120 23:12:36.977135 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:12:37.086841 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 23:12:37.087837 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:12:37.087837 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b063b89aee074a61bf45a77611c2791b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:42.465761 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 23:12:42.466759 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 23:12:42.466759 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:12:42.467756 15348 fine_tuned.py:368]   fp = 2\n",
      "I0120 23:12:42.467756 15348 fine_tuned.py:368]   mcc = 0.9809246787450706\n",
      "I0120 23:12:42.467756 15348 fine_tuned.py:368]   tn = 115\n",
      "I0120 23:12:42.468753 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:12:42.468753 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:12:42.469751 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:12:42.470749 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:45.528353 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.13it/s]\n",
      "I0120 23:12:49.005194 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:12:49.123906 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 23:12:49.125870 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:12:49.125870 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2b899ee5684e1fb4d060075a47043e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:54.472519 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 23:12:54.472519 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:12:54.473516 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:12:54.474514 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:12:54.474514 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:12:54.474514 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:12:54.475512 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:12:54.476509 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 23:12:54.477506 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:12:54.477506 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:12:57.678168 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 64.02it/s]\n",
      "I0120 23:13:01.258514 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:13:01.398140 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 23:13:01.399138 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:13:01.399138 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361df236ab1446d59740d3b5cef37921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:06.688863 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 23:13:06.689862 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:13:06.689862 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:13:06.690859 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:13:06.690859 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:13:06.690859 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:13:06.691857 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:13:06.691857 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 23:13:06.692853 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:13:06.693851 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:09.769790 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 66.33it/s]\n",
      "I0120 23:13:13.144239 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:13:13.250951 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 23:13:13.250951 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:13:13.251949 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e48c542404a54a3c731b65b765152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:18.621471 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 23:13:18.621471 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:13:18.622467 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:13:18.622467 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:13:18.623466 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:13:18.623466 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:13:18.624463 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:13:18.624463 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 23:13:18.625460 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:13:18.626456 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:21.880723 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 62.10it/s]\n",
      "I0120 23:13:25.582399 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:13:25.714078 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 23:13:25.715046 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:13:25.715046 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da12ed1a1fa44dab76de12d78612c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:31.080177 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 23:13:31.081175 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:13:31.081175 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:13:31.082171 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:13:31.082171 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:13:31.082171 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:13:31.083169 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:13:31.083169 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 23:13:31.084317 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:13:31.085290 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:34.432466 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 63.67it/s]\n",
      "I0120 23:13:38.021670 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:13:38.157332 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 23:13:38.158307 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:13:38.158307 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f58fc6e2ca4354a3daafbcc588ea80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:43.549082 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 23:13:43.549082 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:13:43.550077 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:13:43.550077 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:13:43.551074 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:13:43.551074 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:13:43.552074 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:13:43.552074 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 23:13:43.553070 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:13:43.554068 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:46.840466 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 64.03it/s]\n",
      "I0120 23:13:50.455365 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:13:50.567062 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 23:13:50.568060 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:13:50.568060 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fbd4230b4c4d1b9d900913f79eb789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:55.956615 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 23:13:55.956615 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:13:55.957613 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:13:55.957613 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:13:55.957613 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:13:55.958610 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:13:55.958610 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:13:55.959607 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 23:13:55.960605 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:13:55.961602 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:13:59.216894 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 60.50it/s]\n",
      "I0120 23:14:02.937454 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:14:03.049325 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 23:14:03.049325 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:14:03.050324 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992d3c29f3bc49ed922665d862d7f5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:08.441957 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 23:14:08.442955 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:14:08.442955 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:14:08.443953 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:14:08.443953 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:14:08.443953 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:14:08.444950 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:14:08.445949 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 23:14:08.446944 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:14:08.447942 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:11.755904 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 62.99it/s]\n",
      "I0120 23:14:15.352546 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:14:15.472731 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 23:14:15.473728 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:14:15.474727 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb1ec2d566544cc8d25e6c4185e3230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:20.873713 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 23:14:20.874710 15348 fine_tuned.py:368]   acc = 0.9428571428571428\n",
      "I0120 23:14:20.874710 15348 fine_tuned.py:368]   fn = 4\n",
      "I0120 23:14:20.874710 15348 fine_tuned.py:368]   fp = 8\n",
      "I0120 23:14:20.875708 15348 fine_tuned.py:368]   mcc = 0.8853644223185393\n",
      "I0120 23:14:20.875708 15348 fine_tuned.py:368]   tn = 109\n",
      "I0120 23:14:20.876706 15348 fine_tuned.py:368]   tp = 89\n",
      "I0120 23:14:20.877703 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 23:14:20.877703 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:14:20.878699 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:24.201532 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 59.27it/s]\n",
      "I0120 23:14:28.029111 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:14:28.144373 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 23:14:28.145371 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:14:28.145371 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d791b87056134e9ea4747549ae083fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:33.491281 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 23:14:33.491281 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:14:33.491281 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:14:33.492278 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:14:33.492278 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:14:33.493275 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:14:33.493275 15348 fine_tuned.py:368]   tp = 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:14:34.278231 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:14:34.279227 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:14:34.343057 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:14:34.344054 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:14:34.345052 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9634d7bc9f407a8b29511434f76fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [117  93]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       883\n",
      "           1       1.00      1.00      1.00       907\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 93  TN_H 117  TP_M 904  TN_M 881  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [121  99]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       879\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 99  TN_H 121  TP_M 899  TN_M 877  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [131  99]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       869\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 99  TN_H 131  TP_M 899  TN_M 867  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [141  99]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       859\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 99  TN_H 141  TP_M 899  TN_M 857  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [151  99]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       849\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 99  TN_H 151  TP_M 899  TN_M 847  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [161  99]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       839\n",
      "           1       1.00      1.00      1.00       901\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 99  TN_H 161  TP_M 899  TN_M 837  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [170 100]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       830\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 100  TN_H 170  TP_M 899  TN_M 828  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [179 101]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       821\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 101  TN_H 179  TP_M 899  TN_M 819  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [189 101]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       811\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 101  TN_H 189  TP_M 899  TN_M 809  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [199 101]\n",
      "Number of training examples  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       801\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 101  TN_H 199  TP_M 899  TN_M 799  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [209 101]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       791\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 101  TN_H 209  TP_M 899  TN_M 789  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [219 101]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       781\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 101  TN_H 219  TP_M 899  TN_M 779  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [229 101]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       771\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 101  TN_H 229  TP_M 899  TN_M 769  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [239 101]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       761\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 101  TN_H 239  TP_M 899  TN_M 759  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [249 101]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       751\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 101  TN_H 249  TP_M 899  TN_M 749  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [259 101]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       741\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 101  TN_H 259  TP_M 899  TN_M 739  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [269 101]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       731\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 101  TN_H 269  TP_M 899  TN_M 729  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [279 101]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       721\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 101  TN_H 279  TP_M 899  TN_M 719  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [289 101]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       711\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 101  TN_H 289  TP_M 899  TN_M 709  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [299 101]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       701\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TP_H 101  TN_H 299  TP_M 899  TN_M 699  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:15:58.819625 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:15:58.821620 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:15:59.573608 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:15:59.574611 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:15:59.636440 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:15:59.637437 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:15:59.638435 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 23:16:02.661416 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.80it/s]\n",
      "I0120 23:16:07.390075 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:16:07.617970 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 23:16:07.617970 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0120 23:16:07.617970 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 23:16:07.618967 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 23:16:07.619965 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 23:16:07.619965 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65127adb1c7040918c18a56129e022b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000767"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:43<10:15, 43.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead38c9f514c4462b98eebbf98f44036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000122"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:17:05.289042 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0120 23:17:06.563363 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0120 23:17:06.564224 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:28<09:35, 44.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7eef44be9640c7b142e4b8c3faade9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:18:03.860752 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0120 23:18:05.108045 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0120 23:18:05.108045 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:13<08:51, 44.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de8b22cc81a4e33a965692813137ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:19:03.053615 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0120 23:19:04.300293 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0120 23:19:04.301290 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:58<08:09, 44.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4398c606fd49e4baaf0426566f526c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:41<07:20, 44.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df5e23bffc44385b2aa5af5731c7f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:20:00.835718 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0120 23:20:02.134443 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0120 23:20:02.135441 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:25<06:36, 44.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21634d10183343b9993237d630fce7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:20:58.576555 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0120 23:20:59.889089 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0120 23:20:59.890086 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [05:09<05:52, 44.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8497b2db5ff3438bbbf0f7ba33b5cf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:21:57.304884 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0120 23:21:58.531954 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0120 23:21:58.532951 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:54<05:10, 44.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296b210a7c7244dfb797e46d7428c085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [06:36<04:23, 43.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f7ed4ebf254b4099c26fbdacba97fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:22:55.108913 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0120 23:22:56.689489 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0120 23:22:56.690487 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [07:22<03:41, 44.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4913bb20294f0081cb85cf617370e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:23:54.796169 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0120 23:23:55.978006 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 23:23:55.979003 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [08:05<02:55, 43.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e2c4aa592b49e89063b3522df9dcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:24:47.227808 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0120 23:24:48.522343 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0120 23:24:48.522343 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [08:45<02:08, 42.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049c239c5f2247c18f2330f82f804a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [09:23<01:22, 41.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010f78186120424c8802aa0f50d0b4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:25:39.415182 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0120 23:25:40.589041 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0120 23:25:40.589041 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [10:03<00:40, 40.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61593d8e064e1483f08f531ded21e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:26:31.512374 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0120 23:26:32.746372 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0120 23:26:32.746372 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [10:43<00:00, 42.87s/it]\n",
      "I0120 23:26:50.748435 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.009568733237322094\n",
      "I0120 23:26:50.752425 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-280', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0120 23:26:50.753422 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:26:50.754418 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:26:50.754418 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:26:53.719485 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 100.61it/s]\n",
      "I0120 23:26:58.049896 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:26:58.260333 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 23:26:58.260333 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:26:58.261332 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ce31a64e5c41cb8647a268b6b17f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:07.496841 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 23:27:07.497839 15348 fine_tuned.py:368]   acc = 0.9902439024390244\n",
      "I0120 23:27:07.498835 15348 fine_tuned.py:368]   fn = 3\n",
      "I0120 23:27:07.498835 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 23:27:07.498835 15348 fine_tuned.py:368]   mcc = 0.9736343935936171\n",
      "I0120 23:27:07.499834 15348 fine_tuned.py:368]   tn = 308\n",
      "I0120 23:27:07.499834 15348 fine_tuned.py:368]   tp = 98\n",
      "I0120 23:27:07.500832 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:27:07.501829 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:27:07.502825 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:10.460909 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 113.75it/s]\n",
      "I0120 23:27:14.374437 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:27:14.587867 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 23:27:14.588864 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:27:14.588864 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d93c402ca9843ef8bbaa26aa6789041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:23.829139 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 23:27:23.830136 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:27:23.830136 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:27:23.830136 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:27:23.831134 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:27:23.831134 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:27:23.832131 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:27:23.832131 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0120 23:27:23.833128 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:27:23.834125 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:26.810162 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 116.36it/s]\n",
      "I0120 23:27:30.569104 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:27:30.793530 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0120 23:27:30.794530 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:27:30.795498 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bb3e00d91949b78dfb4eb366c90c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:40.009513 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0120 23:27:40.009513 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:27:40.010510 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:27:40.010510 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:27:40.011508 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:27:40.011508 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:27:40.011508 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:27:40.012506 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0120 23:27:40.013503 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:27:40.013503 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:42.978567 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 110.48it/s]\n",
      "I0120 23:27:47.006789 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:27:47.217225 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0120 23:27:47.218223 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:27:47.218223 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef99beb2882c41d2a00c55602ec750a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:56.527269 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0120 23:27:56.528268 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:27:56.528268 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:27:56.529264 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:27:56.529264 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:27:56.530261 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:27:56.530261 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:27:56.532256 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0120 23:27:56.532256 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:27:56.533253 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:27:59.769593 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 115.70it/s]\n",
      "I0120 23:28:04.038172 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:28:04.254593 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0120 23:28:04.255589 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:28:04.255589 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbdd86278f846f183e2bff6893ff483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:13.504840 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0120 23:28:13.505839 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:28:13.505839 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:28:13.505839 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:28:13.506836 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:28:13.506836 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:28:13.507834 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:28:13.508832 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0120 23:28:13.509828 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:28:13.509828 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:16.640449 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 116.95it/s]\n",
      "I0120 23:28:20.354535 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:28:20.564949 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0120 23:28:20.565947 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:28:20.565947 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ca8733ed234520823515c79e2a1b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:29.844595 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0120 23:28:29.845592 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:28:29.845592 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:28:29.846590 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:28:29.846590 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:28:29.847587 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:28:29.847587 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:28:29.848584 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0120 23:28:29.849582 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:28:29.850579 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:33.100881 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 115.48it/s]\n",
      "I0120 23:28:36.931631 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:28:37.137109 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0120 23:28:37.138102 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:28:37.138102 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a401178f02c249868d5e01ac50814913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:46.409272 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0120 23:28:46.410269 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:28:46.410269 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:28:46.411266 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:28:46.411266 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:28:46.411266 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:28:46.412263 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:28:46.413261 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0120 23:28:46.414258 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:28:46.414258 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:28:49.639626 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 113.09it/s]\n",
      "I0120 23:28:53.514258 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:28:53.727714 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0120 23:28:53.728685 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:28:53.728685 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e95730c56d64f0db163656205f78ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:03.045754 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0120 23:29:03.046751 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:29:03.047749 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:29:03.047749 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:29:03.047749 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:29:03.048746 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:29:03.048746 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:29:03.049743 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0120 23:29:03.050741 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:29:03.051739 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:06.361880 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 114.93it/s]\n",
      "I0120 23:29:10.669354 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:29:10.916717 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0120 23:29:10.917689 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:29:10.917689 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0748c41144594b47a0c79fef10792525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:20.241742 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0120 23:29:20.242738 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:29:20.242738 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:29:20.243735 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:29:20.244733 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:29:20.244733 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:29:20.245730 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:29:20.246727 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0120 23:29:20.247725 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:29:20.247725 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:23.281606 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 111.44it/s]\n",
      "I0120 23:29:27.186159 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:29:27.410558 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0120 23:29:27.410558 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:29:27.411555 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8e0473a2594a4abc5e2b58b6ce3d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:36.705687 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0120 23:29:36.706684 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:29:36.706684 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:29:36.707681 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:29:36.707681 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:29:36.707681 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:29:36.708679 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:29:36.709676 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0120 23:29:36.710674 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:29:36.711672 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:39.795418 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 102.54it/s]\n",
      "I0120 23:29:44.581639 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:29:44.794071 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0120 23:29:44.795070 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:29:44.795070 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ff563496bd442db16c351bb067977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:54.116099 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0120 23:29:54.117096 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:29:54.117096 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:29:54.118094 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:29:54.118094 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:29:54.118094 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:29:54.119091 15348 fine_tuned.py:368]   tp = 101\n",
      "I0120 23:29:54.119091 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0120 23:29:54.120089 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:29:54.121086 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:29:57.133026 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 117.56it/s]\n",
      "I0120 23:30:00.915904 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:30:01.157285 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0120 23:30:01.158283 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0120 23:30:01.158283 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a887855f15499ba1888441d31426f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:30:10.502303 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0120 23:30:10.503300 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:30:10.503300 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:30:10.504297 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:30:10.504297 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:30:10.505297 15348 fine_tuned.py:368]   tn = 309\n",
      "I0120 23:30:10.506293 15348 fine_tuned.py:368]   tp = 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:30:11.327199 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:30:11.327199 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:30:11.389033 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:30:11.390030 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:30:11.391028 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1543ab773b39497badedbb82ab47e8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [309 101]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       691\n",
      "           1       1.00      1.00      1.00       899\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 101  TN_H 309  TP_M 898  TN_M 689  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [312 108]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       688\n",
      "           1       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 108  TN_H 312  TP_M 892  TN_M 686  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [322 108]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       678\n",
      "           1       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 108  TN_H 322  TP_M 892  TN_M 676  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [332 108]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       668\n",
      "           1       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 108  TN_H 332  TP_M 892  TN_M 666  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [342 108]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       658\n",
      "           1       1.00      1.00      1.00       892\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 108  TN_H 342  TP_M 892  TN_M 656  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [351 109]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       649\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 109  TN_H 351  TP_M 891  TN_M 647  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [361 109]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       639\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 109  TN_H 361  TP_M 891  TN_M 637  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [371 109]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       629\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 109  TN_H 371  TP_M 891  TN_M 627  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [381 109]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       619\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 109  TN_H 381  TP_M 891  TN_M 617  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [391 109]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       609\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 109  TN_H 391  TP_M 891  TN_M 607  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [401 109]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       599\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 109  TN_H 401  TP_M 891  TN_M 597  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [411 109]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       589\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 109  TN_H 411  TP_M 891  TN_M 587  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [421 109]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       579\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 109  TN_H 421  TP_M 891  TN_M 577  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [431 109]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       569\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 109  TN_H 431  TP_M 891  TN_M 567  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [441 109]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       559\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 109  TN_H 441  TP_M 891  TN_M 557  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [451 109]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       549\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 109  TN_H 451  TP_M 891  TN_M 547  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [461 109]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       539\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 109  TN_H 461  TP_M 891  TN_M 537  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [471 109]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       529\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 109  TN_H 471  TP_M 891  TN_M 527  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [481 109]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       519\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 109  TN_H 481  TP_M 891  TN_M 517  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [491 109]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       509\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 109  TN_H 491  TP_M 891  TN_M 507  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:31:36.910235 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:31:36.911227 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:31:37.609522 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:31:37.609522 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:31:37.668335 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:31:37.670360 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:31:37.671328 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0120 23:31:40.596499 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 145.32it/s]\n",
      "I0120 23:31:45.084490 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:31:45.440538 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 23:31:45.441535 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0120 23:31:45.441535 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 23:31:45.441535 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 23:31:45.442533 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 23:31:45.442533 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b4e85e2ff34c499a4dc15c8887b5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:58<13:40, 58.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249ab1381a7848e6ae9b46512cc5c542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:33:02.960379 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0120 23:33:04.192084 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0120 23:33:04.193081 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:57<12:42, 58.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8c0a90327d437cac78b60112903da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:34:19.837298 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0120 23:34:21.155515 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0120 23:34:21.156513 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:55<11:41, 58.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62281282ce1341a686dcbb9166337669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:35:36.888218 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0120 23:35:38.179764 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0120 23:35:38.180760 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [03:53<10:42, 58.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d745b326344b568c4ccb753f28d455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [04:50<09:40, 58.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bb303a269343348021c4b50e33b2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000028"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:36:53.614690 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0120 23:36:54.876315 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0120 23:36:54.877313 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [05:49<08:42, 58.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe22918707134e60bf46a944d950a4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:38:10.701351 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0120 23:38:11.901141 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0120 23:38:11.902138 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [06:47<07:45, 58.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c8d29509354d5caa1f5da966c11c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:39:27.441995 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0120 23:39:28.990849 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0120 23:39:28.991847 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [07:45<06:47, 58.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d63119704ec4c219e5878b0c8e141be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [08:42<05:47, 57.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5bba091dde4a12b955b528d98b36d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:40:44.684978 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0120 23:40:45.934664 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0120 23:40:45.934664 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [09:41<04:50, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e5f27e1a5d45119b99259bdb636c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:42:01.462810 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0120 23:42:02.813197 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0120 23:42:02.814194 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [10:39<03:52, 58.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e9c3e7eef24c3690554c882087572a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:43:18.776491 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0120 23:43:20.044117 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0120 23:43:20.045114 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [11:37<02:54, 58.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000014\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6b968d1de64384865a0ae14f377db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [12:35<01:55, 57.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7df35c331c48d69a8cebbfa40baaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:44:35.742474 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0120 23:44:38.335441 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0120 23:44:38.335441 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [13:34<00:58, 58.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5615488436e24695b8cf873259788c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:45:54.180528 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0120 23:45:55.436196 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0120 23:45:55.437167 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [14:33<00:00, 58.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [14:33<00:00, 58.21s/it]\n",
      "I0120 23:46:18.638309 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.012920183560167782\n",
      "I0120 23:46:18.641302 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0120 23:46:18.642298 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:46:18.643296 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:46:18.644293 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:46:21.599384 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 134.66it/s]\n",
      "I0120 23:46:26.980984 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:46:27.288163 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0120 23:46:27.289160 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:46:27.289160 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6107ded396fd4072ae0282074c912553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:46:40.960871 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0120 23:46:40.961869 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:46:40.962866 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:46:40.962866 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:46:40.962866 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:46:40.963864 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:46:40.963864 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:46:40.964861 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0120 23:46:40.965858 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:46:40.966856 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:46:43.908982 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 145.87it/s]\n",
      "I0120 23:46:48.306216 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:46:48.622398 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0120 23:46:48.623401 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:46:48.623401 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570c566d16604ff5b1b04fed2ca856c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:02.277806 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0120 23:47:02.278804 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:47:02.278804 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:47:02.279801 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:47:02.279801 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:47:02.279801 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:47:02.280798 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:47:02.281796 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0120 23:47:02.281796 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:47:02.282793 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:05.240877 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 146.04it/s]\n",
      "I0120 23:47:10.164733 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:47:10.468916 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0120 23:47:10.469914 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:47:10.469914 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a74f9189b44988837ab325fa18ffd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:24.140339 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0120 23:47:24.141336 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:47:24.141336 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:47:24.142333 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:47:24.143331 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:47:24.143331 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:47:24.144328 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:47:24.145325 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0120 23:47:24.146323 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:47:24.147320 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:27.134327 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 145.21it/s]\n",
      "I0120 23:47:32.138936 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:47:32.475036 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0120 23:47:32.476033 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:47:32.477030 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecf3844c23549bf8767916569c0ea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:46.277353 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0120 23:47:46.278350 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:47:46.279347 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:47:46.279347 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:47:46.280343 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:47:46.281342 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:47:46.281342 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:47:46.283336 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0120 23:47:46.284333 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:47:46.284333 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:47:49.585498 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 149.47it/s]\n",
      "I0120 23:47:53.929874 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:47:54.260988 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0120 23:47:54.261986 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:47:54.261986 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cdb38821a449afa1a4f3fd5bcdc21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:08.022233 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0120 23:48:08.023230 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:48:08.024228 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:48:08.024228 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:48:08.025225 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:48:08.025225 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:48:08.026221 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:48:08.027220 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0120 23:48:08.028217 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:48:08.029214 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:11.292481 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 150.95it/s]\n",
      "I0120 23:48:15.608932 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:48:15.953035 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0120 23:48:15.954008 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:48:15.954008 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98851a6798f94e8f94ce8d815fd5cce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:29.745218 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0120 23:48:29.746216 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:48:29.746216 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:48:29.747213 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:48:29.748216 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:48:29.748216 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:48:29.749207 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:48:29.750205 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0120 23:48:29.751203 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:48:29.752199 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:32.983551 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 148.56it/s]\n",
      "I0120 23:48:37.352888 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:48:37.692982 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0120 23:48:37.693974 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:48:37.693974 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b478d30ee14442beff0f821b684283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:51.477921 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0120 23:48:51.479917 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:48:51.479917 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:48:51.480914 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:48:51.480914 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:48:51.481911 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:48:51.482909 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:48:51.483906 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0120 23:48:51.484903 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:48:51.485900 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:48:54.705285 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 141.65it/s]\n",
      "I0120 23:48:59.821593 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:49:00.157695 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0120 23:49:00.158720 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:49:00.158720 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ad1d2574984d6cac293b7e7ea502ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:49:14.041620 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0120 23:49:14.042617 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:49:14.042617 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:49:14.043614 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:49:14.043614 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:49:14.044612 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:49:14.045609 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:49:14.046606 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0120 23:49:14.046606 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:49:14.047603 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:49:17.019651 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 148.53it/s]\n",
      "I0120 23:49:21.410928 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:49:21.710100 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0120 23:49:21.710100 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:49:21.711098 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac9c6f0f5284573ba177dd6a3ebadd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:49:35.516158 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0120 23:49:35.518152 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:49:35.518152 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:49:35.519150 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:49:35.519150 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:49:35.520147 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:49:35.521145 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:49:35.522143 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0120 23:49:35.523139 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:49:35.524137 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:49:38.679692 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 148.74it/s]\n",
      "I0120 23:49:43.021075 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:49:43.365187 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0120 23:49:43.366184 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:49:43.366184 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dddacf1848842039d196b82ada8ad7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:49:57.237037 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0120 23:49:57.238034 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:49:57.238034 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:49:57.239031 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:49:57.239031 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:49:57.240028 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:49:57.240028 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:49:57.241026 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0120 23:49:57.242023 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:49:57.243021 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:50:00.337739 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 149.14it/s]\n",
      "I0120 23:50:05.197734 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:50:05.524888 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0120 23:50:05.525887 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:50:05.525887 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ee95264dc848819f8d7c274cce99ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:50:19.365883 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0120 23:50:19.366880 15348 fine_tuned.py:368]   acc = 0.9934426229508196\n",
      "I0120 23:50:19.367877 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:50:19.367877 15348 fine_tuned.py:368]   fp = 4\n",
      "I0120 23:50:19.368875 15348 fine_tuned.py:368]   mcc = 0.9782128390973437\n",
      "I0120 23:50:19.368875 15348 fine_tuned.py:368]   tn = 497\n",
      "I0120 23:50:19.369872 15348 fine_tuned.py:368]   tp = 109\n",
      "I0120 23:50:19.370870 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0120 23:50:19.371867 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:50:19.372864 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:50:22.431678 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 149.80it/s]\n",
      "I0120 23:50:26.851851 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:50:27.176007 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0120 23:50:27.177009 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0120 23:50:27.177009 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7d2127342a47e586b257dcead0d4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:50:41.028916 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0120 23:50:41.030910 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:50:41.030910 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:50:41.031908 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:50:41.032905 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:50:41.032905 15348 fine_tuned.py:368]   tn = 501\n",
      "I0120 23:50:41.033902 15348 fine_tuned.py:368]   tp = 109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:50:41.822058 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:50:41.823028 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:50:41.884890 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0120 23:50:41.885859 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:50:41.885859 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218083f3d7ce47679b88a0a63fc7b7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [501 109]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       499\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 109  TN_H 501  TP_M 891  TN_M 497  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [511 109]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       489\n",
      "           1       1.00      1.00      1.00       891\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 109  TN_H 511  TP_M 891  TN_M 487  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [520 110]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       480\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 110  TN_H 520  TP_M 890  TN_M 478  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [530 110]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       470\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 110  TN_H 530  TP_M 890  TN_M 468  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [540 110]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       460\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 110  TN_H 540  TP_M 890  TN_M 458  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [550 110]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       450\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 110  TN_H 550  TP_M 890  TN_M 448  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [560 110]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       440\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 110  TN_H 560  TP_M 890  TN_M 438  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [570 110]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       430\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 110  TN_H 570  TP_M 890  TN_M 428  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [578 112]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       422\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 112  TN_H 578  TP_M 888  TN_M 420  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [588 112]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       412\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 112  TN_H 588  TP_M 888  TN_M 410  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [598 112]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       402\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 112  TN_H 598  TP_M 888  TN_M 400  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [608 112]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       392\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 112  TN_H 608  TP_M 888  TN_M 390  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [618 112]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       382\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 112  TN_H 618  TP_M 888  TN_M 380  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [628 112]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       372\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 112  TN_H 628  TP_M 888  TN_M 370  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [638 112]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       362\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 112  TN_H 638  TP_M 888  TN_M 360  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [648 112]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       352\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 112  TN_H 648  TP_M 888  TN_M 350  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [658 112]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       342\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 112  TN_H 658  TP_M 888  TN_M 340  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [668 112]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       332\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 112  TN_H 668  TP_M 888  TN_M 330  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [678 112]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       322\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 112  TN_H 678  TP_M 888  TN_M 320  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [688 112]\n",
      "Number of training examples  800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       312\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 112  TN_H 688  TP_M 888  TN_M 310  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [698 112]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       302\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 112  TN_H 698  TP_M 888  TN_M 300  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [708 112]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       292\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 112  TN_H 708  TP_M 888  TN_M 290  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [718 112]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       282\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 112  TN_H 718  TP_M 888  TN_M 280  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [728 112]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       272\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 112  TN_H 728  TP_M 888  TN_M 270  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [738 112]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       262\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 112  TN_H 738  TP_M 888  TN_M 260  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [748 112]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       252\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 112  TN_H 748  TP_M 888  TN_M 250  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [758 112]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       242\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 112  TN_H 758  TP_M 888  TN_M 240  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [768 112]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       232\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 112  TN_H 768  TP_M 888  TN_M 230  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [778 112]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       222\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 112  TN_H 778  TP_M 888  TN_M 220  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [788 112]\n",
      "Number of training examples  900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       212\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 112  TN_H 788  TP_M 888  TN_M 210  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [798 112]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       202\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 112  TN_H 798  TP_M 888  TN_M 200  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [808 112]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       192\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      0.99      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 112  TN_H 808  TP_M 888  TN_M 190  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [818 112]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       182\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      0.99      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 112  TN_H 818  TP_M 888  TN_M 180  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [828 112]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       172\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      0.99      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 112  TN_H 828  TP_M 888  TN_M 170  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [838 112]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       162\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      0.99      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 112  TN_H 838  TP_M 888  TN_M 160  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [848 112]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       152\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      0.99      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 112  TN_H 848  TP_M 888  TN_M 150  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [858 112]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       142\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      0.99      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 112  TN_H 858  TP_M 888  TN_M 140  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [868 112]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       132\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      0.99      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 112  TN_H 868  TP_M 888  TN_M 130  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [878 112]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       122\n",
      "           1       1.00      1.00      1.00       888\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      0.99      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 112  TN_H 878  TP_M 888  TN_M 120  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [887 113]\n",
      "Number of training examples  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       113\n",
      "           1       1.00      1.00      1.00       887\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      0.99      0.99      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 113  TN_H 887  TP_M 887  TN_M 111  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "processing  0 th loops---------------\n",
      "initial random chosen samples [890, 75, 18, 556, 25, 1180, 1467, 1016, 1068, 1393]\n",
      "initial training set size: 10 unique(labels): [0 1] label counts: [5 5]\n",
      "Number of training examples  10\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.73       995\n",
      "           1       0.72      0.77      0.74       995\n",
      "\n",
      "    accuracy                           0.74      1990\n",
      "   macro avg       0.74      0.74      0.73      1990\n",
      "weighted avg       0.74      0.74      0.73      1990\n",
      "\n",
      "TP_H 5  TN_H 5  TP_M 762  TN_M 701  FP_M 294  FN_M 233\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  20 ********************\n",
      "processing  1 th loops---------------\n",
      "training set size: 20 unique(labels): [0 1] label counts: [13  7]\n",
      "Number of training examples  20\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       987\n",
      "           1       0.86      0.88      0.87       993\n",
      "\n",
      "    accuracy                           0.87      1980\n",
      "   macro avg       0.87      0.87      0.87      1980\n",
      "weighted avg       0.87      0.87      0.87      1980\n",
      "\n",
      "TP_H 7  TN_H 13  TP_M 869  TN_M 848  FP_M 139  FN_M 124\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  30 ********************\n",
      "processing  2 th loops---------------\n",
      "training set size: 30 unique(labels): [0 1] label counts: [18 12]\n",
      "Number of training examples  30\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       982\n",
      "           1       0.98      0.93      0.96       988\n",
      "\n",
      "    accuracy                           0.96      1970\n",
      "   macro avg       0.96      0.96      0.96      1970\n",
      "weighted avg       0.96      0.96      0.96      1970\n",
      "\n",
      "TP_H 12  TN_H 18  TP_M 921  TN_M 964  FP_M 18  FN_M 67\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  40 ********************\n",
      "processing  3 th loops---------------\n",
      "training set size: 40 unique(labels): [0 1] label counts: [19 21]\n",
      "Number of training examples  40\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       981\n",
      "           1       0.90      1.00      0.95       979\n",
      "\n",
      "    accuracy                           0.94      1960\n",
      "   macro avg       0.95      0.94      0.94      1960\n",
      "weighted avg       0.95      0.94      0.94      1960\n",
      "\n",
      "TP_H 21  TN_H 19  TP_M 976  TN_M 875  FP_M 106  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  50 ********************\n",
      "processing  4 th loops---------------\n",
      "training set size: 50 unique(labels): [0 1] label counts: [28 22]\n",
      "Number of training examples  50\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       972\n",
      "           1       0.96      0.97      0.97       978\n",
      "\n",
      "    accuracy                           0.97      1950\n",
      "   macro avg       0.97      0.97      0.97      1950\n",
      "weighted avg       0.97      0.97      0.97      1950\n",
      "\n",
      "TP_H 22  TN_H 28  TP_M 950  TN_M 937  FP_M 35  FN_M 28\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  60 ********************\n",
      "processing  5 th loops---------------\n",
      "training set size: 60 unique(labels): [0 1] label counts: [37 23]\n",
      "Number of training examples  60\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       963\n",
      "           1       0.98      0.98      0.98       977\n",
      "\n",
      "    accuracy                           0.98      1940\n",
      "   macro avg       0.98      0.98      0.98      1940\n",
      "weighted avg       0.98      0.98      0.98      1940\n",
      "\n",
      "TP_H 23  TN_H 37  TP_M 956  TN_M 948  FP_M 15  FN_M 21\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  70 ********************\n",
      "processing  6 th loops---------------\n",
      "training set size: 70 unique(labels): [0 1] label counts: [40 30]\n",
      "Number of training examples  70\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       960\n",
      "           1       0.95      0.99      0.97       970\n",
      "\n",
      "    accuracy                           0.97      1930\n",
      "   macro avg       0.97      0.97      0.97      1930\n",
      "weighted avg       0.97      0.97      0.97      1930\n",
      "\n",
      "TP_H 30  TN_H 40  TP_M 957  TN_M 909  FP_M 51  FN_M 13\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  80 ********************\n",
      "processing  7 th loops---------------\n",
      "training set size: 80 unique(labels): [0 1] label counts: [45 35]\n",
      "Number of training examples  80\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       955\n",
      "           1       0.98      0.98      0.98       965\n",
      "\n",
      "    accuracy                           0.98      1920\n",
      "   macro avg       0.98      0.98      0.98      1920\n",
      "weighted avg       0.98      0.98      0.98      1920\n",
      "\n",
      "TP_H 35  TN_H 45  TP_M 945  TN_M 939  FP_M 16  FN_M 20\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  90 ********************\n",
      "processing  8 th loops---------------\n",
      "training set size: 90 unique(labels): [0 1] label counts: [50 40]\n",
      "Number of training examples  90\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       950\n",
      "           1       0.99      0.98      0.99       960\n",
      "\n",
      "    accuracy                           0.99      1910\n",
      "   macro avg       0.99      0.99      0.99      1910\n",
      "weighted avg       0.99      0.99      0.99      1910\n",
      "\n",
      "TP_H 40  TN_H 50  TP_M 945  TN_M 940  FP_M 10  FN_M 15\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  100 ********************\n",
      "processing  9 th loops---------------\n",
      "training set size: 100 unique(labels): [0 1] label counts: [55 45]\n",
      "Number of training examples  100\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       945\n",
      "           1       0.98      0.99      0.99       955\n",
      "\n",
      "    accuracy                           0.99      1900\n",
      "   macro avg       0.99      0.99      0.99      1900\n",
      "weighted avg       0.99      0.99      0.99      1900\n",
      "\n",
      "TP_H 45  TN_H 55  TP_M 949  TN_M 925  FP_M 20  FN_M 6\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  110 ********************\n",
      "processing  10 th loops---------------\n",
      "training set size: 110 unique(labels): [0 1] label counts: [62 48]\n",
      "Number of training examples  110\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       938\n",
      "           1       0.99      0.99      0.99       952\n",
      "\n",
      "    accuracy                           0.99      1890\n",
      "   macro avg       0.99      0.99      0.99      1890\n",
      "weighted avg       0.99      0.99      0.99      1890\n",
      "\n",
      "TP_H 48  TN_H 62  TP_M 943  TN_M 927  FP_M 11  FN_M 9\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  120 ********************\n",
      "processing  11 th loops---------------\n",
      "training set size: 120 unique(labels): [0 1] label counts: [66 54]\n",
      "Number of training examples  120\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       934\n",
      "           1       0.99      0.99      0.99       946\n",
      "\n",
      "    accuracy                           0.99      1880\n",
      "   macro avg       0.99      0.99      0.99      1880\n",
      "weighted avg       0.99      0.99      0.99      1880\n",
      "\n",
      "TP_H 54  TN_H 66  TP_M 941  TN_M 925  FP_M 9  FN_M 5\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  130 ********************\n",
      "processing  12 th loops---------------\n",
      "training set size: 130 unique(labels): [0 1] label counts: [71 59]\n",
      "Number of training examples  130\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       929\n",
      "           1       0.99      1.00      0.99       941\n",
      "\n",
      "    accuracy                           0.99      1870\n",
      "   macro avg       0.99      0.99      0.99      1870\n",
      "weighted avg       0.99      0.99      0.99      1870\n",
      "\n",
      "TP_H 59  TN_H 71  TP_M 937  TN_M 919  FP_M 10  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  140 ********************\n",
      "processing  13 th loops---------------\n",
      "training set size: 140 unique(labels): [0 1] label counts: [79 61]\n",
      "Number of training examples  140\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       921\n",
      "           1       0.99      1.00      0.99       939\n",
      "\n",
      "    accuracy                           0.99      1860\n",
      "   macro avg       0.99      0.99      0.99      1860\n",
      "weighted avg       0.99      0.99      0.99      1860\n",
      "\n",
      "TP_H 61  TN_H 79  TP_M 936  TN_M 913  FP_M 8  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  150 ********************\n",
      "processing  14 th loops---------------\n",
      "training set size: 150 unique(labels): [0 1] label counts: [87 63]\n",
      "Number of training examples  150\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       913\n",
      "           1       0.99      1.00      1.00       937\n",
      "\n",
      "    accuracy                           1.00      1850\n",
      "   macro avg       1.00      1.00      1.00      1850\n",
      "weighted avg       1.00      1.00      1.00      1850\n",
      "\n",
      "TP_H 63  TN_H 87  TP_M 934  TN_M 907  FP_M 6  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  160 ********************\n",
      "processing  15 th loops---------------\n",
      "training set size: 160 unique(labels): [0 1] label counts: [95 65]\n",
      "Number of training examples  160\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       905\n",
      "           1       1.00      1.00      1.00       935\n",
      "\n",
      "    accuracy                           1.00      1840\n",
      "   macro avg       1.00      1.00      1.00      1840\n",
      "weighted avg       1.00      1.00      1.00      1840\n",
      "\n",
      "TP_H 65  TN_H 95  TP_M 932  TN_M 901  FP_M 4  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  170 ********************\n",
      "processing  16 th loops---------------\n",
      "training set size: 170 unique(labels): [0 1] label counts: [100  70]\n",
      "Number of training examples  170\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       900\n",
      "           1       1.00      1.00      1.00       930\n",
      "\n",
      "    accuracy                           1.00      1830\n",
      "   macro avg       1.00      1.00      1.00      1830\n",
      "weighted avg       1.00      1.00      1.00      1830\n",
      "\n",
      "TP_H 70  TN_H 100  TP_M 927  TN_M 898  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  180 ********************\n",
      "processing  17 th loops---------------\n",
      "training set size: 180 unique(labels): [0 1] label counts: [103  77]\n",
      "Number of training examples  180\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       897\n",
      "           1       1.00      1.00      1.00       923\n",
      "\n",
      "    accuracy                           1.00      1820\n",
      "   macro avg       1.00      1.00      1.00      1820\n",
      "weighted avg       1.00      1.00      1.00      1820\n",
      "\n",
      "TP_H 77  TN_H 103  TP_M 920  TN_M 895  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  190 ********************\n",
      "processing  18 th loops---------------\n",
      "training set size: 190 unique(labels): [0 1] label counts: [107  83]\n",
      "Number of training examples  190\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       893\n",
      "           1       1.00      1.00      1.00       917\n",
      "\n",
      "    accuracy                           1.00      1810\n",
      "   macro avg       1.00      1.00      1.00      1810\n",
      "weighted avg       1.00      1.00      1.00      1810\n",
      "\n",
      "TP_H 83  TN_H 107  TP_M 914  TN_M 891  FP_M 2  FN_M 3\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  200 ********************\n",
      "processing  19 th loops---------------\n",
      "training set size: 200 unique(labels): [0 1] label counts: [110  90]\n",
      "Number of training examples  200\n",
      "best parameters is  SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       890\n",
      "           1       1.00      1.00      1.00       910\n",
      "\n",
      "    accuracy                           1.00      1800\n",
      "   macro avg       1.00      1.00      1.00      1800\n",
      "weighted avg       1.00      1.00      1.00      1800\n",
      "\n",
      "TP_H 90  TN_H 110  TP_M 908  TN_M 888  FP_M 2  FN_M 2\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  210 ********************\n",
      "processing  20 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:52:24.544682 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:52:24.546678 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:52:25.299753 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:52:25.300752 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:52:25.797037 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0120 23:52:25.799031 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:52:26.170076 15348 modeling_utils.py:401] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n",
      "I0120 23:52:29.036382 15348 modeling_utils.py:473] Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "I0120 23:52:29.038371 15348 modeling_utils.py:476] Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.weight']\n",
      "I0120 23:52:29.222877 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:02<00:00, 71.26it/s]\n",
      "I0120 23:52:33.012373 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:52:33.145019 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0120 23:52:33.146015 15348 fine_tuned.py:166]   Num examples = 210\n",
      "I0120 23:52:33.146015 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0120 23:52:33.147013 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0120 23:52:33.148010 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0120 23:52:33.148010 15348 fine_tuned.py:170]   Total optimization steps = 795\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3955c55de1654b8d9ef0c8acb6943410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.761721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716275"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:20<04:53, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f2605f130646dfa143e79f181b1f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:53:00.900516 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-70\\config.json\n",
      "I0120 23:53:02.105292 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-70\\pytorch_model.bin\n",
      "I0120 23:53:02.105292 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.120821"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [00:43<04:37, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63b4b2379be4914bd4e9904535aa582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:53:29.424257 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-140\\config.json\n",
      "I0120 23:53:30.717796 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-140\\pytorch_model.bin\n",
      "I0120 23:53:30.718794 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [01:04<04:16, 21.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e938d7ae3fe8434693d316ed0ec9995d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:53:56.320288 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-210\\config.json\n",
      "I0120 23:53:57.559000 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-210\\pytorch_model.bin\n",
      "I0120 23:53:57.559997 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002034"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [01:25<03:52, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71036d2cdad42ecb292ca18214cea84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [01:44<03:27, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865fd016941b47208ae5e96be7cac46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:54:23.658219 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-280\\config.json\n",
      "I0120 23:54:26.496797 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-280\\pytorch_model.bin\n",
      "I0120 23:54:26.496797 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000721"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [02:07<03:11, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2724aefd35b244079c9af7c41d36d3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000657"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:54:52.831182 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-350\\config.json\n",
      "I0120 23:54:54.405889 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-350\\pytorch_model.bin\n",
      "I0120 23:54:54.406918 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [02:29<02:51, 21.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae67f08b7b5941f78742a093ed0e2e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:55:20.922916 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-420\\config.json\n",
      "I0120 23:55:22.110738 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-420\\pytorch_model.bin\n",
      "I0120 23:55:22.111734 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [02:50<02:29, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d6c5c95202496aae9a27b07403ab73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000327"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [03:10<02:05, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbc138c17e84a3c9b1c0c52493e3a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:55:48.191041 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-490\\config.json\n",
      "I0120 23:55:49.427702 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-490\\pytorch_model.bin\n",
      "I0120 23:55:49.428723 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [03:31<01:44, 20.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6cf569a7a84e6a9e20395c6b7d1949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:56:15.692124 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-560\\config.json\n",
      "I0120 23:56:16.882966 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-560\\pytorch_model.bin\n",
      "I0120 23:56:16.883963 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [03:52<01:23, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed899b13d754d2f95fddf5ebd194b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000319"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:56:42.837503 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-630\\config.json\n",
      "I0120 23:56:44.051256 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-630\\pytorch_model.bin\n",
      "I0120 23:56:44.051256 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [04:12<01:02, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5884831aecd84e41ac43e45792d64826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [04:32<00:41, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6e27a27aa04023a5a0a20cd1ebabdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:57:09.800388 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-700\\config.json\n",
      "I0120 23:57:11.409084 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-700\\pytorch_model.bin\n",
      "I0120 23:57:11.410081 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [04:53<00:20, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3d55353fed4699ac8d5b7f5fb78835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:57:37.427094 15348 configuration_utils.py:72] Configuration saved in outputs/20\\dbpedia-770\\config.json\n",
      "I0120 23:57:38.628879 15348 modeling_utils.py:251] Model weights saved in outputs/20\\dbpedia-770\\pytorch_model.bin\n",
      "I0120 23:57:38.628879 15348 fine_tuned.py:227] Saving model checkpoint to outputs/20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [05:14<00:00, 20.98s/it]\n",
      "I0120 23:57:47.874758 15348 fine_tuned.py:405]  global_step = 795, average loss = 0.10109170756812366\n",
      "I0120 23:57:47.878749 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-140', 'outputs\\\\20\\\\dbpedia-210', 'outputs\\\\20\\\\dbpedia-280', 'outputs\\\\20\\\\dbpedia-350', 'outputs\\\\20\\\\dbpedia-420', 'outputs\\\\20\\\\dbpedia-490', 'outputs\\\\20\\\\dbpedia-560', 'outputs\\\\20\\\\dbpedia-630', 'outputs\\\\20\\\\dbpedia-700', 'outputs\\\\20\\\\dbpedia-70', 'outputs\\\\20\\\\dbpedia-770']\n",
      "I0120 23:57:47.878749 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-140\\config.json\n",
      "I0120 23:57:47.880743 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:57:47.880743 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-140\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:57:50.810901 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 61.41it/s]\n",
      "I0120 23:57:54.975787 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:57:55.088485 15348 fine_tuned.py:285] ***** Running evaluation 140 *****\n",
      "I0120 23:57:55.089498 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:57:55.090451 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8867cd54714b423996ba28226469d421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:57:59.860536 15348 fine_tuned.py:366] ***** Eval results 140 *****\n",
      "I0120 23:57:59.860536 15348 fine_tuned.py:368]   acc = 0.9761904761904762\n",
      "I0120 23:57:59.861533 15348 fine_tuned.py:368]   fn = 2\n",
      "I0120 23:57:59.861533 15348 fine_tuned.py:368]   fp = 3\n",
      "I0120 23:57:59.861533 15348 fine_tuned.py:368]   mcc = 0.9518481320520862\n",
      "I0120 23:57:59.862531 15348 fine_tuned.py:368]   tn = 114\n",
      "I0120 23:57:59.862531 15348 fine_tuned.py:368]   tp = 91\n",
      "I0120 23:57:59.863528 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-210\\config.json\n",
      "I0120 23:57:59.864526 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:57:59.864526 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-210\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:02.952264 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 69.77it/s]\n",
      "I0120 23:58:06.220549 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:58:06.334244 15348 fine_tuned.py:285] ***** Running evaluation 210 *****\n",
      "I0120 23:58:06.335212 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:58:06.336209 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029fbceb4a345a68c271aa6f594a1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:11.066138 15348 fine_tuned.py:366] ***** Eval results 210 *****\n",
      "I0120 23:58:11.067135 15348 fine_tuned.py:368]   acc = 0.9904761904761905\n",
      "I0120 23:58:11.067135 15348 fine_tuned.py:368]   fn = 1\n",
      "I0120 23:58:11.067135 15348 fine_tuned.py:368]   fp = 1\n",
      "I0120 23:58:11.068132 15348 fine_tuned.py:368]   mcc = 0.9807003032809485\n",
      "I0120 23:58:11.068132 15348 fine_tuned.py:368]   tn = 116\n",
      "I0120 23:58:11.068132 15348 fine_tuned.py:368]   tp = 92\n",
      "I0120 23:58:11.069129 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:58:11.070127 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:58:11.070127 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:14.047161 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 68.54it/s]\n",
      "I0120 23:58:17.316412 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:58:17.421133 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0120 23:58:17.421133 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:58:17.421133 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8423554ee8946a3a69149adc6349871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:22.132210 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0120 23:58:22.133208 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:58:22.133208 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:58:22.133208 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:58:22.134205 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:58:22.134205 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:58:22.135204 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:58:22.135204 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-350\\config.json\n",
      "I0120 23:58:22.136200 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:58:22.137196 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-350\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:25.099270 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:02<00:00, 71.06it/s]\n",
      "I0120 23:58:28.362539 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:58:28.481251 15348 fine_tuned.py:285] ***** Running evaluation 350 *****\n",
      "I0120 23:58:28.482249 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:58:28.482249 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68667e6430f407a819a1017a56e6de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:33.194386 15348 fine_tuned.py:366] ***** Eval results 350 *****\n",
      "I0120 23:58:33.195409 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:58:33.195409 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:58:33.196382 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:58:33.196382 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:58:33.196382 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:58:33.197380 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:58:33.197380 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-420\\config.json\n",
      "I0120 23:58:33.198376 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:58:33.199374 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-420\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:36.160450 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:02<00:00, 71.16it/s]\n",
      "I0120 23:58:39.321024 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:58:39.440673 15348 fine_tuned.py:285] ***** Running evaluation 420 *****\n",
      "I0120 23:58:39.441670 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:58:39.442668 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dada55b3e78f4779bae0a690250e6e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:44.208892 15348 fine_tuned.py:366] ***** Eval results 420 *****\n",
      "I0120 23:58:44.209890 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:58:44.209890 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:58:44.209890 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:58:44.210888 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:58:44.210888 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:58:44.210888 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:58:44.211884 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-490\\config.json\n",
      "I0120 23:58:44.212881 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:58:44.212881 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-490\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:47.183932 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:02<00:00, 70.40it/s]\n",
      "I0120 23:58:50.463187 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:58:50.574884 15348 fine_tuned.py:285] ***** Running evaluation 490 *****\n",
      "I0120 23:58:50.575879 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:58:50.575879 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376a86bd82d0449f825650b3c521edd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:55.303873 15348 fine_tuned.py:366] ***** Eval results 490 *****\n",
      "I0120 23:58:55.304871 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:58:55.305870 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:58:55.306866 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:58:55.306866 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:58:55.307863 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:58:55.308861 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:58:55.309858 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-560\\config.json\n",
      "I0120 23:58:55.311853 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:58:55.312851 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-560\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:58:58.350721 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 69.65it/s]\n",
      "I0120 23:59:02.109663 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:59:02.223360 15348 fine_tuned.py:285] ***** Running evaluation 560 *****\n",
      "I0120 23:59:02.224357 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:59:02.224357 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb723d3a814a45c98b07f7f4a02d8b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:06.925374 15348 fine_tuned.py:366] ***** Eval results 560 *****\n",
      "I0120 23:59:06.926370 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:59:06.926370 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:59:06.927368 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:59:06.927368 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:59:06.928364 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:59:06.928364 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:59:06.929362 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-630\\config.json\n",
      "I0120 23:59:06.930359 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:59:06.930359 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-630\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:09.856529 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 67.42it/s]\n",
      "I0120 23:59:13.749146 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:59:13.878797 15348 fine_tuned.py:285] ***** Running evaluation 630 *****\n",
      "I0120 23:59:13.878797 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:59:13.879791 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b537702e33c340b18f3fcba431b3c9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:18.614096 15348 fine_tuned.py:366] ***** Eval results 630 *****\n",
      "I0120 23:59:18.615093 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:59:18.615093 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:59:18.616091 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:59:18.616091 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:59:18.617088 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:59:18.617088 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:59:18.618085 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-700\\config.json\n",
      "I0120 23:59:18.619083 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:59:18.620080 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-700\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:21.717791 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 69.24it/s]\n",
      "I0120 23:59:24.984051 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:59:25.095776 15348 fine_tuned.py:285] ***** Running evaluation 700 *****\n",
      "I0120 23:59:25.096774 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:59:25.096774 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8404d313244333b20fb25bdafa7c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:29.854020 15348 fine_tuned.py:366] ***** Eval results 700 *****\n",
      "I0120 23:59:29.854020 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:59:29.855017 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:59:29.855017 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:59:29.856014 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:59:29.856014 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:59:29.856014 15348 fine_tuned.py:368]   tp = 93\n",
      "I0120 23:59:29.857012 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-70\\config.json\n",
      "I0120 23:59:29.858010 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:59:29.859008 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-70\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:32.894883 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 69.86it/s]\n",
      "I0120 23:59:36.661831 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:59:36.770512 15348 fine_tuned.py:285] ***** Running evaluation 70 *****\n",
      "I0120 23:59:36.771510 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:59:36.771510 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdbd3f450bb42259cb2e0b5787317be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "I0120 23:59:41.538753 15348 fine_tuned.py:366] ***** Eval results 70 *****\n",
      "I0120 23:59:41.539751 15348 fine_tuned.py:368]   acc = 0.5571428571428572\n",
      "I0120 23:59:41.540748 15348 fine_tuned.py:368]   fn = 93\n",
      "I0120 23:59:41.540748 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:59:41.540748 15348 fine_tuned.py:368]   mcc = 0.0\n",
      "I0120 23:59:41.541745 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:59:41.541745 15348 fine_tuned.py:368]   tp = 0\n",
      "I0120 23:59:41.542742 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-770\\config.json\n",
      "I0120 23:59:41.543740 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:59:41.544738 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-770\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:44.608541 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 210/210 [00:03<00:00, 69.95it/s]\n",
      "I0120 23:59:48.368479 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0120 23:59:48.498131 15348 fine_tuned.py:285] ***** Running evaluation 770 *****\n",
      "I0120 23:59:48.498131 15348 fine_tuned.py:286]   Num examples = 210\n",
      "I0120 23:59:48.499156 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988fa714a91940aaa39c11f8f372ee22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=53.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:53.378074 15348 fine_tuned.py:366] ***** Eval results 770 *****\n",
      "I0120 23:59:53.378074 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0120 23:59:53.379071 15348 fine_tuned.py:368]   fn = 0\n",
      "I0120 23:59:53.379071 15348 fine_tuned.py:368]   fp = 0\n",
      "I0120 23:59:53.380069 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0120 23:59:53.380069 15348 fine_tuned.py:368]   tn = 117\n",
      "I0120 23:59:53.380069 15348 fine_tuned.py:368]   tp = 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0120 23:59:54.168957 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0120 23:59:54.168957 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0120 23:59:54.274674 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0120 23:59:54.275671 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0120 23:59:54.276669 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32afabfdc4f74803949f001dfc058af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 210 unique(labels): [0 1] label counts: [117  93]\n",
      "Number of training examples  210\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       883\n",
      "           1       1.00      1.00      1.00       907\n",
      "\n",
      "    accuracy                           1.00      1790\n",
      "   macro avg       1.00      1.00      1.00      1790\n",
      "weighted avg       1.00      1.00      1.00      1790\n",
      "\n",
      "TP_H 93  TN_H 117  TP_M 906  TN_M 881  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  220 ********************\n",
      "processing  21 th loops---------------\n",
      "training set size: 220 unique(labels): [0 1] label counts: [120 100]\n",
      "Number of training examples  220\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       880\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1780\n",
      "   macro avg       1.00      1.00      1.00      1780\n",
      "weighted avg       1.00      1.00      1.00      1780\n",
      "\n",
      "TP_H 100  TN_H 120  TP_M 900  TN_M 878  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  230 ********************\n",
      "processing  22 th loops---------------\n",
      "training set size: 230 unique(labels): [0 1] label counts: [130 100]\n",
      "Number of training examples  230\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       870\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1770\n",
      "   macro avg       1.00      1.00      1.00      1770\n",
      "weighted avg       1.00      1.00      1.00      1770\n",
      "\n",
      "TP_H 100  TN_H 130  TP_M 900  TN_M 868  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  240 ********************\n",
      "processing  23 th loops---------------\n",
      "training set size: 240 unique(labels): [0 1] label counts: [140 100]\n",
      "Number of training examples  240\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       860\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1760\n",
      "   macro avg       1.00      1.00      1.00      1760\n",
      "weighted avg       1.00      1.00      1.00      1760\n",
      "\n",
      "TP_H 100  TN_H 140  TP_M 900  TN_M 858  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  250 ********************\n",
      "processing  24 th loops---------------\n",
      "training set size: 250 unique(labels): [0 1] label counts: [150 100]\n",
      "Number of training examples  250\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       850\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1750\n",
      "   macro avg       1.00      1.00      1.00      1750\n",
      "weighted avg       1.00      1.00      1.00      1750\n",
      "\n",
      "TP_H 100  TN_H 150  TP_M 900  TN_M 848  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  260 ********************\n",
      "processing  25 th loops---------------\n",
      "training set size: 260 unique(labels): [0 1] label counts: [160 100]\n",
      "Number of training examples  260\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       840\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1740\n",
      "   macro avg       1.00      1.00      1.00      1740\n",
      "weighted avg       1.00      1.00      1.00      1740\n",
      "\n",
      "TP_H 100  TN_H 160  TP_M 900  TN_M 838  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  270 ********************\n",
      "processing  26 th loops---------------\n",
      "training set size: 270 unique(labels): [0 1] label counts: [170 100]\n",
      "Number of training examples  270\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       830\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1730\n",
      "   macro avg       1.00      1.00      1.00      1730\n",
      "weighted avg       1.00      1.00      1.00      1730\n",
      "\n",
      "TP_H 100  TN_H 170  TP_M 900  TN_M 828  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  280 ********************\n",
      "processing  27 th loops---------------\n",
      "training set size: 280 unique(labels): [0 1] label counts: [180 100]\n",
      "Number of training examples  280\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       820\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1720\n",
      "   macro avg       1.00      1.00      1.00      1720\n",
      "weighted avg       1.00      1.00      1.00      1720\n",
      "\n",
      "TP_H 100  TN_H 180  TP_M 900  TN_M 818  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  290 ********************\n",
      "processing  28 th loops---------------\n",
      "training set size: 290 unique(labels): [0 1] label counts: [190 100]\n",
      "Number of training examples  290\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       810\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1710\n",
      "   macro avg       1.00      1.00      1.00      1710\n",
      "weighted avg       1.00      1.00      1.00      1710\n",
      "\n",
      "TP_H 100  TN_H 190  TP_M 900  TN_M 808  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  300 ********************\n",
      "processing  29 th loops---------------\n",
      "training set size: 300 unique(labels): [0 1] label counts: [200 100]\n",
      "Number of training examples  300\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       800\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1700\n",
      "   macro avg       1.00      1.00      1.00      1700\n",
      "weighted avg       1.00      1.00      1.00      1700\n",
      "\n",
      "TP_H 100  TN_H 200  TP_M 900  TN_M 798  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  310 ********************\n",
      "processing  30 th loops---------------\n",
      "training set size: 310 unique(labels): [0 1] label counts: [210 100]\n",
      "Number of training examples  310\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       790\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1690\n",
      "   macro avg       1.00      1.00      1.00      1690\n",
      "weighted avg       1.00      1.00      1.00      1690\n",
      "\n",
      "TP_H 100  TN_H 210  TP_M 900  TN_M 788  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  320 ********************\n",
      "processing  31 th loops---------------\n",
      "training set size: 320 unique(labels): [0 1] label counts: [220 100]\n",
      "Number of training examples  320\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       780\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1680\n",
      "   macro avg       1.00      1.00      1.00      1680\n",
      "weighted avg       1.00      1.00      1.00      1680\n",
      "\n",
      "TP_H 100  TN_H 220  TP_M 900  TN_M 778  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  330 ********************\n",
      "processing  32 th loops---------------\n",
      "training set size: 330 unique(labels): [0 1] label counts: [230 100]\n",
      "Number of training examples  330\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       770\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1670\n",
      "   macro avg       1.00      1.00      1.00      1670\n",
      "weighted avg       1.00      1.00      1.00      1670\n",
      "\n",
      "TP_H 100  TN_H 230  TP_M 900  TN_M 768  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  340 ********************\n",
      "processing  33 th loops---------------\n",
      "training set size: 340 unique(labels): [0 1] label counts: [240 100]\n",
      "Number of training examples  340\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       760\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1660\n",
      "   macro avg       1.00      1.00      1.00      1660\n",
      "weighted avg       1.00      1.00      1.00      1660\n",
      "\n",
      "TP_H 100  TN_H 240  TP_M 900  TN_M 758  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  350 ********************\n",
      "processing  34 th loops---------------\n",
      "training set size: 350 unique(labels): [0 1] label counts: [250 100]\n",
      "Number of training examples  350\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       750\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1650\n",
      "   macro avg       1.00      1.00      1.00      1650\n",
      "weighted avg       1.00      1.00      1.00      1650\n",
      "\n",
      "TP_H 100  TN_H 250  TP_M 900  TN_M 748  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  360 ********************\n",
      "processing  35 th loops---------------\n",
      "training set size: 360 unique(labels): [0 1] label counts: [260 100]\n",
      "Number of training examples  360\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       740\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1640\n",
      "   macro avg       1.00      1.00      1.00      1640\n",
      "weighted avg       1.00      1.00      1.00      1640\n",
      "\n",
      "TP_H 100  TN_H 260  TP_M 900  TN_M 738  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  370 ********************\n",
      "processing  36 th loops---------------\n",
      "training set size: 370 unique(labels): [0 1] label counts: [270 100]\n",
      "Number of training examples  370\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       730\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1630\n",
      "   macro avg       1.00      1.00      1.00      1630\n",
      "weighted avg       1.00      1.00      1.00      1630\n",
      "\n",
      "TP_H 100  TN_H 270  TP_M 900  TN_M 728  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  380 ********************\n",
      "processing  37 th loops---------------\n",
      "training set size: 380 unique(labels): [0 1] label counts: [280 100]\n",
      "Number of training examples  380\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       720\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1620\n",
      "   macro avg       1.00      1.00      1.00      1620\n",
      "weighted avg       1.00      1.00      1.00      1620\n",
      "\n",
      "TP_H 100  TN_H 280  TP_M 900  TN_M 718  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  390 ********************\n",
      "processing  38 th loops---------------\n",
      "training set size: 390 unique(labels): [0 1] label counts: [290 100]\n",
      "Number of training examples  390\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       710\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1610\n",
      "   macro avg       1.00      1.00      1.00      1610\n",
      "weighted avg       1.00      1.00      1.00      1610\n",
      "\n",
      "TP_H 100  TN_H 290  TP_M 900  TN_M 708  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  400 ********************\n",
      "processing  39 th loops---------------\n",
      "training set size: 400 unique(labels): [0 1] label counts: [300 100]\n",
      "Number of training examples  400\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       700\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1600\n",
      "   macro avg       1.00      1.00      1.00      1600\n",
      "weighted avg       1.00      1.00      1.00      1600\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_H 100  TN_H 300  TP_M 900  TN_M 698  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  410 ********************\n",
      "processing  40 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:01:16.431412 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0121 00:01:16.432410 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:01:17.260195 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0121 00:01:17.260195 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0121 00:01:17.329011 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0121 00:01:17.332005 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:01:17.332005 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n",
      "I0121 00:01:20.307042 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 116.03it/s]\n",
      "I0121 00:01:24.691311 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:01:24.916708 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0121 00:01:24.916708 15348 fine_tuned.py:166]   Num examples = 410\n",
      "I0121 00:01:24.917706 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0121 00:01:24.917706 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0121 00:01:24.917706 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0121 00:01:24.918703 15348 fine_tuned.py:170]   Total optimization steps = 1545\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522cb0b6ff3f4003b3ad1a07700d74e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.001185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000132"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:40<09:20, 40.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823441cfe33f480bbe4ced00edb6de42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:02:17.726398 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-136\\config.json\n",
      "I0121 00:02:19.311157 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-136\\pytorch_model.bin\n",
      "I0121 00:02:19.312155 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:21<08:45, 40.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8374403ddd4c6fbcca0a0a4cb56411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:03:11.030765 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-272\\config.json\n",
      "I0121 00:03:12.279424 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-272\\pytorch_model.bin\n",
      "I0121 00:03:12.280421 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:01<08:03, 40.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e92e5babbf41e89c947da431b51a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:04:04.288278 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-408\\config.json\n",
      "I0121 00:04:05.559659 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-408\\pytorch_model.bin\n",
      "I0121 00:04:05.560686 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [02:42<07:24, 40.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0ea1c74e3b4768803825e854c4034e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [03:20<06:38, 39.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000033\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402c1d37235d432b913c6561b51f3008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:04:56.345739 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-544\\config.json\n",
      "I0121 00:04:57.541540 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-544\\pytorch_model.bin\n",
      "I0121 00:04:57.541540 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000029"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [04:00<05:58, 39.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7018dd4abdfc43178b09abd049c28205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:05:48.494459 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-680\\config.json\n",
      "I0121 00:05:49.742094 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-680\\pytorch_model.bin\n",
      "I0121 00:05:49.743092 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [04:39<05:18, 39.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318f39c13f244e4c863c735dc6bf538f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:06:40.179026 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-816\\config.json\n",
      "I0121 00:06:41.389786 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-816\\pytorch_model.bin\n",
      "I0121 00:06:41.390784 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [05:19<04:37, 39.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d87135b57324075b2fc0e0c885c9d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [05:58<03:56, 39.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76318e87ae84609924374a905a7807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:07:32.247739 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-952\\config.json\n",
      "I0121 00:07:33.519337 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-952\\pytorch_model.bin\n",
      "I0121 00:07:33.520336 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [06:37<03:17, 39.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81711b55c1f4bea9ec9ce5cef0e8390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:08:24.533119 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1088\\config.json\n",
      "I0121 00:08:25.791752 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0121 00:08:25.792749 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [07:17<02:38, 39.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000017\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2628a1f7d14eadbefdbc9ed8337208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:09:16.571469 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1224\\config.json\n",
      "I0121 00:09:17.831097 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1224\\pytorch_model.bin\n",
      "I0121 00:09:17.832096 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [07:57<01:58, 39.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd07c5182ec47bbbbdb10a92d3b80d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [08:35<01:18, 39.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687596943b634aa3bd7e51a383052da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:10:08.447070 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1360\\config.json\n",
      "I0121 00:10:09.683760 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1360\\pytorch_model.bin\n",
      "I0121 00:10:09.684760 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [09:15<00:39, 39.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75fa27618b94ef58fee0ae72458bd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:00.302255 15348 configuration_utils.py:72] Configuration saved in outputs/40\\dbpedia-1496\\config.json\n",
      "I0121 00:11:01.539943 15348 modeling_utils.py:251] Model weights saved in outputs/40\\dbpedia-1496\\pytorch_model.bin\n",
      "I0121 00:11:01.539943 15348 fine_tuned.py:227] Saving model checkpoint to outputs/40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [09:54<00:00, 39.65s/it]\n",
      "I0121 00:11:19.691726 15348 fine_tuned.py:405]  global_step = 1545, average loss = 0.00912468706326963\n",
      "I0121 00:11:19.702694 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\20\\\\dbpedia-280', 'outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\40\\\\dbpedia-1224', 'outputs\\\\40\\\\dbpedia-1360', 'outputs\\\\40\\\\dbpedia-136', 'outputs\\\\40\\\\dbpedia-1496', 'outputs\\\\40\\\\dbpedia-272', 'outputs\\\\40\\\\dbpedia-408', 'outputs\\\\40\\\\dbpedia-544', 'outputs\\\\40\\\\dbpedia-680', 'outputs\\\\40\\\\dbpedia-816', 'outputs\\\\40\\\\dbpedia-952']\n",
      "I0121 00:11:19.702694 15348 configuration_utils.py:157] loading configuration file outputs\\20\\dbpedia-280\\config.json\n",
      "I0121 00:11:19.704688 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:11:19.705687 15348 modeling_utils.py:398] loading weights file outputs\\20\\dbpedia-280\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\20\\dbpedia-280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:22.616895 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 93.67it/s]\n",
      "I0121 00:11:27.786064 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:11:27.999493 15348 fine_tuned.py:285] ***** Running evaluation 280 *****\n",
      "I0121 00:11:27.999493 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:11:28.000489 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa124acf9ee403292201c1f746aa6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:37.177933 15348 fine_tuned.py:366] ***** Eval results 280 *****\n",
      "I0121 00:11:37.177933 15348 fine_tuned.py:368]   acc = 0.9975609756097561\n",
      "I0121 00:11:37.178931 15348 fine_tuned.py:368]   fn = 1\n",
      "I0121 00:11:37.178931 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:11:37.178931 15348 fine_tuned.py:368]   mcc = 0.9933864908771584\n",
      "I0121 00:11:37.179928 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:11:37.179928 15348 fine_tuned.py:368]   tp = 99\n",
      "I0121 00:11:37.180926 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0121 00:11:37.181923 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:11:37.181923 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:40.166935 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 118.57it/s]\n",
      "I0121 00:11:44.374675 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:11:44.586110 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0121 00:11:44.587107 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:11:44.587107 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be8604db9934326b6054c10a822ca39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:53.765279 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0121 00:11:53.766276 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:11:53.766276 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:11:53.766276 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:11:53.767273 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:11:53.767273 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:11:53.767273 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:11:53.768270 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1224\\config.json\n",
      "I0121 00:11:53.769268 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:11:53.770265 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1224\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:11:56.738322 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 114.74it/s]\n",
      "I0121 00:12:00.559099 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:12:00.767540 15348 fine_tuned.py:285] ***** Running evaluation 1224 *****\n",
      "I0121 00:12:00.768538 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:12:00.769536 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1bdaf249d94795a436d816eea30ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:09.928078 15348 fine_tuned.py:366] ***** Eval results 1224 *****\n",
      "I0121 00:12:09.929074 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:12:09.929074 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:12:09.930072 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:12:09.930072 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:12:09.931069 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:12:09.931069 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:12:09.932067 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1360\\config.json\n",
      "I0121 00:12:09.933064 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:12:09.933064 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1360\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:12.992875 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 114.64it/s]\n",
      "I0121 00:12:17.272425 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:12:17.480867 15348 fine_tuned.py:285] ***** Running evaluation 1360 *****\n",
      "I0121 00:12:17.480867 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:12:17.481864 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97472d3c1491420eaa90758200976663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:26.698538 15348 fine_tuned.py:366] ***** Eval results 1360 *****\n",
      "I0121 00:12:26.698538 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:12:26.699536 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:12:26.699536 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:12:26.700533 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:12:26.700533 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:12:26.700533 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:12:26.701531 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-136\\config.json\n",
      "I0121 00:12:26.702527 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:12:26.702527 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-136\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:29.612739 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 113.56it/s]\n",
      "I0121 00:12:33.444486 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:12:33.650934 15348 fine_tuned.py:285] ***** Running evaluation 136 *****\n",
      "I0121 00:12:33.651932 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:12:33.651932 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63176c248e04922af5216660e8ac87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:42.811917 15348 fine_tuned.py:366] ***** Eval results 136 *****\n",
      "I0121 00:12:42.811917 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:12:42.812914 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:12:42.812914 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:12:42.813912 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:12:42.813912 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:12:42.813912 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:12:42.814909 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1496\\config.json\n",
      "I0121 00:12:42.815906 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:12:42.815906 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1496\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:45.764018 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 115.48it/s]\n",
      "I0121 00:12:49.540912 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:12:49.756336 15348 fine_tuned.py:285] ***** Running evaluation 1496 *****\n",
      "I0121 00:12:49.756336 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:12:49.757333 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50dffcb9d93a4241955e9cdd0dfa39a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:12:58.942788 15348 fine_tuned.py:366] ***** Eval results 1496 *****\n",
      "I0121 00:12:58.943785 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:12:58.944783 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:12:58.944783 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:12:58.945780 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:12:58.945780 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:12:58.946778 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:12:58.946778 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-272\\config.json\n",
      "I0121 00:12:58.947775 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:12:58.947775 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-272\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:01.997614 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 90.53it/s]\n",
      "I0121 00:13:07.292455 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:13:07.524834 15348 fine_tuned.py:285] ***** Running evaluation 272 *****\n",
      "I0121 00:13:07.525859 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:13:07.526829 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a74057a8f947e4b12020ef9215793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:16.685323 15348 fine_tuned.py:366] ***** Eval results 272 *****\n",
      "I0121 00:13:16.685323 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:13:16.686320 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:13:16.686320 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:13:16.687319 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:13:16.687319 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:13:16.688315 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:13:16.688315 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-408\\config.json\n",
      "I0121 00:13:16.689312 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:13:16.690308 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-408\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:19.718206 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 91.78it/s]\n",
      "I0121 00:13:24.480463 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:13:24.702896 15348 fine_tuned.py:285] ***** Running evaluation 408 *****\n",
      "I0121 00:13:24.703893 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:13:24.703893 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812cf049f1b04b47bf26437da253627d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:33.844668 15348 fine_tuned.py:366] ***** Eval results 408 *****\n",
      "I0121 00:13:33.845665 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:13:33.845665 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:13:33.845665 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:13:33.846663 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:13:33.846663 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:13:33.847661 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:13:33.847661 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-544\\config.json\n",
      "I0121 00:13:33.848658 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:13:33.849655 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-544\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:36.814729 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 94.22it/s]\n",
      "I0121 00:13:41.943996 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:13:42.158424 15348 fine_tuned.py:285] ***** Running evaluation 544 *****\n",
      "I0121 00:13:42.159421 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:13:42.159421 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03d71bbbeb6491c916981a2b252a30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:51.350516 15348 fine_tuned.py:366] ***** Eval results 544 *****\n",
      "I0121 00:13:51.351513 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:13:51.351513 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:13:51.351513 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:13:51.352510 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:13:51.352510 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:13:51.352510 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:13:51.353507 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-680\\config.json\n",
      "I0121 00:13:51.354506 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:13:51.355503 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-680\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:13:54.312589 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 410/410 [00:04<00:00, 98.37it/s]\n",
      "I0121 00:13:58.757696 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:13:59.039941 15348 fine_tuned.py:285] ***** Running evaluation 680 *****\n",
      "I0121 00:13:59.040939 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:13:59.041936 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803eebed71524369a26c663b83d421b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:08.267473 15348 fine_tuned.py:366] ***** Eval results 680 *****\n",
      "I0121 00:14:08.267473 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:14:08.268471 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:14:08.268471 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:14:08.268471 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:14:08.269468 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:14:08.269468 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:14:08.270465 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-816\\config.json\n",
      "I0121 00:14:08.271463 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:14:08.271463 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-816\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:11.259468 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 104.93it/s]\n",
      "I0121 00:14:15.939945 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:14:16.218199 15348 fine_tuned.py:285] ***** Running evaluation 816 *****\n",
      "I0121 00:14:16.219196 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:14:16.219196 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539d3ac3504f4c5db59c0603c5966642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:25.436217 15348 fine_tuned.py:366] ***** Eval results 816 *****\n",
      "I0121 00:14:25.437215 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:14:25.437215 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:14:25.437215 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:14:25.438211 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:14:25.438211 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:14:25.439210 15348 fine_tuned.py:368]   tp = 100\n",
      "I0121 00:14:25.440206 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-952\\config.json\n",
      "I0121 00:14:25.441204 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:14:25.442202 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-952\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:28.471096 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 410/410 [00:03<00:00, 109.25it/s]\n",
      "I0121 00:14:32.964075 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:14:33.211414 15348 fine_tuned.py:285] ***** Running evaluation 952 *****\n",
      "I0121 00:14:33.212409 15348 fine_tuned.py:286]   Num examples = 410\n",
      "I0121 00:14:33.212409 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a460809d15374c02bdedc0c3f9764471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=103.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:42.430524 15348 fine_tuned.py:366] ***** Eval results 952 *****\n",
      "I0121 00:14:42.431521 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:14:42.431521 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:14:42.431521 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:14:42.432518 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:14:42.432518 15348 fine_tuned.py:368]   tn = 310\n",
      "I0121 00:14:42.433516 15348 fine_tuned.py:368]   tp = 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:14:43.131648 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0121 00:14:43.132663 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0121 00:14:43.193516 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0121 00:14:43.194507 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:14:43.195489 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531baffc9d2e4b8a9532b7918cd22dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 410 unique(labels): [0 1] label counts: [310 100]\n",
      "Number of training examples  410\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       690\n",
      "           1       1.00      1.00      1.00       900\n",
      "\n",
      "    accuracy                           1.00      1590\n",
      "   macro avg       1.00      1.00      1.00      1590\n",
      "weighted avg       1.00      1.00      1.00      1590\n",
      "\n",
      "TP_H 100  TN_H 310  TP_M 896  TN_M 688  FP_M 2  FN_M 4\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  420 ********************\n",
      "processing  41 th loops---------------\n",
      "training set size: 420 unique(labels): [0 1] label counts: [310 110]\n",
      "Number of training examples  420\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       690\n",
      "           1       1.00      1.00      1.00       890\n",
      "\n",
      "    accuracy                           1.00      1580\n",
      "   macro avg       1.00      1.00      1.00      1580\n",
      "weighted avg       1.00      1.00      1.00      1580\n",
      "\n",
      "TP_H 110  TN_H 310  TP_M 889  TN_M 688  FP_M 2  FN_M 1\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  430 ********************\n",
      "processing  42 th loops---------------\n",
      "training set size: 430 unique(labels): [0 1] label counts: [319 111]\n",
      "Number of training examples  430\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       889\n",
      "\n",
      "    accuracy                           1.00      1570\n",
      "   macro avg       1.00      1.00      1.00      1570\n",
      "weighted avg       1.00      1.00      1.00      1570\n",
      "\n",
      "TP_H 111  TN_H 319  TP_M 889  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  440 ********************\n",
      "processing  43 th loops---------------\n",
      "training set size: 440 unique(labels): [0 1] label counts: [319 121]\n",
      "Number of training examples  440\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       879\n",
      "\n",
      "    accuracy                           1.00      1560\n",
      "   macro avg       1.00      1.00      1.00      1560\n",
      "weighted avg       1.00      1.00      1.00      1560\n",
      "\n",
      "TP_H 121  TN_H 319  TP_M 879  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  450 ********************\n",
      "processing  44 th loops---------------\n",
      "training set size: 450 unique(labels): [0 1] label counts: [319 131]\n",
      "Number of training examples  450\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       869\n",
      "\n",
      "    accuracy                           1.00      1550\n",
      "   macro avg       1.00      1.00      1.00      1550\n",
      "weighted avg       1.00      1.00      1.00      1550\n",
      "\n",
      "TP_H 131  TN_H 319  TP_M 869  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  460 ********************\n",
      "processing  45 th loops---------------\n",
      "training set size: 460 unique(labels): [0 1] label counts: [319 141]\n",
      "Number of training examples  460\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       859\n",
      "\n",
      "    accuracy                           1.00      1540\n",
      "   macro avg       1.00      1.00      1.00      1540\n",
      "weighted avg       1.00      1.00      1.00      1540\n",
      "\n",
      "TP_H 141  TN_H 319  TP_M 859  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  470 ********************\n",
      "processing  46 th loops---------------\n",
      "training set size: 470 unique(labels): [0 1] label counts: [319 151]\n",
      "Number of training examples  470\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       849\n",
      "\n",
      "    accuracy                           1.00      1530\n",
      "   macro avg       1.00      1.00      1.00      1530\n",
      "weighted avg       1.00      1.00      1.00      1530\n",
      "\n",
      "TP_H 151  TN_H 319  TP_M 849  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  480 ********************\n",
      "processing  47 th loops---------------\n",
      "training set size: 480 unique(labels): [0 1] label counts: [319 161]\n",
      "Number of training examples  480\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       681\n",
      "           1       1.00      1.00      1.00       839\n",
      "\n",
      "    accuracy                           1.00      1520\n",
      "   macro avg       1.00      1.00      1.00      1520\n",
      "weighted avg       1.00      1.00      1.00      1520\n",
      "\n",
      "TP_H 161  TN_H 319  TP_M 839  TN_M 679  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  490 ********************\n",
      "processing  48 th loops---------------\n",
      "training set size: 490 unique(labels): [0 1] label counts: [320 170]\n",
      "Number of training examples  490\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       680\n",
      "           1       1.00      1.00      1.00       830\n",
      "\n",
      "    accuracy                           1.00      1510\n",
      "   macro avg       1.00      1.00      1.00      1510\n",
      "weighted avg       1.00      1.00      1.00      1510\n",
      "\n",
      "TP_H 170  TN_H 320  TP_M 830  TN_M 678  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  500 ********************\n",
      "processing  49 th loops---------------\n",
      "training set size: 500 unique(labels): [0 1] label counts: [322 178]\n",
      "Number of training examples  500\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       678\n",
      "           1       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           1.00      1500\n",
      "   macro avg       1.00      1.00      1.00      1500\n",
      "weighted avg       1.00      1.00      1.00      1500\n",
      "\n",
      "TP_H 178  TN_H 322  TP_M 822  TN_M 676  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  510 ********************\n",
      "processing  50 th loops---------------\n",
      "training set size: 510 unique(labels): [0 1] label counts: [322 188]\n",
      "Number of training examples  510\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       678\n",
      "           1       1.00      1.00      1.00       812\n",
      "\n",
      "    accuracy                           1.00      1490\n",
      "   macro avg       1.00      1.00      1.00      1490\n",
      "weighted avg       1.00      1.00      1.00      1490\n",
      "\n",
      "TP_H 188  TN_H 322  TP_M 812  TN_M 676  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  520 ********************\n",
      "processing  51 th loops---------------\n",
      "training set size: 520 unique(labels): [0 1] label counts: [324 196]\n",
      "Number of training examples  520\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       676\n",
      "           1       1.00      1.00      1.00       804\n",
      "\n",
      "    accuracy                           1.00      1480\n",
      "   macro avg       1.00      1.00      1.00      1480\n",
      "weighted avg       1.00      1.00      1.00      1480\n",
      "\n",
      "TP_H 196  TN_H 324  TP_M 804  TN_M 674  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  530 ********************\n",
      "processing  52 th loops---------------\n",
      "training set size: 530 unique(labels): [0 1] label counts: [324 206]\n",
      "Number of training examples  530\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       676\n",
      "           1       1.00      1.00      1.00       794\n",
      "\n",
      "    accuracy                           1.00      1470\n",
      "   macro avg       1.00      1.00      1.00      1470\n",
      "weighted avg       1.00      1.00      1.00      1470\n",
      "\n",
      "TP_H 206  TN_H 324  TP_M 794  TN_M 674  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  540 ********************\n",
      "processing  53 th loops---------------\n",
      "training set size: 540 unique(labels): [0 1] label counts: [328 212]\n",
      "Number of training examples  540\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       672\n",
      "           1       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1460\n",
      "   macro avg       1.00      1.00      1.00      1460\n",
      "weighted avg       1.00      1.00      1.00      1460\n",
      "\n",
      "TP_H 212  TN_H 328  TP_M 788  TN_M 670  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  550 ********************\n",
      "processing  54 th loops---------------\n",
      "training set size: 550 unique(labels): [0 1] label counts: [330 220]\n",
      "Number of training examples  550\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       670\n",
      "           1       1.00      1.00      1.00       780\n",
      "\n",
      "    accuracy                           1.00      1450\n",
      "   macro avg       1.00      1.00      1.00      1450\n",
      "weighted avg       1.00      1.00      1.00      1450\n",
      "\n",
      "TP_H 220  TN_H 330  TP_M 780  TN_M 668  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  560 ********************\n",
      "processing  55 th loops---------------\n",
      "training set size: 560 unique(labels): [0 1] label counts: [330 230]\n",
      "Number of training examples  560\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       670\n",
      "           1       1.00      1.00      1.00       770\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "TP_H 230  TN_H 330  TP_M 770  TN_M 668  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  570 ********************\n",
      "processing  56 th loops---------------\n",
      "training set size: 570 unique(labels): [0 1] label counts: [330 240]\n",
      "Number of training examples  570\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       670\n",
      "           1       1.00      1.00      1.00       760\n",
      "\n",
      "    accuracy                           1.00      1430\n",
      "   macro avg       1.00      1.00      1.00      1430\n",
      "weighted avg       1.00      1.00      1.00      1430\n",
      "\n",
      "TP_H 240  TN_H 330  TP_M 760  TN_M 668  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  580 ********************\n",
      "processing  57 th loops---------------\n",
      "training set size: 580 unique(labels): [0 1] label counts: [330 250]\n",
      "Number of training examples  580\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       670\n",
      "           1       1.00      1.00      1.00       750\n",
      "\n",
      "    accuracy                           1.00      1420\n",
      "   macro avg       1.00      1.00      1.00      1420\n",
      "weighted avg       1.00      1.00      1.00      1420\n",
      "\n",
      "TP_H 250  TN_H 330  TP_M 750  TN_M 668  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  590 ********************\n",
      "processing  58 th loops---------------\n",
      "training set size: 590 unique(labels): [0 1] label counts: [331 259]\n",
      "Number of training examples  590\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       669\n",
      "           1       1.00      1.00      1.00       741\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "TP_H 259  TN_H 331  TP_M 741  TN_M 667  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  600 ********************\n",
      "processing  59 th loops---------------\n",
      "training set size: 600 unique(labels): [0 1] label counts: [333 267]\n",
      "Number of training examples  600\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       667\n",
      "           1       1.00      1.00      1.00       733\n",
      "\n",
      "    accuracy                           1.00      1400\n",
      "   macro avg       1.00      1.00      1.00      1400\n",
      "weighted avg       1.00      1.00      1.00      1400\n",
      "\n",
      "TP_H 267  TN_H 333  TP_M 733  TN_M 665  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  610 ********************\n",
      "processing  60 th loops---------------\n",
      "constructing new text training set.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:16:09.368573 15348 configuration_utils.py:160] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n",
      "I0121 00:16:09.369573 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": \"binary\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:16:10.287088 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0121 00:16:10.288086 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0121 00:16:10.350917 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0121 00:16:10.351917 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:16:10.351917 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n",
      "I0121 00:16:13.677017 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 134.90it/s]\n",
      "I0121 00:16:19.012739 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:16:19.336873 15348 fine_tuned.py:165] ***** Running training *****\n",
      "I0121 00:16:19.336873 15348 fine_tuned.py:166]   Num examples = 610\n",
      "I0121 00:16:19.337870 15348 fine_tuned.py:167]   Num Epochs = 15\n",
      "I0121 00:16:19.337870 15348 fine_tuned.py:168]   Total train batch size  = 4\n",
      "I0121 00:16:19.338867 15348 fine_tuned.py:169]   Gradient Accumulation steps = 1\n",
      "I0121 00:16:19.338867 15348 fine_tuned.py:170]   Total optimization steps = 2295\n",
      "Epoch:   0%|                                                                                    | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46197190dcd145b49514d129edbc9895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000014"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jh\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|█████                                                                       | 1/15 [00:58<13:38, 58.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c70b475d48e40b7beb3ea646355a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:17:36.944350 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-203\\config.json\n",
      "I0121 00:17:38.662757 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-203\\pytorch_model.bin\n",
      "I0121 00:17:38.663754 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000013"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|██████████▏                                                                 | 2/15 [01:58<12:44, 58.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fc328b8d8d4a7791772bbe2e2e0870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000019"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:18:55.221594 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-406\\config.json\n",
      "I0121 00:18:56.685678 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-406\\pytorch_model.bin\n",
      "I0121 00:18:56.686675 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|███████████████▏                                                            | 3/15 [02:57<11:46, 58.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85395ea560e4df4bd5dd7a323d9d9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:20:12.754343 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-609\\config.json\n",
      "I0121 00:20:14.082787 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-609\\pytorch_model.bin\n",
      "I0121 00:20:14.082787 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|████████████████████▎                                                       | 4/15 [03:55<10:46, 58.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f903ef9c78274e24b9f57679c2892c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|█████████████████████████▎                                                  | 5/15 [04:53<09:43, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5053d8fe88f64c25b864eb8f4310dbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:21:30.250817 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-812\\config.json\n",
      "I0121 00:21:31.497481 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-812\\pytorch_model.bin\n",
      "I0121 00:21:31.498479 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000008"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|██████████████████████████████▍                                             | 6/15 [05:51<08:46, 58.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f398637ffe84242ae5a668c4ae4b3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:22:47.382470 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1015\\config.json\n",
      "I0121 00:22:48.602205 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1015\\pytorch_model.bin\n",
      "I0121 00:22:48.603203 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|███████████████████████████████████▍                                        | 7/15 [06:49<07:47, 58.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3571e70bf2a2477ba01191ed7abb6946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:24:04.444200 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1218\\config.json\n",
      "I0121 00:24:05.642992 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1218\\pytorch_model.bin\n",
      "I0121 00:24:05.643989 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|████████████████████████████████████████▌                                   | 8/15 [07:48<06:48, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0953b94d334429a0c69be0f7432220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|█████████████████████████████████████████████▌                              | 9/15 [08:45<05:48, 58.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0.000006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adac7c7cfa454ae2b5f6a7769c2fc277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:25:21.344958 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1421\\config.json\n",
      "I0121 00:25:22.507141 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1421\\pytorch_model.bin\n",
      "I0121 00:25:22.508138 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████████████████████████████████████████████████                         | 10/15 [09:43<04:50, 58.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be706d7a840746cfac9f7f7c2df4d1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:26:38.538240 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1624\\config.json\n",
      "I0121 00:26:39.777929 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1624\\pytorch_model.bin\n",
      "I0121 00:26:39.778922 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|██████████████████████████████████████████████████████▉                    | 11/15 [10:42<03:52, 58.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ab3366008b418cb0993d3d7b0067ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000006"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:27:55.983256 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-1827\\config.json\n",
      "I0121 00:27:57.261834 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-1827\\pytorch_model.bin\n",
      "I0121 00:27:57.262832 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████████████████████████████████████████████████████████               | 12/15 [11:41<02:55, 58.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223d0ce63ed543709b55150b2426db96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|█████████████████████████████████████████████████████████████████          | 13/15 [12:38<01:55, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fc482aabf44a5788517ae16d6cefcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:29:13.018295 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2030\\config.json\n",
      "I0121 00:29:14.227060 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2030\\pytorch_model.bin\n",
      "I0121 00:29:14.228059 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|██████████████████████████████████████████████████████████████████████     | 14/15 [13:36<00:58, 58.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab80b24a31040778d7f8f4314d185ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=153.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000005"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:30:29.942789 15348 configuration_utils.py:72] Configuration saved in outputs/60\\dbpedia-2233\\config.json\n",
      "I0121 00:30:31.152552 15348 modeling_utils.py:251] Model weights saved in outputs/60\\dbpedia-2233\\pytorch_model.bin\n",
      "I0121 00:30:31.153550 15348 fine_tuned.py:227] Saving model checkpoint to outputs/60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████| 15/15 [14:34<00:00, 58.32s/it]\n",
      "I0121 00:30:54.175827 15348 fine_tuned.py:405]  global_step = 2295, average loss = 0.009058045600753984\n",
      "I0121 00:30:54.180814 15348 fine_tuned.py:414] Evaluate the following checkpoints: ['outputs\\\\40\\\\dbpedia-1088', 'outputs\\\\60\\\\dbpedia-1015', 'outputs\\\\60\\\\dbpedia-1218', 'outputs\\\\60\\\\dbpedia-1421', 'outputs\\\\60\\\\dbpedia-1624', 'outputs\\\\60\\\\dbpedia-1827', 'outputs\\\\60\\\\dbpedia-2030', 'outputs\\\\60\\\\dbpedia-203', 'outputs\\\\60\\\\dbpedia-2233', 'outputs\\\\60\\\\dbpedia-406', 'outputs\\\\60\\\\dbpedia-609', 'outputs\\\\60\\\\dbpedia-812']\n",
      "I0121 00:30:54.181811 15348 configuration_utils.py:157] loading configuration file outputs\\40\\dbpedia-1088\\config.json\n",
      "I0121 00:30:54.181811 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:30:54.182809 15348 modeling_utils.py:398] loading weights file outputs\\40\\dbpedia-1088\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\40\\dbpedia-1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:30:57.184775 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:05<00:00, 105.00it/s]\n",
      "I0121 00:31:03.268496 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:31:03.605593 15348 fine_tuned.py:285] ***** Running evaluation 1088 *****\n",
      "I0121 00:31:03.606590 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:31:03.606590 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f01287490d4c68851207df35dedafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:31:17.313527 15348 fine_tuned.py:366] ***** Eval results 1088 *****\n",
      "I0121 00:31:17.314523 15348 fine_tuned.py:368]   acc = 0.9918032786885246\n",
      "I0121 00:31:17.314523 15348 fine_tuned.py:368]   fn = 5\n",
      "I0121 00:31:17.315529 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:31:17.315529 15348 fine_tuned.py:368]   mcc = 0.9835429003202354\n",
      "I0121 00:31:17.315529 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:31:17.316490 15348 fine_tuned.py:368]   tp = 269\n",
      "I0121 00:31:17.317488 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0121 00:31:17.318484 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:31:17.318484 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:31:20.273577 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 146.18it/s]\n",
      "I0121 00:31:24.702748 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:31:25.010931 15348 fine_tuned.py:285] ***** Running evaluation 1015 *****\n",
      "I0121 00:31:25.011925 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:31:25.012896 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65462983794f48c6b5158b5100e364d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:31:38.630014 15348 fine_tuned.py:366] ***** Eval results 1015 *****\n",
      "I0121 00:31:38.631010 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:31:38.631010 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:31:38.632008 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:31:38.632008 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:31:38.633006 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:31:38.633006 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:31:38.634003 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1218\\config.json\n",
      "I0121 00:31:38.635001 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:31:38.635001 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1218\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:31:41.659906 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 147.10it/s]\n",
      "I0121 00:31:46.150913 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:31:46.466045 15348 fine_tuned.py:285] ***** Running evaluation 1218 *****\n",
      "I0121 00:31:46.466045 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:31:46.467042 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04d0e4ab86c4e8692c902715a71de59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:00.166647 15348 fine_tuned.py:366] ***** Eval results 1218 *****\n",
      "I0121 00:32:00.167643 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:32:00.167643 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:32:00.168641 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:32:00.168641 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:32:00.168641 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:32:00.169639 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:32:00.170637 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1421\\config.json\n",
      "I0121 00:32:00.171635 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:32:00.171635 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1421\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:03.149664 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 147.42it/s]\n",
      "I0121 00:32:07.654610 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:32:07.985752 15348 fine_tuned.py:285] ***** Running evaluation 1421 *****\n",
      "I0121 00:32:07.986754 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:32:07.986754 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c9527bd57c4af28d216279909de1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:21.664311 15348 fine_tuned.py:366] ***** Eval results 1421 *****\n",
      "I0121 00:32:21.664311 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:32:21.665308 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:32:21.665308 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:32:21.666306 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:32:21.666306 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:32:21.667303 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:32:21.668300 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1624\\config.json\n",
      "I0121 00:32:21.668300 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:32:21.669298 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1624\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:24.595467 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 151.66it/s]\n",
      "I0121 00:32:29.429562 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:32:29.739730 15348 fine_tuned.py:285] ***** Running evaluation 1624 *****\n",
      "I0121 00:32:29.739730 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:32:29.740701 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d846f549df14265bcdc2da0621576f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:43.475624 15348 fine_tuned.py:366] ***** Eval results 1624 *****\n",
      "I0121 00:32:43.476622 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:32:43.476622 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:32:43.476622 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:32:43.477619 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:32:43.477619 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:32:43.478618 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:32:43.479614 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1827\\config.json\n",
      "I0121 00:32:43.479614 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:32:43.480611 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1827\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:32:46.645142 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 146.99it/s]\n",
      "I0121 00:32:51.023457 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:32:51.346591 15348 fine_tuned.py:285] ***** Running evaluation 1827 *****\n",
      "I0121 00:32:51.346591 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:32:51.347562 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090e72e5936549828cc7b754aad76707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:05.260147 15348 fine_tuned.py:366] ***** Eval results 1827 *****\n",
      "I0121 00:33:05.261144 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:33:05.262141 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:33:05.262141 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:33:05.262141 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:33:05.263138 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:33:05.263138 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:33:05.264136 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2030\\config.json\n",
      "I0121 00:33:05.265133 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:33:05.266131 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2030\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:08.211249 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 149.18it/s]\n",
      "I0121 00:33:13.060304 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:33:13.406380 15348 fine_tuned.py:285] ***** Running evaluation 2030 *****\n",
      "I0121 00:33:13.407375 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:33:13.408344 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8609c39e0d4f40519b3f1c075d75434e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:27.209863 15348 fine_tuned.py:366] ***** Eval results 2030 *****\n",
      "I0121 00:33:27.210860 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:33:27.210860 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:33:27.211857 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:33:27.211857 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:33:27.211857 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:33:27.212855 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:33:27.213853 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-203\\config.json\n",
      "I0121 00:33:27.214849 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:33:27.214849 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-203\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:30.190885 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 148.78it/s]\n",
      "I0121 00:33:34.546736 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:33:34.868413 15348 fine_tuned.py:285] ***** Running evaluation 203 *****\n",
      "I0121 00:33:34.869380 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:33:34.869380 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601964fef23e448fa447c14e7d02ee69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:48.980602 15348 fine_tuned.py:366] ***** Eval results 203 *****\n",
      "I0121 00:33:48.981598 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:33:48.981598 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:33:48.982595 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:33:48.982595 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:33:48.982595 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:33:48.983592 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:33:48.984590 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-2233\\config.json\n",
      "I0121 00:33:48.985587 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:33:48.986584 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-2233\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:33:52.000519 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 147.10it/s]\n",
      "I0121 00:33:56.446622 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:33:56.769785 15348 fine_tuned.py:285] ***** Running evaluation 2233 *****\n",
      "I0121 00:33:56.770785 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:33:56.770785 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa44c4c79e6949feb8d9f85b085949e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:10.617703 15348 fine_tuned.py:366] ***** Eval results 2233 *****\n",
      "I0121 00:34:10.618701 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:34:10.619698 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:34:10.620696 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:34:10.620696 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:34:10.621693 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:34:10.622691 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:34:10.622691 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-406\\config.json\n",
      "I0121 00:34:10.623688 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:34:10.624685 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-406\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:13.536891 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 147.95it/s]\n",
      "I0121 00:34:18.433789 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:34:18.763940 15348 fine_tuned.py:285] ***** Running evaluation 406 *****\n",
      "I0121 00:34:18.764931 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:34:18.764931 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086523878d01401fae6a26c9b5186fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:32.784508 15348 fine_tuned.py:366] ***** Eval results 406 *****\n",
      "I0121 00:34:32.785505 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:34:32.785505 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:34:32.785505 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:34:32.786501 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:34:32.786501 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:34:32.787500 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:34:32.788496 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-609\\config.json\n",
      "I0121 00:34:32.788496 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:34:32.789494 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-609\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:35.735610 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 145.90it/s]\n",
      "I0121 00:34:40.726257 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:34:41.066376 15348 fine_tuned.py:285] ***** Running evaluation 609 *****\n",
      "I0121 00:34:41.067375 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:34:41.068344 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92568c51af784b028f3d3457e79ec215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:54.906985 15348 fine_tuned.py:366] ***** Eval results 609 *****\n",
      "I0121 00:34:54.907982 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:34:54.907982 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:34:54.908980 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:34:54.908980 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:34:54.909977 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:34:54.909977 15348 fine_tuned.py:368]   tp = 274\n",
      "I0121 00:34:54.910974 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-812\\config.json\n",
      "I0121 00:34:54.911971 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:34:54.911971 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-812\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs\\60\\dbpedia-812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:34:57.933886 15348 fine_tuned.py:112] Creating features from dataset file at data/\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 610/610 [00:04<00:00, 144.15it/s]\n",
      "I0121 00:35:02.914558 15348 fine_tuned.py:124] Saving features into cached file data/cached_train_roberta-base_512_binary\n",
      "I0121 00:35:03.234729 15348 fine_tuned.py:285] ***** Running evaluation 812 *****\n",
      "I0121 00:35:03.235727 15348 fine_tuned.py:286]   Num examples = 610\n",
      "I0121 00:35:03.235727 15348 fine_tuned.py:287]   Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46472ed75714934a4a4e1d6566267de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=153.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:35:17.138497 15348 fine_tuned.py:366] ***** Eval results 812 *****\n",
      "I0121 00:35:17.139522 15348 fine_tuned.py:368]   acc = 1.0\n",
      "I0121 00:35:17.139522 15348 fine_tuned.py:368]   fn = 0\n",
      "I0121 00:35:17.139522 15348 fine_tuned.py:368]   fp = 0\n",
      "I0121 00:35:17.140492 15348 fine_tuned.py:368]   mcc = 1.0\n",
      "I0121 00:35:17.140492 15348 fine_tuned.py:368]   tn = 336\n",
      "I0121 00:35:17.141489 15348 fine_tuned.py:368]   tp = 274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- dbpedia ----------\n",
      "2000  neg  1000  pos  1000\n",
      "start encoding text by roberta-base\n",
      "total number of examples  2000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0121 00:35:17.896497 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n",
      "I0121 00:35:17.897494 15348 tokenization_utils.py:398] loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at C:\\Users\\jh\\.cache\\torch\\transformers\\b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "I0121 00:35:17.959302 15348 configuration_utils.py:157] loading configuration file outputs\\60\\dbpedia-1015\\config.json\n",
      "I0121 00:35:17.960299 15348 configuration_utils.py:177] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "I0121 00:35:17.960299 15348 modeling_utils.py:398] loading weights file outputs\\60\\dbpedia-1015\\pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473350a60e7b450cb96a5e7dadf16410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2000.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training set size: 610 unique(labels): [0 1] label counts: [336 274]\n",
      "Number of training examples  610\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       664\n",
      "           1       1.00      1.00      1.00       726\n",
      "\n",
      "    accuracy                           1.00      1390\n",
      "   macro avg       1.00      1.00      1.00      1390\n",
      "weighted avg       1.00      1.00      1.00      1390\n",
      "\n",
      "TP_H 274  TN_H 336  TP_M 726  TN_M 662  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  620 ********************\n",
      "processing  61 th loops---------------\n",
      "training set size: 620 unique(labels): [0 1] label counts: [338 282]\n",
      "Number of training examples  620\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       662\n",
      "           1       1.00      1.00      1.00       718\n",
      "\n",
      "    accuracy                           1.00      1380\n",
      "   macro avg       1.00      1.00      1.00      1380\n",
      "weighted avg       1.00      1.00      1.00      1380\n",
      "\n",
      "TP_H 282  TN_H 338  TP_M 718  TN_M 660  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  630 ********************\n",
      "processing  62 th loops---------------\n",
      "training set size: 630 unique(labels): [0 1] label counts: [341 289]\n",
      "Number of training examples  630\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       659\n",
      "           1       1.00      1.00      1.00       711\n",
      "\n",
      "    accuracy                           1.00      1370\n",
      "   macro avg       1.00      1.00      1.00      1370\n",
      "weighted avg       1.00      1.00      1.00      1370\n",
      "\n",
      "TP_H 289  TN_H 341  TP_M 711  TN_M 657  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  640 ********************\n",
      "processing  63 th loops---------------\n",
      "training set size: 640 unique(labels): [0 1] label counts: [344 296]\n",
      "Number of training examples  640\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       656\n",
      "           1       1.00      1.00      1.00       704\n",
      "\n",
      "    accuracy                           1.00      1360\n",
      "   macro avg       1.00      1.00      1.00      1360\n",
      "weighted avg       1.00      1.00      1.00      1360\n",
      "\n",
      "TP_H 296  TN_H 344  TP_M 704  TN_M 654  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  650 ********************\n",
      "processing  64 th loops---------------\n",
      "training set size: 650 unique(labels): [0 1] label counts: [346 304]\n",
      "Number of training examples  650\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       654\n",
      "           1       1.00      1.00      1.00       696\n",
      "\n",
      "    accuracy                           1.00      1350\n",
      "   macro avg       1.00      1.00      1.00      1350\n",
      "weighted avg       1.00      1.00      1.00      1350\n",
      "\n",
      "TP_H 304  TN_H 346  TP_M 696  TN_M 652  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  660 ********************\n",
      "processing  65 th loops---------------\n",
      "training set size: 660 unique(labels): [0 1] label counts: [346 314]\n",
      "Number of training examples  660\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       654\n",
      "           1       1.00      1.00      1.00       686\n",
      "\n",
      "    accuracy                           1.00      1340\n",
      "   macro avg       1.00      1.00      1.00      1340\n",
      "weighted avg       1.00      1.00      1.00      1340\n",
      "\n",
      "TP_H 314  TN_H 346  TP_M 686  TN_M 652  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  670 ********************\n",
      "processing  66 th loops---------------\n",
      "training set size: 670 unique(labels): [0 1] label counts: [347 323]\n",
      "Number of training examples  670\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       653\n",
      "           1       1.00      1.00      1.00       677\n",
      "\n",
      "    accuracy                           1.00      1330\n",
      "   macro avg       1.00      1.00      1.00      1330\n",
      "weighted avg       1.00      1.00      1.00      1330\n",
      "\n",
      "TP_H 323  TN_H 347  TP_M 677  TN_M 651  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  680 ********************\n",
      "processing  67 th loops---------------\n",
      "training set size: 680 unique(labels): [0 1] label counts: [347 333]\n",
      "Number of training examples  680\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       653\n",
      "           1       1.00      1.00      1.00       667\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "TP_H 333  TN_H 347  TP_M 667  TN_M 651  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  690 ********************\n",
      "processing  68 th loops---------------\n",
      "training set size: 690 unique(labels): [0 1] label counts: [347 343]\n",
      "Number of training examples  690\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       653\n",
      "           1       1.00      1.00      1.00       657\n",
      "\n",
      "    accuracy                           1.00      1310\n",
      "   macro avg       1.00      1.00      1.00      1310\n",
      "weighted avg       1.00      1.00      1.00      1310\n",
      "\n",
      "TP_H 343  TN_H 347  TP_M 657  TN_M 651  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  700 ********************\n",
      "processing  69 th loops---------------\n",
      "training set size: 700 unique(labels): [0 1] label counts: [349 351]\n",
      "Number of training examples  700\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       651\n",
      "           1       1.00      1.00      1.00       649\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      1.00      1.00      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n",
      "TP_H 351  TN_H 349  TP_M 649  TN_M 649  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  710 ********************\n",
      "processing  70 th loops---------------\n",
      "training set size: 710 unique(labels): [0 1] label counts: [351 359]\n",
      "Number of training examples  710\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       649\n",
      "           1       1.00      1.00      1.00       641\n",
      "\n",
      "    accuracy                           1.00      1290\n",
      "   macro avg       1.00      1.00      1.00      1290\n",
      "weighted avg       1.00      1.00      1.00      1290\n",
      "\n",
      "TP_H 359  TN_H 351  TP_M 641  TN_M 647  FP_M 2  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  720 ********************\n",
      "processing  71 th loops---------------\n",
      "training set size: 720 unique(labels): [0 1] label counts: [356 364]\n",
      "Number of training examples  720\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       636\n",
      "\n",
      "    accuracy                           1.00      1280\n",
      "   macro avg       1.00      1.00      1.00      1280\n",
      "weighted avg       1.00      1.00      1.00      1280\n",
      "\n",
      "TP_H 364  TN_H 356  TP_M 636  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  730 ********************\n",
      "processing  72 th loops---------------\n",
      "training set size: 730 unique(labels): [0 1] label counts: [356 374]\n",
      "Number of training examples  730\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       626\n",
      "\n",
      "    accuracy                           1.00      1270\n",
      "   macro avg       1.00      1.00      1.00      1270\n",
      "weighted avg       1.00      1.00      1.00      1270\n",
      "\n",
      "TP_H 374  TN_H 356  TP_M 626  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  740 ********************\n",
      "processing  73 th loops---------------\n",
      "training set size: 740 unique(labels): [0 1] label counts: [356 384]\n",
      "Number of training examples  740\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       616\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n",
      "TP_H 384  TN_H 356  TP_M 616  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  750 ********************\n",
      "processing  74 th loops---------------\n",
      "training set size: 750 unique(labels): [0 1] label counts: [356 394]\n",
      "Number of training examples  750\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       606\n",
      "\n",
      "    accuracy                           1.00      1250\n",
      "   macro avg       1.00      1.00      1.00      1250\n",
      "weighted avg       1.00      1.00      1.00      1250\n",
      "\n",
      "TP_H 394  TN_H 356  TP_M 606  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  760 ********************\n",
      "processing  75 th loops---------------\n",
      "training set size: 760 unique(labels): [0 1] label counts: [356 404]\n",
      "Number of training examples  760\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       596\n",
      "\n",
      "    accuracy                           1.00      1240\n",
      "   macro avg       1.00      1.00      1.00      1240\n",
      "weighted avg       1.00      1.00      1.00      1240\n",
      "\n",
      "TP_H 404  TN_H 356  TP_M 596  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  770 ********************\n",
      "processing  76 th loops---------------\n",
      "training set size: 770 unique(labels): [0 1] label counts: [356 414]\n",
      "Number of training examples  770\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       586\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "TP_H 414  TN_H 356  TP_M 586  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  780 ********************\n",
      "processing  77 th loops---------------\n",
      "training set size: 780 unique(labels): [0 1] label counts: [356 424]\n",
      "Number of training examples  780\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       576\n",
      "\n",
      "    accuracy                           1.00      1220\n",
      "   macro avg       1.00      1.00      1.00      1220\n",
      "weighted avg       1.00      1.00      1.00      1220\n",
      "\n",
      "TP_H 424  TN_H 356  TP_M 576  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  790 ********************\n",
      "processing  78 th loops---------------\n",
      "training set size: 790 unique(labels): [0 1] label counts: [356 434]\n",
      "Number of training examples  790\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       566\n",
      "\n",
      "    accuracy                           1.00      1210\n",
      "   macro avg       1.00      1.00      1.00      1210\n",
      "weighted avg       1.00      1.00      1.00      1210\n",
      "\n",
      "TP_H 434  TN_H 356  TP_M 566  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  800 ********************\n",
      "processing  79 th loops---------------\n",
      "training set size: 800 unique(labels): [0 1] label counts: [356 444]\n",
      "Number of training examples  800\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       556\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n",
      "TP_H 444  TN_H 356  TP_M 556  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  810 ********************\n",
      "processing  80 th loops---------------\n",
      "training set size: 810 unique(labels): [0 1] label counts: [356 454]\n",
      "Number of training examples  810\n",
      "start gridsearch ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       546\n",
      "\n",
      "    accuracy                           1.00      1190\n",
      "   macro avg       1.00      1.00      1.00      1190\n",
      "weighted avg       1.00      1.00      1.00      1190\n",
      "\n",
      "TP_H 454  TN_H 356  TP_M 546  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  820 ********************\n",
      "processing  81 th loops---------------\n",
      "training set size: 820 unique(labels): [0 1] label counts: [356 464]\n",
      "Number of training examples  820\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       536\n",
      "\n",
      "    accuracy                           1.00      1180\n",
      "   macro avg       1.00      1.00      1.00      1180\n",
      "weighted avg       1.00      1.00      1.00      1180\n",
      "\n",
      "TP_H 464  TN_H 356  TP_M 536  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  830 ********************\n",
      "processing  82 th loops---------------\n",
      "training set size: 830 unique(labels): [0 1] label counts: [356 474]\n",
      "Number of training examples  830\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       526\n",
      "\n",
      "    accuracy                           1.00      1170\n",
      "   macro avg       1.00      1.00      1.00      1170\n",
      "weighted avg       1.00      1.00      1.00      1170\n",
      "\n",
      "TP_H 474  TN_H 356  TP_M 526  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  840 ********************\n",
      "processing  83 th loops---------------\n",
      "training set size: 840 unique(labels): [0 1] label counts: [356 484]\n",
      "Number of training examples  840\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       516\n",
      "\n",
      "    accuracy                           1.00      1160\n",
      "   macro avg       1.00      1.00      1.00      1160\n",
      "weighted avg       1.00      1.00      1.00      1160\n",
      "\n",
      "TP_H 484  TN_H 356  TP_M 516  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  850 ********************\n",
      "processing  84 th loops---------------\n",
      "training set size: 850 unique(labels): [0 1] label counts: [356 494]\n",
      "Number of training examples  850\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       506\n",
      "\n",
      "    accuracy                           1.00      1150\n",
      "   macro avg       1.00      1.00      1.00      1150\n",
      "weighted avg       1.00      1.00      1.00      1150\n",
      "\n",
      "TP_H 494  TN_H 356  TP_M 506  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  860 ********************\n",
      "processing  85 th loops---------------\n",
      "training set size: 860 unique(labels): [0 1] label counts: [356 504]\n",
      "Number of training examples  860\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       496\n",
      "\n",
      "    accuracy                           1.00      1140\n",
      "   macro avg       1.00      1.00      1.00      1140\n",
      "weighted avg       1.00      1.00      1.00      1140\n",
      "\n",
      "TP_H 504  TN_H 356  TP_M 496  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  870 ********************\n",
      "processing  86 th loops---------------\n",
      "training set size: 870 unique(labels): [0 1] label counts: [356 514]\n",
      "Number of training examples  870\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       486\n",
      "\n",
      "    accuracy                           1.00      1130\n",
      "   macro avg       1.00      1.00      1.00      1130\n",
      "weighted avg       1.00      1.00      1.00      1130\n",
      "\n",
      "TP_H 514  TN_H 356  TP_M 486  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  880 ********************\n",
      "processing  87 th loops---------------\n",
      "training set size: 880 unique(labels): [0 1] label counts: [356 524]\n",
      "Number of training examples  880\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       476\n",
      "\n",
      "    accuracy                           1.00      1120\n",
      "   macro avg       1.00      1.00      1.00      1120\n",
      "weighted avg       1.00      1.00      1.00      1120\n",
      "\n",
      "TP_H 524  TN_H 356  TP_M 476  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  890 ********************\n",
      "processing  88 th loops---------------\n",
      "training set size: 890 unique(labels): [0 1] label counts: [356 534]\n",
      "Number of training examples  890\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       466\n",
      "\n",
      "    accuracy                           1.00      1110\n",
      "   macro avg       1.00      1.00      1.00      1110\n",
      "weighted avg       1.00      1.00      1.00      1110\n",
      "\n",
      "TP_H 534  TN_H 356  TP_M 466  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  900 ********************\n",
      "processing  89 th loops---------------\n",
      "training set size: 900 unique(labels): [0 1] label counts: [356 544]\n",
      "Number of training examples  900\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       456\n",
      "\n",
      "    accuracy                           1.00      1100\n",
      "   macro avg       1.00      1.00      1.00      1100\n",
      "weighted avg       1.00      1.00      1.00      1100\n",
      "\n",
      "TP_H 544  TN_H 356  TP_M 456  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  910 ********************\n",
      "processing  90 th loops---------------\n",
      "training set size: 910 unique(labels): [0 1] label counts: [356 554]\n",
      "Number of training examples  910\n",
      "start gridsearch ...\n",
      "best parameters is  {'C': 0.01, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       446\n",
      "\n",
      "    accuracy                           1.00      1090\n",
      "   macro avg       1.00      1.00      1.00      1090\n",
      "weighted avg       1.00      1.00      1.00      1090\n",
      "\n",
      "TP_H 554  TN_H 356  TP_M 446  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  920 ********************\n",
      "processing  91 th loops---------------\n",
      "training set size: 920 unique(labels): [0 1] label counts: [356 564]\n",
      "Number of training examples  920\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       644\n",
      "           1       1.00      1.00      1.00       436\n",
      "\n",
      "    accuracy                           1.00      1080\n",
      "   macro avg       1.00      1.00      1.00      1080\n",
      "weighted avg       1.00      1.00      1.00      1080\n",
      "\n",
      "TP_H 564  TN_H 356  TP_M 436  TN_M 643  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  930 ********************\n",
      "processing  92 th loops---------------\n",
      "training set size: 930 unique(labels): [0 1] label counts: [357 573]\n",
      "Number of training examples  930\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       643\n",
      "           1       1.00      1.00      1.00       427\n",
      "\n",
      "    accuracy                           1.00      1070\n",
      "   macro avg       1.00      1.00      1.00      1070\n",
      "weighted avg       1.00      1.00      1.00      1070\n",
      "\n",
      "TP_H 573  TN_H 357  TP_M 427  TN_M 642  FP_M 1  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  940 ********************\n",
      "processing  93 th loops---------------\n",
      "training set size: 940 unique(labels): [0 1] label counts: [358 582]\n",
      "Number of training examples  940\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       418\n",
      "\n",
      "    accuracy                           1.00      1060\n",
      "   macro avg       1.00      1.00      1.00      1060\n",
      "weighted avg       1.00      1.00      1.00      1060\n",
      "\n",
      "TP_H 582  TN_H 358  TP_M 418  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  950 ********************\n",
      "processing  94 th loops---------------\n",
      "training set size: 950 unique(labels): [0 1] label counts: [358 592]\n",
      "Number of training examples  950\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       408\n",
      "\n",
      "    accuracy                           1.00      1050\n",
      "   macro avg       1.00      1.00      1.00      1050\n",
      "weighted avg       1.00      1.00      1.00      1050\n",
      "\n",
      "TP_H 592  TN_H 358  TP_M 408  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  960 ********************\n",
      "processing  95 th loops---------------\n",
      "training set size: 960 unique(labels): [0 1] label counts: [358 602]\n",
      "Number of training examples  960\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       398\n",
      "\n",
      "    accuracy                           1.00      1040\n",
      "   macro avg       1.00      1.00      1.00      1040\n",
      "weighted avg       1.00      1.00      1.00      1040\n",
      "\n",
      "TP_H 602  TN_H 358  TP_M 398  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  970 ********************\n",
      "processing  96 th loops---------------\n",
      "training set size: 970 unique(labels): [0 1] label counts: [358 612]\n",
      "Number of training examples  970\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       388\n",
      "\n",
      "    accuracy                           1.00      1030\n",
      "   macro avg       1.00      1.00      1.00      1030\n",
      "weighted avg       1.00      1.00      1.00      1030\n",
      "\n",
      "TP_H 612  TN_H 358  TP_M 388  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  980 ********************\n",
      "processing  97 th loops---------------\n",
      "training set size: 980 unique(labels): [0 1] label counts: [358 622]\n",
      "Number of training examples  980\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       378\n",
      "\n",
      "    accuracy                           1.00      1020\n",
      "   macro avg       1.00      1.00      1.00      1020\n",
      "weighted avg       1.00      1.00      1.00      1020\n",
      "\n",
      "TP_H 622  TN_H 358  TP_M 378  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  990 ********************\n",
      "processing  98 th loops---------------\n",
      "training set size: 990 unique(labels): [0 1] label counts: [358 632]\n",
      "Number of training examples  990\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       368\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       1.00      1.00      1.00      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n",
      "TP_H 632  TN_H 358  TP_M 368  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1000 ********************\n",
      "processing  99 th loops---------------\n",
      "training set size: 1000 unique(labels): [0 1] label counts: [358 642]\n",
      "Number of training examples  1000\n",
      "best parameters is  SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='linear', max_iter=10000, probability=True, random_state=2019,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       642\n",
      "           1       1.00      1.00      1.00       358\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "TP_H 642  TN_H 358  TP_M 358  TN_M 642  FP_M 0  FN_M 0\n",
      "******************** selection method  uncertainty ********************\n",
      "******************** num of training set  1010 ********************\n",
      "--- 28852.275008678436 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# Run the main function\n",
    "# selection_method = 'certainty'\n",
    "selection_method = 'uncertainty'\n",
    "# selection_method = 'mostConfident'\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df_permutation = pd.DataFrame()\n",
    "    \n",
    "    ## using different random seeds to seed the initial dataset\n",
    "    random_seeds = [i for i in range(1988,1998)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for seed in random_seeds:\n",
    "        confusion_matrice = []\n",
    "        entropy = []\n",
    "        permutations = []\n",
    "        \n",
    "        for loop in range(100):\n",
    "            print('processing ',loop,'th loops---------------')\n",
    "\n",
    "            ## first 20 loops are identical to normal active learning\n",
    "            if loop==0:\n",
    "                \n",
    "                \n",
    "                dir_neg = dataset + '_neg.csv'\n",
    "                dir_pos = dataset + '_pos.csv'\n",
    "                representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "                representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "                ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "                labels = np.array([0]*len(representations_neg)+[1]*len(representations_pos))\n",
    "       \n",
    "                parser = ArgumentParser()\n",
    "                args = parser.parse_known_args()[0]\n",
    "                args = easydict.EasyDict({\n",
    "                        \"n_seedsamples\":5,\n",
    "                        \"initial_random_seed\":seed,\n",
    "                        \"initial\": True,\n",
    "                        \"TEXT_emb\": ulti_representations,\n",
    "                        \"LABEL_emb\": labels,\n",
    "                        \"gridsearch\":True,\n",
    "                        \"loop\":loop,\n",
    "                        \"gridsearch_interval\":10\n",
    "\n",
    "                })\n",
    "\n",
    "                evaluation,y_pred_prob,y_pred,permutation,best_params_,dist = active_process(args)\n",
    "\n",
    "\n",
    "                permutation = sample_candidates(num_candidate=10,permutation=permutation,selection_method=selection_method,y_prob=y_pred_prob,y_pred=y_pred,dist=dist)\n",
    "                permutations.append(permutation)\n",
    "                \n",
    "                confusion_matrice.append(evaluation['Confusion matrix'])\n",
    "                \n",
    "                \n",
    "        \n",
    "\n",
    "            else:\n",
    "                \n",
    "                ## start fine tuning\n",
    "                if loop==20:\n",
    "                    construct_train_set(dataset,permutation)\n",
    "                    ## fine tuning\n",
    "                    checkpoint, accs = fine_tuned.fine_tuned(loop,dataset,'roberta-base',int(len(permutation)/3),1e-5)\n",
    "                    \n",
    "                    ## re-infer embeddings\n",
    "                    inference.inference(dataset,checkpoint,loop)\n",
    "\n",
    "                    \n",
    "                    ## save tuned embeddings to local\n",
    "                    dir_neg = dataset + '_tuned_neg_%s.csv'%(loop)\n",
    "                    dir_pos = dataset + '_tuned_pos_%s.csv'%(loop)\n",
    "                    representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "                    representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "\n",
    "                    ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "\n",
    "                    for key in accs.keys():\n",
    "                        if key!= checkpoint:\n",
    "                            shutil.rmtree(key)\n",
    "\n",
    "                elif loop%20==0 and loop>20 and loop<80:\n",
    "                    construct_train_set(dataset,permutation)\n",
    "                    checkpoint, accs = fine_tuned.fine_tuned(loop,dataset,checkpoint,int(len(permutation)/3),1e-5)\n",
    "                    inference.inference(dataset,checkpoint,loop)\n",
    "\n",
    "                    dir_neg = dataset + '_tuned_neg_%s.csv'%(loop)\n",
    "                    dir_pos = dataset + '_tuned_pos_%s.csv'%(loop)\n",
    "                    representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "                    representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "\n",
    "                    ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "\n",
    "                    for key in accs.keys():\n",
    "                        if key!= checkpoint:\n",
    "                            shutil.rmtree(key)\n",
    "\n",
    "                parser = ArgumentParser()\n",
    "                args = parser.parse_known_args()[0]\n",
    "                args = easydict.EasyDict({\n",
    "                        \"n_seedsamples\":5,\n",
    "                        \"initial_random_seed\":seed,\n",
    "                        \"permutation\": permutation,\n",
    "                        \"initial\": False,\n",
    "                        \"TEXT_emb\": ulti_representations,\n",
    "                        \"LABEL_emb\": labels,\n",
    "                        \"best_params_\":best_params_,\n",
    "                        \"loop\":loop,\n",
    "                        \"gridsearch_interval\":10\n",
    "                })\n",
    "\n",
    "                evaluation,y_pred_prob,y_pred,permutation,best_params_,dist = active_process(args)\n",
    "\n",
    "\n",
    "                permutation = sample_candidates(num_candidate=10,permutation=permutation,selection_method=selection_method,y_prob=y_pred_prob,y_pred=y_pred,dist=dist)\n",
    "                permutations.append(permutation)\n",
    "                \n",
    "                confusion_matrice.append(evaluation['Confusion matrix'])\n",
    "                \n",
    "               \n",
    "                \n",
    "              \n",
    "        ## the tp_h, tn_h, tp_m, tn_m, fp_m, fn_m for each loop\n",
    "        df[seed] = [item[0] for item in confusion_matrice]\n",
    "        df.to_csv('./results/raw_%s_%s_%s_gridsearch.csv'%(text_rep,dataset,selection_method))\n",
    "\n",
    "\n",
    "        ## the index of documents for each loop\n",
    "        df_permutation[seed] = [permutation for permutation in permutations]\n",
    "\n",
    "        df_permutation.to_csv('./results/permutation_%s_%s_%s_result.csv'%(text_rep,dataset,selection_method))\n",
    "        \n",
    "        shutil.rmtree(\"./outputs/\") \n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import easydict\n",
    "# from argparse import ArgumentParser\n",
    "\n",
    "# # Run the main function\n",
    "# # selection_method = 'certainty'\n",
    "# selection_method = 'uncertainty'\n",
    "# # selection_method = 'mostConfident'\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     df = pd.DataFrame()\n",
    "#     df_permutation = pd.DataFrame()\n",
    "# #     random_seeds = [1989,1990,1991,1992,1993,1994,1995,1996,1997]\n",
    "#     random_seeds = [i for i in range(1988,1998)]\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     for seed in random_seeds:\n",
    "#         confusion_matrice = []\n",
    "#         entropy = []\n",
    "#         permutations = []\n",
    "        \n",
    "#         for loop in range(100):\n",
    "#             print('processing ',loop,'th loops---------------')\n",
    "\n",
    "#             if loop==0 :\n",
    "                \n",
    "#                 dir_neg = dataset + '_neg.csv'\n",
    "#                 dir_pos = dataset + '_pos.csv'\n",
    "#                 representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "#                 representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "#                 ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "#                 labels = np.array([0]*len(representations_neg)+[1]*len(representations_pos))\n",
    "       \n",
    "#                 parser = ArgumentParser()\n",
    "#                 args = parser.parse_known_args()[0]\n",
    "#                 args = easydict.EasyDict({\n",
    "#                         \"n_seedsamples\":5,\n",
    "#                         \"initial_random_seed\":seed,\n",
    "#                         \"initial\": True,\n",
    "#                         \"TEXT_emb\": ulti_representations,\n",
    "#                         \"LABEL_emb\": labels,\n",
    "#                         \"gridsearch\":True,\n",
    "#                         \"loop\":loop,\n",
    "#                         \"gridsearch_interval\":10\n",
    "\n",
    "#                 })\n",
    "\n",
    "#                 evaluation,y_pred_prob,y_pred,permutation,best_params_,dist = active_process(args)\n",
    "\n",
    "\n",
    "#                 permutation = sample_candidates(num_candidate=10,permutation=permutation,selection_method=selection_method,y_prob=y_pred_prob,y_pred=y_pred,dist=dist)\n",
    "#                 permutations.append(permutation)\n",
    "                \n",
    "#                 confusion_matrice.append(evaluation['Confusion matrix'])\n",
    "                \n",
    "                \n",
    "        \n",
    "\n",
    "#             else:\n",
    "                \n",
    "               \n",
    "#                 if loop==40:\n",
    "#                     construct_train_set(dataset,permutation)\n",
    "#                     checkpoint, accs = fine_tuned.fine_tuned(loop,dataset,'roberta-base',32,1e-6)\n",
    "#                     inference.inference(dataset,checkpoint,loop)\n",
    "\n",
    "#                     dir_neg = dataset + '_tuned_neg_%s.csv'%(loop)\n",
    "#                     dir_pos = dataset + '_tuned_pos_%s.csv'%(loop)\n",
    "#                     representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "#                     representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "\n",
    "#                     ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "#                 elif loop%40==0 and loop>40:\n",
    "#                     construct_train_set(dataset,permutation)\n",
    "#                     checkpoint, accs = fine_tuned.fine_tuned(loop,dataset,checkpoint,64,1e-5)\n",
    "#                     inference.inference(dataset,checkpoint,loop)\n",
    "\n",
    "#                     dir_neg = dataset + '_tuned_neg_%s.csv'%(loop)\n",
    "#                     dir_pos = dataset + '_tuned_pos_%s.csv'%(loop)\n",
    "#                     representations_neg = genfromtxt('./%s_data/'%(text_rep)+dir_neg, delimiter=',')\n",
    "#                     representations_pos = genfromtxt('./%s_data/'%(text_rep)+dir_pos, delimiter=',')\n",
    "\n",
    "#                     ulti_representations = np.concatenate((representations_neg,representations_pos),axis=0)\n",
    "                    \n",
    "              \n",
    "\n",
    "#                 parser = ArgumentParser()\n",
    "#                 args = parser.parse_known_args()[0]\n",
    "#                 args = easydict.EasyDict({\n",
    "#                         \"n_seedsamples\":5,\n",
    "#                         \"initial_random_seed\":seed,\n",
    "#                         \"permutation\": permutation,\n",
    "#                         \"initial\": False,\n",
    "#                         \"TEXT_emb\": ulti_representations,\n",
    "#                         \"LABEL_emb\": labels,\n",
    "#                         \"best_params_\":best_params_,\n",
    "#                         \"loop\":loop,\n",
    "#                         \"gridsearch_interval\":10\n",
    "#                 })\n",
    "\n",
    "#                 evaluation,y_pred_prob,y_pred,permutation,best_params_,dist = active_process(args)\n",
    "\n",
    "\n",
    "#                 permutation = sample_candidates(num_candidate=10,permutation=permutation,selection_method=selection_method,y_prob=y_pred_prob,y_pred=y_pred,dist=dist)\n",
    "#                 permutations.append(permutation)\n",
    "                \n",
    "#                 confusion_matrice.append(evaluation['Confusion matrix'])\n",
    "                \n",
    "#         shutil.rmtree(\"./outputs/\")\n",
    "                \n",
    "                \n",
    "            \n",
    "#         df[seed] = [item[0] for item in confusion_matrice]\n",
    "#         df.to_csv('./results/raw_%s_%s_%s_gridsearch.csv'%(text_rep,dataset,selection_method))\n",
    "\n",
    "\n",
    "#         df_permutation[seed] = [permutation for permutation in permutations]\n",
    "\n",
    "#         df_permutation.to_csv('./results/permutation_%s_%s_%s_result.csv'%(text_rep,dataset,selection_method))\n",
    "        \n",
    "#     print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
